{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "# with open('datasets/normed_singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "    # graph_dict = pkl.load(f)\n",
    "with open('datasets/x18_exp_l2_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)\n",
    "    \n",
    "print(len(graph_dict['train']) + len(graph_dict['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Best param value ranges from WandB sweeps\n",
    "\n",
    "- Cutoff distance = 11 - 12.5\n",
    "- Dropout = 0.4-0.5\n",
    "- Edge weights = \"exp\"\n",
    "- Edge weight lambda = 2\n",
    "- Hidden channels = 320\n",
    "- Learning rate = 3.5e-5 - 4.5e-5\n",
    "- Weight decay = 1e-6 - 1e-5\n",
    "\n",
    "New best params for 18 feature model\n",
    "\n",
    "- Dropout = 0.6\n",
    "- Hidden channels = 256\n",
    "- Learning rate = 4e-5\n",
    "- Weight decay = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "cutoff_distance = 12\n",
    "\n",
    "# gcn params - from best wandb sweep\n",
    "num_node_features = 18\n",
    "batch_size = 256\n",
    "hidden_channels = 240\n",
    "dropout = 0.6\n",
    "\n",
    "edge_weight_func = \"exp\"\n",
    "edge_weight_lambda = 2\n",
    "\n",
    "learning_rate = 4e-5\n",
    "wd = 5e-6\n",
    "epochs = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'train-final-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylan-home\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250707_093840-nykbb1lw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/train-final-model/runs/nykbb1lw' target=\"_blank\">18 node feats - Run 8 - 1500 epochs</a></strong> to <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/train-final-model/runs/nykbb1lw' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/nykbb1lw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6929, Test Loss: 0.6931\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6921, Test Loss: 0.6937\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6912\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6906\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6901\n",
      "Epoch: 060, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6872, Test Loss: 0.6891\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6894\n",
      "Epoch: 080, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6849, Test Loss: 0.6884\n",
      "Epoch: 090, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6842, Test Loss: 0.6875\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6828, Test Loss: 0.6867\n",
      "Epoch: 110, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6822, Test Loss: 0.6851\n",
      "Epoch: 120, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6804, Test Loss: 0.6842\n",
      "Epoch: 130, Train Acc: 0.5647, Test Acc: 0.5100, Train Loss: 0.6786, Test Loss: 0.6833\n",
      "Epoch: 140, Train Acc: 0.5711, Test Acc: 0.5150, Train Loss: 0.6762, Test Loss: 0.6817\n",
      "Epoch: 150, Train Acc: 0.5948, Test Acc: 0.5350, Train Loss: 0.6745, Test Loss: 0.6795\n",
      "Epoch: 160, Train Acc: 0.6013, Test Acc: 0.5350, Train Loss: 0.6721, Test Loss: 0.6776\n",
      "Epoch: 170, Train Acc: 0.6142, Test Acc: 0.5550, Train Loss: 0.6695, Test Loss: 0.6748\n",
      "Epoch: 180, Train Acc: 0.6336, Test Acc: 0.5700, Train Loss: 0.6658, Test Loss: 0.6719\n",
      "Epoch: 190, Train Acc: 0.6487, Test Acc: 0.5800, Train Loss: 0.6618, Test Loss: 0.6688\n",
      "Epoch: 200, Train Acc: 0.6638, Test Acc: 0.5850, Train Loss: 0.6572, Test Loss: 0.6654\n",
      "Epoch: 210, Train Acc: 0.7026, Test Acc: 0.6550, Train Loss: 0.6529, Test Loss: 0.6610\n",
      "Epoch: 220, Train Acc: 0.7069, Test Acc: 0.6500, Train Loss: 0.6470, Test Loss: 0.6567\n",
      "Epoch: 230, Train Acc: 0.7392, Test Acc: 0.6800, Train Loss: 0.6415, Test Loss: 0.6520\n",
      "Epoch: 240, Train Acc: 0.7435, Test Acc: 0.6850, Train Loss: 0.6343, Test Loss: 0.6466\n",
      "Epoch: 250, Train Acc: 0.7457, Test Acc: 0.6850, Train Loss: 0.6294, Test Loss: 0.6410\n",
      "Epoch: 260, Train Acc: 0.7306, Test Acc: 0.6700, Train Loss: 0.6203, Test Loss: 0.6354\n",
      "Epoch: 270, Train Acc: 0.7371, Test Acc: 0.6900, Train Loss: 0.6144, Test Loss: 0.6296\n",
      "Epoch: 280, Train Acc: 0.7457, Test Acc: 0.6900, Train Loss: 0.6048, Test Loss: 0.6236\n",
      "Epoch: 290, Train Acc: 0.7392, Test Acc: 0.6900, Train Loss: 0.5974, Test Loss: 0.6182\n",
      "Epoch: 300, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.5886, Test Loss: 0.6127\n",
      "Epoch: 310, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.5806, Test Loss: 0.6073\n",
      "Epoch: 320, Train Acc: 0.7759, Test Acc: 0.6850, Train Loss: 0.5713, Test Loss: 0.6025\n",
      "Epoch: 330, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5677, Test Loss: 0.5977\n",
      "Epoch: 340, Train Acc: 0.7759, Test Acc: 0.6750, Train Loss: 0.5581, Test Loss: 0.5932\n",
      "Epoch: 350, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5507, Test Loss: 0.5895\n",
      "Epoch: 360, Train Acc: 0.7780, Test Acc: 0.6900, Train Loss: 0.5472, Test Loss: 0.5853\n",
      "Epoch: 370, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5408, Test Loss: 0.5818\n",
      "Epoch: 380, Train Acc: 0.7672, Test Acc: 0.7000, Train Loss: 0.5384, Test Loss: 0.5789\n",
      "Epoch: 390, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5334, Test Loss: 0.5769\n",
      "Epoch: 400, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5227, Test Loss: 0.5725\n",
      "Epoch: 410, Train Acc: 0.7866, Test Acc: 0.7000, Train Loss: 0.5174, Test Loss: 0.5712\n",
      "Epoch: 420, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5139, Test Loss: 0.5689\n",
      "Epoch: 430, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.5087, Test Loss: 0.5654\n",
      "Epoch: 440, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.5087, Test Loss: 0.5637\n",
      "Epoch: 450, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.5031, Test Loss: 0.5614\n",
      "Epoch: 460, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.4977, Test Loss: 0.5598\n",
      "Epoch: 470, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.4927, Test Loss: 0.5606\n",
      "Epoch: 480, Train Acc: 0.7888, Test Acc: 0.7200, Train Loss: 0.4918, Test Loss: 0.5568\n",
      "Epoch: 490, Train Acc: 0.7953, Test Acc: 0.7100, Train Loss: 0.4875, Test Loss: 0.5561\n",
      "Epoch: 500, Train Acc: 0.7909, Test Acc: 0.7200, Train Loss: 0.4827, Test Loss: 0.5547\n",
      "Epoch: 510, Train Acc: 0.7909, Test Acc: 0.7300, Train Loss: 0.4834, Test Loss: 0.5517\n",
      "Epoch: 520, Train Acc: 0.7953, Test Acc: 0.7300, Train Loss: 0.4775, Test Loss: 0.5506\n",
      "Epoch: 530, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4779, Test Loss: 0.5488\n",
      "Epoch: 540, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4749, Test Loss: 0.5479\n",
      "Epoch: 550, Train Acc: 0.8017, Test Acc: 0.7350, Train Loss: 0.4708, Test Loss: 0.5465\n",
      "Epoch: 560, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4702, Test Loss: 0.5454\n",
      "Epoch: 570, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4671, Test Loss: 0.5475\n",
      "Epoch: 580, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4613, Test Loss: 0.5435\n",
      "Epoch: 590, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4601, Test Loss: 0.5408\n",
      "Epoch: 600, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4580, Test Loss: 0.5409\n",
      "Epoch: 610, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4569, Test Loss: 0.5402\n",
      "Epoch: 620, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4596, Test Loss: 0.5372\n",
      "Epoch: 630, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4534, Test Loss: 0.5385\n",
      "Epoch: 640, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4609, Test Loss: 0.5391\n",
      "Epoch: 650, Train Acc: 0.7974, Test Acc: 0.7400, Train Loss: 0.4504, Test Loss: 0.5351\n",
      "Epoch: 660, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4591, Test Loss: 0.5362\n",
      "Epoch: 670, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.4412, Test Loss: 0.5333\n",
      "Epoch: 680, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4453, Test Loss: 0.5344\n",
      "Epoch: 690, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4418, Test Loss: 0.5304\n",
      "Epoch: 700, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4475, Test Loss: 0.5290\n",
      "Epoch: 710, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4369, Test Loss: 0.5287\n",
      "Epoch: 720, Train Acc: 0.8254, Test Acc: 0.7550, Train Loss: 0.4363, Test Loss: 0.5294\n",
      "Epoch: 730, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4429, Test Loss: 0.5270\n",
      "Epoch: 740, Train Acc: 0.8190, Test Acc: 0.7600, Train Loss: 0.4307, Test Loss: 0.5305\n",
      "Epoch: 750, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4363, Test Loss: 0.5261\n",
      "Epoch: 760, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4251, Test Loss: 0.5253\n",
      "Epoch: 770, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.4304, Test Loss: 0.5266\n",
      "Epoch: 780, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4264, Test Loss: 0.5236\n",
      "Epoch: 790, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4232, Test Loss: 0.5236\n",
      "Epoch: 800, Train Acc: 0.8254, Test Acc: 0.7700, Train Loss: 0.4214, Test Loss: 0.5277\n",
      "Epoch: 810, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4241, Test Loss: 0.5257\n",
      "Epoch: 820, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4294, Test Loss: 0.5207\n",
      "Epoch: 830, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4170, Test Loss: 0.5211\n",
      "Epoch: 840, Train Acc: 0.8276, Test Acc: 0.7800, Train Loss: 0.4169, Test Loss: 0.5215\n",
      "Epoch: 850, Train Acc: 0.8082, Test Acc: 0.7500, Train Loss: 0.4318, Test Loss: 0.5221\n",
      "Epoch: 860, Train Acc: 0.8254, Test Acc: 0.7750, Train Loss: 0.4120, Test Loss: 0.5251\n",
      "Epoch: 870, Train Acc: 0.8233, Test Acc: 0.7700, Train Loss: 0.4174, Test Loss: 0.5282\n",
      "Epoch: 880, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.4102, Test Loss: 0.5233\n",
      "Epoch: 890, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.4108, Test Loss: 0.5229\n",
      "Epoch: 900, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.4086, Test Loss: 0.5212\n",
      "Epoch: 910, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.4084, Test Loss: 0.5213\n",
      "Epoch: 920, Train Acc: 0.8362, Test Acc: 0.7750, Train Loss: 0.4038, Test Loss: 0.5194\n",
      "Epoch: 930, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3998, Test Loss: 0.5181\n",
      "Epoch: 940, Train Acc: 0.8384, Test Acc: 0.7950, Train Loss: 0.4060, Test Loss: 0.5167\n",
      "Epoch: 950, Train Acc: 0.8362, Test Acc: 0.7750, Train Loss: 0.4063, Test Loss: 0.5186\n",
      "Epoch: 960, Train Acc: 0.8362, Test Acc: 0.7900, Train Loss: 0.4011, Test Loss: 0.5153\n",
      "Epoch: 970, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4058, Test Loss: 0.5142\n",
      "Epoch: 980, Train Acc: 0.8362, Test Acc: 0.7950, Train Loss: 0.3982, Test Loss: 0.5146\n",
      "Epoch: 990, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.3987, Test Loss: 0.5248\n",
      "Epoch: 1000, Train Acc: 0.8341, Test Acc: 0.7850, Train Loss: 0.3947, Test Loss: 0.5213\n",
      "Epoch: 1010, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.3987, Test Loss: 0.5327\n",
      "Epoch: 1020, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3956, Test Loss: 0.5212\n",
      "Epoch: 1030, Train Acc: 0.8384, Test Acc: 0.7950, Train Loss: 0.3925, Test Loss: 0.5146\n",
      "Epoch: 1040, Train Acc: 0.8405, Test Acc: 0.7950, Train Loss: 0.3931, Test Loss: 0.5136\n",
      "Epoch: 1050, Train Acc: 0.8405, Test Acc: 0.7950, Train Loss: 0.3916, Test Loss: 0.5160\n",
      "Epoch: 1060, Train Acc: 0.8427, Test Acc: 0.8000, Train Loss: 0.3886, Test Loss: 0.5151\n",
      "Epoch: 1070, Train Acc: 0.8362, Test Acc: 0.7850, Train Loss: 0.3865, Test Loss: 0.5223\n",
      "Epoch: 1080, Train Acc: 0.8448, Test Acc: 0.7950, Train Loss: 0.3902, Test Loss: 0.5141\n",
      "Epoch: 1090, Train Acc: 0.8470, Test Acc: 0.8000, Train Loss: 0.3877, Test Loss: 0.5157\n",
      "Epoch: 1100, Train Acc: 0.8491, Test Acc: 0.8000, Train Loss: 0.3811, Test Loss: 0.5159\n",
      "Epoch: 1110, Train Acc: 0.8405, Test Acc: 0.7850, Train Loss: 0.3819, Test Loss: 0.5219\n",
      "Epoch: 1120, Train Acc: 0.8427, Test Acc: 0.8000, Train Loss: 0.3863, Test Loss: 0.5136\n",
      "Epoch: 1130, Train Acc: 0.8470, Test Acc: 0.7850, Train Loss: 0.3842, Test Loss: 0.5198\n",
      "Epoch: 1140, Train Acc: 0.8427, Test Acc: 0.8000, Train Loss: 0.3804, Test Loss: 0.5133\n",
      "Epoch: 1150, Train Acc: 0.8448, Test Acc: 0.8050, Train Loss: 0.3785, Test Loss: 0.5137\n",
      "Epoch: 1160, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.3725, Test Loss: 0.5261\n",
      "Epoch: 1170, Train Acc: 0.8556, Test Acc: 0.8000, Train Loss: 0.3766, Test Loss: 0.5174\n",
      "Epoch: 1180, Train Acc: 0.8491, Test Acc: 0.8000, Train Loss: 0.3727, Test Loss: 0.5140\n",
      "Epoch: 1190, Train Acc: 0.8578, Test Acc: 0.8100, Train Loss: 0.3699, Test Loss: 0.5171\n",
      "Epoch: 1200, Train Acc: 0.8534, Test Acc: 0.8050, Train Loss: 0.3712, Test Loss: 0.5151\n",
      "Epoch: 1210, Train Acc: 0.8513, Test Acc: 0.7800, Train Loss: 0.3706, Test Loss: 0.5235\n",
      "Epoch: 1220, Train Acc: 0.8470, Test Acc: 0.8000, Train Loss: 0.3748, Test Loss: 0.5147\n",
      "Epoch: 1230, Train Acc: 0.8556, Test Acc: 0.8000, Train Loss: 0.3667, Test Loss: 0.5203\n",
      "Epoch: 1240, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.3680, Test Loss: 0.5275\n",
      "Epoch: 1250, Train Acc: 0.8534, Test Acc: 0.7850, Train Loss: 0.3690, Test Loss: 0.5234\n",
      "Epoch: 1260, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3800, Test Loss: 0.5176\n",
      "Epoch: 1270, Train Acc: 0.8405, Test Acc: 0.7750, Train Loss: 0.3627, Test Loss: 0.5312\n",
      "Epoch: 1280, Train Acc: 0.8534, Test Acc: 0.7900, Train Loss: 0.3641, Test Loss: 0.5252\n",
      "Epoch: 1290, Train Acc: 0.8405, Test Acc: 0.7700, Train Loss: 0.3644, Test Loss: 0.5350\n",
      "Epoch: 1300, Train Acc: 0.8556, Test Acc: 0.8150, Train Loss: 0.3580, Test Loss: 0.5199\n",
      "Epoch: 1310, Train Acc: 0.8405, Test Acc: 0.7700, Train Loss: 0.3615, Test Loss: 0.5347\n",
      "Epoch: 1320, Train Acc: 0.8556, Test Acc: 0.8150, Train Loss: 0.3566, Test Loss: 0.5202\n",
      "Epoch: 1330, Train Acc: 0.8599, Test Acc: 0.8050, Train Loss: 0.3596, Test Loss: 0.5185\n",
      "Epoch: 1340, Train Acc: 0.8556, Test Acc: 0.8000, Train Loss: 0.3586, Test Loss: 0.5239\n",
      "Epoch: 1350, Train Acc: 0.8578, Test Acc: 0.8150, Train Loss: 0.3529, Test Loss: 0.5206\n",
      "Epoch: 1360, Train Acc: 0.8556, Test Acc: 0.8050, Train Loss: 0.3574, Test Loss: 0.5230\n",
      "Epoch: 1370, Train Acc: 0.8513, Test Acc: 0.7800, Train Loss: 0.3516, Test Loss: 0.5360\n",
      "Epoch: 1380, Train Acc: 0.8556, Test Acc: 0.8100, Train Loss: 0.3536, Test Loss: 0.5211\n",
      "Epoch: 1390, Train Acc: 0.8578, Test Acc: 0.8000, Train Loss: 0.3521, Test Loss: 0.5186\n",
      "Epoch: 1400, Train Acc: 0.8534, Test Acc: 0.7800, Train Loss: 0.3545, Test Loss: 0.5353\n",
      "Epoch: 1410, Train Acc: 0.8578, Test Acc: 0.7750, Train Loss: 0.3505, Test Loss: 0.5353\n",
      "Epoch: 1420, Train Acc: 0.8578, Test Acc: 0.7900, Train Loss: 0.3559, Test Loss: 0.5212\n",
      "Epoch: 1430, Train Acc: 0.8621, Test Acc: 0.8100, Train Loss: 0.3482, Test Loss: 0.5229\n",
      "Epoch: 1440, Train Acc: 0.8599, Test Acc: 0.8050, Train Loss: 0.3460, Test Loss: 0.5270\n",
      "Epoch: 1450, Train Acc: 0.8491, Test Acc: 0.7750, Train Loss: 0.3447, Test Loss: 0.5416\n",
      "Epoch: 1460, Train Acc: 0.8578, Test Acc: 0.8000, Train Loss: 0.3436, Test Loss: 0.5229\n",
      "Epoch: 1470, Train Acc: 0.8427, Test Acc: 0.7550, Train Loss: 0.3516, Test Loss: 0.5557\n",
      "Epoch: 1480, Train Acc: 0.8599, Test Acc: 0.8050, Train Loss: 0.3397, Test Loss: 0.5289\n",
      "Epoch: 1490, Train Acc: 0.8578, Test Acc: 0.7850, Train Loss: 0.3487, Test Loss: 0.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▂▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████▇</td></tr><tr><td>Test F1</td><td>▃▃▃▃▃▂▄▁▄▃▄▂▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█████▇</td></tr><tr><td>Test Loss</td><td>████▇▇▆▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▂</td></tr><tr><td>Test Sensitivity</td><td>███▇▇▆▄▁▃▃▃▁▃▃▃▃▃▅▄▄▄▄▄▅▅▅▅▄▅▅▅▅▅▄▅▅▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>▁▁▁▂▁▃▆█▇▇▇█▇██▇█▇▇▇████▇▇▇████████████▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▂▃▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▂▂▂▄▂▄▄▅▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>Train Loss</td><td>█████▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>███▇▇▆▄▁▃▃▃▂▃▃▃▄▄▅▄▄▄▄▄▄▄▄▅▄▄▄▄▅▅▄▅▅▄▅▅▅</td></tr><tr><td>Train Specificity</td><td>▁▁▁▂▂▄▆▇▇▇▇█▇██▇▇▇▇███████▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.81</td></tr><tr><td>Test F1</td><td>0.81188</td></tr><tr><td>Test Loss</td><td>0.5279</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.82474</td></tr><tr><td>Train Accuracy</td><td>0.86207</td></tr><tr><td>Train F1</td><td>0.86383</td></tr><tr><td>Train Loss</td><td>0.33924</td></tr><tr><td>Train Sensitivity</td><td>0.8252</td></tr><tr><td>Train Specificity</td><td>0.90367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">18 node feats - Run 8 - 1500 epochs</strong> at: <a href='https://wandb.ai/dylan-home/train-final-model/runs/nykbb1lw' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/nykbb1lw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250707_093840-nykbb1lw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run_name = f'Run 7 - {epochs} epochs - lr {learning_rate}'\n",
    "run_name = f'18 node feats - Run 8 - {epochs} epochs'\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = cutoff_distance,\n",
    "            edge_weight_func = edge_weight_func,\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = hidden_channels,\n",
    "            learning_rate = learning_rate,\n",
    "            wd = wd,\n",
    "            dropout = dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= edge_weight_lambda,\n",
    "            early_stop=False,\n",
    "            # no_node_chem_feats=True,\n",
    "            save_path= f'saved_models/{project}/{run_name}',\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': f'{run_name}',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[185, 18], edge_index=[2, 5452], edge_attr=[5452, 1], y=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dict['train']['pnca_mut_0']['graph'].dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
