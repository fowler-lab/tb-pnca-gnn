{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)\n",
    "    \n",
    "print(len(graph_dict['train']) + len(graph_dict['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Best param value ranges from WandB sweeps\n",
    "\n",
    "- Cutoff distance = 11 - 12.5\n",
    "- Dropout = 0.4-0.5\n",
    "- Edge weights = \"exp\"\n",
    "- Edge weight lambda = 2\n",
    "- Hidden channels = 320\n",
    "- Learning rate = 3.5e-5 - 4.5e-5\n",
    "- Weight decay = 1e-6 - 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "cutoff_distance = 12\n",
    "\n",
    "# gcn params - from best wandb sweep\n",
    "num_node_features = 16\n",
    "batch_size = 256\n",
    "hidden_channels = 320\n",
    "dropout = 0.5\n",
    "\n",
    "edge_weight_func = \"exp\"\n",
    "edge_weight_lambda = 2\n",
    "\n",
    "learning_rate = 4e-5\n",
    "wd = 5e-5\n",
    "epochs = 942\n",
    "\n",
    "\n",
    "wt_seq = 'MRALIIVDVQNDFCEGGSLAVTGGAALARAISDYLAEAADYHHVVATKDFHIDPGDHFSGTPDYSSSWPPHCVSGTPGADFHPSLDTSAIEAVFYKGAYTGAYSGFEGVDENGTPLLNWLRQRGVDEVDVVGIATDHCVRQTAEDAVRNGLATRVLVDLTAGVSADTTVAALEEMRTASVELVCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'train-final-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting edge index and attaching edge weights for cutoff distance 12\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylan-home\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.20.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250626_151528-aaj9gz0w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/train-final-model/runs/aaj9gz0w' target=\"_blank\">Run 6 - 942 epochs</a></strong> to <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/train-final-model/runs/aaj9gz0w' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/aaj9gz0w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 0.5345, Test Acc: 0.4800, Train Loss: 0.6919, Test Loss: 0.6923\n",
      "Epoch: 020, Train Acc: 0.5388, Test Acc: 0.5050, Train Loss: 0.6894, Test Loss: 0.6907\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6884, Test Loss: 0.6905\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6902\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6896\n",
      "Epoch: 060, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6883\n",
      "Epoch: 070, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6845, Test Loss: 0.6874\n",
      "Epoch: 080, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6831, Test Loss: 0.6868\n",
      "Epoch: 090, Train Acc: 0.5582, Test Acc: 0.5100, Train Loss: 0.6817, Test Loss: 0.6852\n",
      "Epoch: 100, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6804, Test Loss: 0.6843\n",
      "Epoch: 110, Train Acc: 0.5711, Test Acc: 0.5100, Train Loss: 0.6774, Test Loss: 0.6819\n",
      "Epoch: 120, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6748, Test Loss: 0.6802\n",
      "Epoch: 130, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6726, Test Loss: 0.6781\n",
      "Epoch: 140, Train Acc: 0.6272, Test Acc: 0.5600, Train Loss: 0.6690, Test Loss: 0.6740\n",
      "Epoch: 150, Train Acc: 0.6422, Test Acc: 0.5750, Train Loss: 0.6646, Test Loss: 0.6703\n",
      "Epoch: 160, Train Acc: 0.6638, Test Acc: 0.6450, Train Loss: 0.6598, Test Loss: 0.6656\n",
      "Epoch: 170, Train Acc: 0.6961, Test Acc: 0.6700, Train Loss: 0.6532, Test Loss: 0.6605\n",
      "Epoch: 180, Train Acc: 0.7069, Test Acc: 0.6900, Train Loss: 0.6468, Test Loss: 0.6547\n",
      "Epoch: 190, Train Acc: 0.7263, Test Acc: 0.6700, Train Loss: 0.6387, Test Loss: 0.6483\n",
      "Epoch: 200, Train Acc: 0.7478, Test Acc: 0.6850, Train Loss: 0.6295, Test Loss: 0.6411\n",
      "Epoch: 210, Train Acc: 0.7457, Test Acc: 0.6850, Train Loss: 0.6212, Test Loss: 0.6337\n",
      "Epoch: 220, Train Acc: 0.7392, Test Acc: 0.6850, Train Loss: 0.6109, Test Loss: 0.6264\n",
      "Epoch: 230, Train Acc: 0.7500, Test Acc: 0.6750, Train Loss: 0.6008, Test Loss: 0.6190\n",
      "Epoch: 240, Train Acc: 0.7586, Test Acc: 0.6900, Train Loss: 0.5910, Test Loss: 0.6116\n",
      "Epoch: 250, Train Acc: 0.7608, Test Acc: 0.6950, Train Loss: 0.5808, Test Loss: 0.6051\n",
      "Epoch: 260, Train Acc: 0.7500, Test Acc: 0.7000, Train Loss: 0.5735, Test Loss: 0.5998\n",
      "Epoch: 270, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5632, Test Loss: 0.5929\n",
      "Epoch: 280, Train Acc: 0.7672, Test Acc: 0.7050, Train Loss: 0.5542, Test Loss: 0.5876\n",
      "Epoch: 290, Train Acc: 0.7672, Test Acc: 0.7000, Train Loss: 0.5443, Test Loss: 0.5827\n",
      "Epoch: 300, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5401, Test Loss: 0.5788\n",
      "Epoch: 310, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5316, Test Loss: 0.5751\n",
      "Epoch: 320, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.5214, Test Loss: 0.5705\n",
      "Epoch: 330, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5195, Test Loss: 0.5682\n",
      "Epoch: 340, Train Acc: 0.7931, Test Acc: 0.7150, Train Loss: 0.5090, Test Loss: 0.5693\n",
      "Epoch: 350, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5101, Test Loss: 0.5633\n",
      "Epoch: 360, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.4993, Test Loss: 0.5594\n",
      "Epoch: 370, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.4967, Test Loss: 0.5572\n",
      "Epoch: 380, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4897, Test Loss: 0.5580\n",
      "Epoch: 390, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4898, Test Loss: 0.5530\n",
      "Epoch: 400, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.4836, Test Loss: 0.5518\n",
      "Epoch: 410, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4803, Test Loss: 0.5495\n",
      "Epoch: 420, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4831, Test Loss: 0.5486\n",
      "Epoch: 430, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4780, Test Loss: 0.5464\n",
      "Epoch: 440, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4677, Test Loss: 0.5451\n",
      "Epoch: 450, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4682, Test Loss: 0.5433\n",
      "Epoch: 460, Train Acc: 0.8017, Test Acc: 0.7500, Train Loss: 0.4637, Test Loss: 0.5448\n",
      "Epoch: 470, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4601, Test Loss: 0.5431\n",
      "Epoch: 480, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4597, Test Loss: 0.5412\n",
      "Epoch: 490, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4581, Test Loss: 0.5391\n",
      "Epoch: 500, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4598, Test Loss: 0.5370\n",
      "Epoch: 510, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4518, Test Loss: 0.5367\n",
      "Epoch: 520, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4496, Test Loss: 0.5360\n",
      "Epoch: 530, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4561, Test Loss: 0.5337\n",
      "Epoch: 540, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4438, Test Loss: 0.5343\n",
      "Epoch: 550, Train Acc: 0.8060, Test Acc: 0.7250, Train Loss: 0.4529, Test Loss: 0.5329\n",
      "Epoch: 560, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4391, Test Loss: 0.5317\n",
      "Epoch: 570, Train Acc: 0.8147, Test Acc: 0.7650, Train Loss: 0.4372, Test Loss: 0.5326\n",
      "Epoch: 580, Train Acc: 0.8060, Test Acc: 0.7300, Train Loss: 0.4483, Test Loss: 0.5308\n",
      "Epoch: 590, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4327, Test Loss: 0.5293\n",
      "Epoch: 600, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4356, Test Loss: 0.5319\n",
      "Epoch: 610, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4460, Test Loss: 0.5304\n",
      "Epoch: 620, Train Acc: 0.8190, Test Acc: 0.7650, Train Loss: 0.4291, Test Loss: 0.5299\n",
      "Epoch: 630, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4260, Test Loss: 0.5253\n",
      "Epoch: 640, Train Acc: 0.8103, Test Acc: 0.7600, Train Loss: 0.4365, Test Loss: 0.5245\n",
      "Epoch: 650, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4242, Test Loss: 0.5277\n",
      "Epoch: 660, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4266, Test Loss: 0.5226\n",
      "Epoch: 670, Train Acc: 0.8147, Test Acc: 0.7650, Train Loss: 0.4284, Test Loss: 0.5236\n",
      "Epoch: 680, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4211, Test Loss: 0.5220\n",
      "Epoch: 690, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4155, Test Loss: 0.5239\n",
      "Epoch: 700, Train Acc: 0.8233, Test Acc: 0.7650, Train Loss: 0.4220, Test Loss: 0.5211\n",
      "Epoch: 710, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4193, Test Loss: 0.5234\n",
      "Epoch: 720, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.4157, Test Loss: 0.5217\n",
      "Epoch: 730, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4205, Test Loss: 0.5196\n",
      "Epoch: 740, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4125, Test Loss: 0.5320\n",
      "Epoch: 750, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.4065, Test Loss: 0.5184\n",
      "Epoch: 760, Train Acc: 0.8190, Test Acc: 0.7600, Train Loss: 0.4224, Test Loss: 0.5209\n",
      "Epoch: 770, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.4039, Test Loss: 0.5225\n",
      "Epoch: 780, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4165, Test Loss: 0.5179\n",
      "Epoch: 790, Train Acc: 0.8341, Test Acc: 0.7900, Train Loss: 0.4021, Test Loss: 0.5185\n",
      "Epoch: 800, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3991, Test Loss: 0.5203\n",
      "Epoch: 810, Train Acc: 0.8341, Test Acc: 0.7800, Train Loss: 0.3997, Test Loss: 0.5173\n",
      "Epoch: 820, Train Acc: 0.8341, Test Acc: 0.7900, Train Loss: 0.3994, Test Loss: 0.5181\n",
      "Epoch: 830, Train Acc: 0.8319, Test Acc: 0.7800, Train Loss: 0.4008, Test Loss: 0.5168\n",
      "Epoch: 840, Train Acc: 0.8405, Test Acc: 0.7750, Train Loss: 0.3925, Test Loss: 0.5239\n",
      "Epoch: 850, Train Acc: 0.8341, Test Acc: 0.7900, Train Loss: 0.3956, Test Loss: 0.5175\n",
      "Epoch: 860, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4142, Test Loss: 0.5221\n",
      "Epoch: 870, Train Acc: 0.8341, Test Acc: 0.7850, Train Loss: 0.3945, Test Loss: 0.5162\n",
      "Epoch: 880, Train Acc: 0.8362, Test Acc: 0.7900, Train Loss: 0.3937, Test Loss: 0.5161\n",
      "Epoch: 890, Train Acc: 0.8427, Test Acc: 0.7800, Train Loss: 0.3848, Test Loss: 0.5193\n",
      "Epoch: 900, Train Acc: 0.8448, Test Acc: 0.7850, Train Loss: 0.3846, Test Loss: 0.5163\n",
      "Epoch: 910, Train Acc: 0.8233, Test Acc: 0.7850, Train Loss: 0.4047, Test Loss: 0.5197\n",
      "Epoch: 920, Train Acc: 0.8427, Test Acc: 0.7700, Train Loss: 0.3816, Test Loss: 0.5305\n",
      "Epoch: 930, Train Acc: 0.8427, Test Acc: 0.7650, Train Loss: 0.3785, Test Loss: 0.5326\n",
      "Epoch: 940, Train Acc: 0.8491, Test Acc: 0.8000, Train Loss: 0.3807, Test Loss: 0.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▃▃▅▆▆▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇█████▇</td></tr><tr><td>Test F1</td><td>▃▂▃▃▃▃▃▃▄▂▃▂▂▃▁▄▄▅▅▃▆▇▇▆▇▇▆▆▇▇█▇▆▆███▇██</td></tr><tr><td>Test Loss</td><td>██████▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▂▁▁▂</td></tr><tr><td>Test Sensitivity</td><td>█▇████▆▆▄▂▃▂▂▃▁▃▃▃▄▂▄▅▅▄▅▅▄▄▄▅▅▄▃▄▅▅▅▄▅▅</td></tr><tr><td>Test Specificity</td><td>▁▂▁▁▁▁▃▃▆█▇██▇█▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇███▇▇▇█▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▁▂▁▂▃▄▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇███▇██▇███████</td></tr><tr><td>Train F1</td><td>▂▁▂▂▂▂▃▄▅▂▅▄▄▅▂▅▅▆▆▅▇▇▇▆▇▇▇▇▇▇█▇▇▇▇██▇██</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>█▆████▆▆▄▂▃▃▃▄▁▃▃▄▄▃▅▅▅▄▅▅▄▄▄▅▅▄▄▄▄▅▅▄▅▅</td></tr><tr><td>Train Specificity</td><td>▁▃▁▂▁▂▄▄▇▇▇██▇█▇█▇▇█▇▇▇█▇▇███▇██████▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.795</td></tr><tr><td>Test F1</td><td>0.79803</td></tr><tr><td>Test Loss</td><td>0.51785</td></tr><tr><td>Test Sensitivity</td><td>0.78641</td></tr><tr><td>Test Specificity</td><td>0.80412</td></tr><tr><td>Train Accuracy</td><td>0.84483</td></tr><tr><td>Train F1</td><td>0.84615</td></tr><tr><td>Train Loss</td><td>0.38054</td></tr><tr><td>Train Sensitivity</td><td>0.80488</td></tr><tr><td>Train Specificity</td><td>0.88991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 6 - 942 epochs</strong> at: <a href='https://wandb.ai/dylan-home/train-final-model/runs/aaj9gz0w' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/aaj9gz0w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250626_151528-aaj9gz0w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_name = f'Run 6 - {epochs} epochs'\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = cutoff_distance,\n",
    "            edge_weight_func = edge_weight_func,\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = hidden_channels,\n",
    "            learning_rate = learning_rate,\n",
    "            wd = wd,\n",
    "            dropout = dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= edge_weight_lambda,\n",
    "            early_stop=False,\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': f'{run_name}',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'saved_models/{project}/{run_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
