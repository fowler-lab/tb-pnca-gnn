{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/normed_singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)\n",
    "    \n",
    "print(len(graph_dict['train']) + len(graph_dict['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Best param value ranges from WandB sweeps\n",
    "\n",
    "- Cutoff distance = 11 - 12.5\n",
    "- Dropout = 0.4-0.5\n",
    "- Edge weights = \"exp\"\n",
    "- Edge weight lambda = 2\n",
    "- Hidden channels = 320\n",
    "- Learning rate = 3.5e-5 - 4.5e-5\n",
    "- Weight decay = 1e-6 - 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "cutoff_distance = 12\n",
    "\n",
    "# gcn params - from best wandb sweep\n",
    "num_node_features = 16\n",
    "batch_size = 256\n",
    "hidden_channels = 320\n",
    "dropout = 0.5\n",
    "\n",
    "edge_weight_func = \"exp\"\n",
    "edge_weight_lambda = 2\n",
    "\n",
    "learning_rate = 4e-5\n",
    "wd = 5e-5\n",
    "epochs = 997\n",
    "\n",
    "\n",
    "wt_seq = 'MRALIIVDVQNDFCEGGSLAVTGGAALARAISDYLAEAADYHHVVATKDFHIDPGDHFSGTPDYSSSWPPHCVSGTPGADFHPSLDTSAIEAVFYKGAYTGAYSGFEGVDENGTPLLNWLRQRGVDEVDVVGIATDHCVRQTAEDAVRNGLATRVLVDLTAGVSADTTVAALEEMRTASVELVCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'train-final-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting edge index and attaching edge weights for cutoff distance 12\n",
      "Using CUDA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.20.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250627_160359-pjd6mmnn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/train-final-model/runs/pjd6mmnn' target=\"_blank\">Run 2 - 997 epochs</a></strong> to <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/train-final-model/runs/pjd6mmnn' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/pjd6mmnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 0.5345, Test Acc: 0.4800, Train Loss: 0.6919, Test Loss: 0.6923\n",
      "Epoch: 020, Train Acc: 0.5388, Test Acc: 0.5000, Train Loss: 0.6894, Test Loss: 0.6907\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6884, Test Loss: 0.6905\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6902\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6896\n",
      "Epoch: 060, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6883\n",
      "Epoch: 070, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6845, Test Loss: 0.6874\n",
      "Epoch: 080, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6831, Test Loss: 0.6868\n",
      "Epoch: 090, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6817, Test Loss: 0.6852\n",
      "Epoch: 100, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6804, Test Loss: 0.6843\n",
      "Epoch: 110, Train Acc: 0.5711, Test Acc: 0.5150, Train Loss: 0.6774, Test Loss: 0.6819\n",
      "Epoch: 120, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6747, Test Loss: 0.6801\n",
      "Epoch: 130, Train Acc: 0.5496, Test Acc: 0.5150, Train Loss: 0.6725, Test Loss: 0.6781\n",
      "Epoch: 140, Train Acc: 0.6272, Test Acc: 0.5600, Train Loss: 0.6689, Test Loss: 0.6740\n",
      "Epoch: 150, Train Acc: 0.6444, Test Acc: 0.5750, Train Loss: 0.6645, Test Loss: 0.6702\n",
      "Epoch: 160, Train Acc: 0.6638, Test Acc: 0.6450, Train Loss: 0.6597, Test Loss: 0.6655\n",
      "Epoch: 170, Train Acc: 0.6961, Test Acc: 0.6700, Train Loss: 0.6531, Test Loss: 0.6605\n",
      "Epoch: 180, Train Acc: 0.7091, Test Acc: 0.6900, Train Loss: 0.6466, Test Loss: 0.6546\n",
      "Epoch: 190, Train Acc: 0.7306, Test Acc: 0.6700, Train Loss: 0.6386, Test Loss: 0.6482\n",
      "Epoch: 200, Train Acc: 0.7457, Test Acc: 0.6800, Train Loss: 0.6294, Test Loss: 0.6410\n",
      "Epoch: 210, Train Acc: 0.7457, Test Acc: 0.6850, Train Loss: 0.6211, Test Loss: 0.6336\n",
      "Epoch: 220, Train Acc: 0.7371, Test Acc: 0.6950, Train Loss: 0.6106, Test Loss: 0.6263\n",
      "Epoch: 230, Train Acc: 0.7500, Test Acc: 0.6750, Train Loss: 0.6006, Test Loss: 0.6189\n",
      "Epoch: 240, Train Acc: 0.7565, Test Acc: 0.6800, Train Loss: 0.5909, Test Loss: 0.6115\n",
      "Epoch: 250, Train Acc: 0.7565, Test Acc: 0.7000, Train Loss: 0.5808, Test Loss: 0.6051\n",
      "Epoch: 260, Train Acc: 0.7500, Test Acc: 0.6950, Train Loss: 0.5735, Test Loss: 0.5998\n",
      "Epoch: 270, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5628, Test Loss: 0.5928\n",
      "Epoch: 280, Train Acc: 0.7672, Test Acc: 0.7000, Train Loss: 0.5538, Test Loss: 0.5876\n",
      "Epoch: 290, Train Acc: 0.7672, Test Acc: 0.7000, Train Loss: 0.5441, Test Loss: 0.5827\n",
      "Epoch: 300, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5403, Test Loss: 0.5790\n",
      "Epoch: 310, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5315, Test Loss: 0.5752\n",
      "Epoch: 320, Train Acc: 0.7823, Test Acc: 0.7100, Train Loss: 0.5212, Test Loss: 0.5706\n",
      "Epoch: 330, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5190, Test Loss: 0.5682\n",
      "Epoch: 340, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.5089, Test Loss: 0.5693\n",
      "Epoch: 350, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5099, Test Loss: 0.5633\n",
      "Epoch: 360, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4989, Test Loss: 0.5595\n",
      "Epoch: 370, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.4971, Test Loss: 0.5575\n",
      "Epoch: 380, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4896, Test Loss: 0.5579\n",
      "Epoch: 390, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4899, Test Loss: 0.5530\n",
      "Epoch: 400, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.4833, Test Loss: 0.5516\n",
      "Epoch: 410, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4802, Test Loss: 0.5495\n",
      "Epoch: 420, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4831, Test Loss: 0.5488\n",
      "Epoch: 430, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4779, Test Loss: 0.5464\n",
      "Epoch: 440, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4676, Test Loss: 0.5451\n",
      "Epoch: 450, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4683, Test Loss: 0.5434\n",
      "Epoch: 460, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4637, Test Loss: 0.5456\n",
      "Epoch: 470, Train Acc: 0.8060, Test Acc: 0.7300, Train Loss: 0.4600, Test Loss: 0.5435\n",
      "Epoch: 480, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4599, Test Loss: 0.5409\n",
      "Epoch: 490, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4582, Test Loss: 0.5391\n",
      "Epoch: 500, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4599, Test Loss: 0.5371\n",
      "Epoch: 510, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4514, Test Loss: 0.5371\n",
      "Epoch: 520, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4493, Test Loss: 0.5363\n",
      "Epoch: 530, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4565, Test Loss: 0.5338\n",
      "Epoch: 540, Train Acc: 0.8190, Test Acc: 0.7400, Train Loss: 0.4439, Test Loss: 0.5341\n",
      "Epoch: 550, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4518, Test Loss: 0.5325\n",
      "Epoch: 560, Train Acc: 0.8233, Test Acc: 0.7400, Train Loss: 0.4393, Test Loss: 0.5313\n",
      "Epoch: 570, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4371, Test Loss: 0.5327\n",
      "Epoch: 580, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4488, Test Loss: 0.5309\n",
      "Epoch: 590, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4327, Test Loss: 0.5291\n",
      "Epoch: 600, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.4355, Test Loss: 0.5306\n",
      "Epoch: 610, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4461, Test Loss: 0.5305\n",
      "Epoch: 620, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.4291, Test Loss: 0.5301\n",
      "Epoch: 630, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4268, Test Loss: 0.5252\n",
      "Epoch: 640, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4407, Test Loss: 0.5263\n",
      "Epoch: 650, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4241, Test Loss: 0.5275\n",
      "Epoch: 660, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4264, Test Loss: 0.5227\n",
      "Epoch: 670, Train Acc: 0.8125, Test Acc: 0.7600, Train Loss: 0.4288, Test Loss: 0.5238\n",
      "Epoch: 680, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4211, Test Loss: 0.5220\n",
      "Epoch: 690, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4153, Test Loss: 0.5242\n",
      "Epoch: 700, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4200, Test Loss: 0.5205\n",
      "Epoch: 710, Train Acc: 0.8276, Test Acc: 0.7800, Train Loss: 0.4192, Test Loss: 0.5227\n",
      "Epoch: 720, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.4161, Test Loss: 0.5210\n",
      "Epoch: 730, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4225, Test Loss: 0.5204\n",
      "Epoch: 740, Train Acc: 0.8211, Test Acc: 0.7550, Train Loss: 0.4119, Test Loss: 0.5309\n",
      "Epoch: 750, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.4068, Test Loss: 0.5182\n",
      "Epoch: 760, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4201, Test Loss: 0.5200\n",
      "Epoch: 770, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.4037, Test Loss: 0.5218\n",
      "Epoch: 780, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.4148, Test Loss: 0.5174\n",
      "Epoch: 790, Train Acc: 0.8341, Test Acc: 0.7850, Train Loss: 0.4019, Test Loss: 0.5183\n",
      "Epoch: 800, Train Acc: 0.8362, Test Acc: 0.7800, Train Loss: 0.3986, Test Loss: 0.5208\n",
      "Epoch: 810, Train Acc: 0.8297, Test Acc: 0.7900, Train Loss: 0.3984, Test Loss: 0.5177\n",
      "Epoch: 820, Train Acc: 0.8341, Test Acc: 0.7950, Train Loss: 0.3989, Test Loss: 0.5181\n",
      "Epoch: 830, Train Acc: 0.8319, Test Acc: 0.7800, Train Loss: 0.4003, Test Loss: 0.5166\n",
      "Epoch: 840, Train Acc: 0.8384, Test Acc: 0.7750, Train Loss: 0.3922, Test Loss: 0.5239\n",
      "Epoch: 850, Train Acc: 0.8341, Test Acc: 0.7900, Train Loss: 0.3954, Test Loss: 0.5174\n",
      "Epoch: 860, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4156, Test Loss: 0.5230\n",
      "Epoch: 870, Train Acc: 0.8319, Test Acc: 0.7900, Train Loss: 0.3933, Test Loss: 0.5161\n",
      "Epoch: 880, Train Acc: 0.8384, Test Acc: 0.7900, Train Loss: 0.3935, Test Loss: 0.5161\n",
      "Epoch: 890, Train Acc: 0.8427, Test Acc: 0.7800, Train Loss: 0.3846, Test Loss: 0.5189\n",
      "Epoch: 900, Train Acc: 0.8427, Test Acc: 0.7900, Train Loss: 0.3845, Test Loss: 0.5163\n",
      "Epoch: 910, Train Acc: 0.8276, Test Acc: 0.7850, Train Loss: 0.4064, Test Loss: 0.5208\n",
      "Epoch: 920, Train Acc: 0.8427, Test Acc: 0.7700, Train Loss: 0.3811, Test Loss: 0.5300\n",
      "Epoch: 930, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.3774, Test Loss: 0.5310\n",
      "Epoch: 940, Train Acc: 0.8448, Test Acc: 0.7950, Train Loss: 0.3795, Test Loss: 0.5178\n",
      "Epoch: 950, Train Acc: 0.8513, Test Acc: 0.7900, Train Loss: 0.3766, Test Loss: 0.5188\n",
      "Epoch: 960, Train Acc: 0.8470, Test Acc: 0.7900, Train Loss: 0.3768, Test Loss: 0.5182\n",
      "Epoch: 970, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3869, Test Loss: 0.5186\n",
      "Epoch: 980, Train Acc: 0.8384, Test Acc: 0.7850, Train Loss: 0.3886, Test Loss: 0.5184\n",
      "Epoch: 990, Train Acc: 0.8448, Test Acc: 0.7850, Train Loss: 0.3756, Test Loss: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▄▅▅▅▆▆▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇██▇██</td></tr><tr><td>Test F1</td><td>▃▃▃▃▃▃▃▅▂▂▂▂▃▁▄▃▄▄▃▅▅▅▆▇▅▆▇▇▇▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Test Loss</td><td>█████▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▅▅▂▂▂▂▂▁▃▃▃▃▂▄▄▄▄▅▄▄▅▅▄▄▃▅▅▅▅▄▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▅▅▇▇████▇▇▇▇█▇▇▇▇▇▇▇▇▇███▇▇▇▇█▇▇▇█</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▂▄▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▂▂▅▂▃▄▄▄▂▆▅▆▆▅▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████</td></tr><tr><td>Train Loss</td><td>██████▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██████▅▅▂▃▃▃▃▁▄▃▄▄▃▄▄▄▄▅▄▄▅▅▄▄▄▅▄▅▅▄▅▅▅▅</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▂▅▆▇▇▇▇▇█▇█▇▇█▇███▇██████████▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.8</td></tr><tr><td>Test F1</td><td>0.80198</td></tr><tr><td>Test Loss</td><td>0.51878</td></tr><tr><td>Test Sensitivity</td><td>0.78641</td></tr><tr><td>Test Specificity</td><td>0.81443</td></tr><tr><td>Train Accuracy</td><td>0.84914</td></tr><tr><td>Train F1</td><td>0.84914</td></tr><tr><td>Train Loss</td><td>0.37336</td></tr><tr><td>Train Sensitivity</td><td>0.80081</td></tr><tr><td>Train Specificity</td><td>0.90367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 2 - 997 epochs</strong> at: <a href='https://wandb.ai/dylan-home/train-final-model/runs/pjd6mmnn' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/pjd6mmnn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250627_160359-pjd6mmnn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_name = f'Run 2 - {epochs} epochs'\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = cutoff_distance,\n",
    "            edge_weight_func = edge_weight_func,\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = hidden_channels,\n",
    "            learning_rate = learning_rate,\n",
    "            wd = wd,\n",
    "            dropout = dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= edge_weight_lambda,\n",
    "            early_stop=False,\n",
    "            path= f'saved_models/{project}/{run_name}',\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': f'{run_name}',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, f'saved_models/{project}/{run_name} - 0.80198 Test F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
