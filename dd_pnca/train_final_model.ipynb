{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/normed_singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)\n",
    "# with open('datasets/singletons_af_no_mpfs_graph_dict.pkl', 'rb') as f:\n",
    "#     graph_dict = pkl.load(f)\n",
    "# with open('datasets/singletons_no_af.pkl', 'rb') as f:\n",
    "#     graph_dict = pkl.load(f)\n",
    "    \n",
    "print(len(graph_dict['train']) + len(graph_dict['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Best param value ranges from WandB sweeps\n",
    "\n",
    "- Cutoff distance = 11 - 12.5\n",
    "- Dropout = 0.4-0.5\n",
    "- Edge weights = \"exp\"\n",
    "- Edge weight lambda = 2\n",
    "- Hidden channels = 320\n",
    "- Learning rate = 3.5e-5 - 4.5e-5\n",
    "- Weight decay = 1e-6 - 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "cutoff_distance = 12\n",
    "\n",
    "# gcn params - from best wandb sweep\n",
    "num_node_features = 16\n",
    "batch_size = 256\n",
    "hidden_channels = 320\n",
    "dropout = 0.5\n",
    "\n",
    "edge_weight_func = \"exp\"\n",
    "edge_weight_lambda = 2\n",
    "\n",
    "learning_rate = 4e-5\n",
    "wd = 5e-5\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "wt_seq = 'MRALIIVDVQNDFCEGGSLAVTGGAALARAISDYLAEAADYHHVVATKDFHIDPGDHFSGTPDYSSSWPPHCVSGTPGADFHPSLDTSAIEAVFYKGAYTGAYSGFEGVDENGTPLLNWLRQRGVDEVDVVGIATDHCVRQTAEDAVRNGLATRVLVDLTAGVSADTTVAALEEMRTASVELVCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'train-final-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting edge index and attaching edge weights for cutoff distance 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylan-home\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.20.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250701_165303-aamdxrp5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/train-final-model/runs/aamdxrp5' target=\"_blank\">Shuffle graph - Run 3 - 500 epochs</a></strong> to <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/train-final-model/runs/aamdxrp5' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/aamdxrp5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6927, Test Loss: 0.6929\n",
      "Epoch: 010, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6916, Test Loss: 0.6922\n",
      "Epoch: 020, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6910\n",
      "Epoch: 030, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6843, Test Loss: 0.6912\n",
      "Epoch: 040, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6827, Test Loss: 0.6913\n",
      "Epoch: 050, Train Acc: 0.5496, Test Acc: 0.5000, Train Loss: 0.6811, Test Loss: 0.6908\n",
      "Epoch: 060, Train Acc: 0.5582, Test Acc: 0.4900, Train Loss: 0.6785, Test Loss: 0.6902\n",
      "Epoch: 070, Train Acc: 0.5690, Test Acc: 0.4950, Train Loss: 0.6766, Test Loss: 0.6897\n",
      "Epoch: 080, Train Acc: 0.5582, Test Acc: 0.5000, Train Loss: 0.6730, Test Loss: 0.6897\n",
      "Epoch: 090, Train Acc: 0.5733, Test Acc: 0.4950, Train Loss: 0.6708, Test Loss: 0.6885\n",
      "Epoch: 100, Train Acc: 0.5776, Test Acc: 0.5100, Train Loss: 0.6674, Test Loss: 0.6876\n",
      "Epoch: 110, Train Acc: 0.6142, Test Acc: 0.5300, Train Loss: 0.6617, Test Loss: 0.6856\n",
      "Epoch: 120, Train Acc: 0.6142, Test Acc: 0.5250, Train Loss: 0.6571, Test Loss: 0.6850\n",
      "Epoch: 130, Train Acc: 0.6379, Test Acc: 0.5400, Train Loss: 0.6504, Test Loss: 0.6830\n",
      "Epoch: 140, Train Acc: 0.6983, Test Acc: 0.5600, Train Loss: 0.6438, Test Loss: 0.6796\n",
      "Epoch: 150, Train Acc: 0.7112, Test Acc: 0.5850, Train Loss: 0.6347, Test Loss: 0.6768\n",
      "Epoch: 160, Train Acc: 0.7371, Test Acc: 0.5800, Train Loss: 0.6248, Test Loss: 0.6729\n",
      "Epoch: 170, Train Acc: 0.7392, Test Acc: 0.5900, Train Loss: 0.6138, Test Loss: 0.6697\n",
      "Epoch: 180, Train Acc: 0.7586, Test Acc: 0.6000, Train Loss: 0.6006, Test Loss: 0.6646\n",
      "Epoch: 190, Train Acc: 0.7845, Test Acc: 0.6350, Train Loss: 0.5865, Test Loss: 0.6594\n",
      "Epoch: 200, Train Acc: 0.7866, Test Acc: 0.6400, Train Loss: 0.5720, Test Loss: 0.6540\n",
      "Epoch: 210, Train Acc: 0.7974, Test Acc: 0.6400, Train Loss: 0.5545, Test Loss: 0.6487\n",
      "Epoch: 220, Train Acc: 0.7996, Test Acc: 0.6600, Train Loss: 0.5419, Test Loss: 0.6448\n",
      "Epoch: 230, Train Acc: 0.7996, Test Acc: 0.6400, Train Loss: 0.5255, Test Loss: 0.6411\n",
      "Epoch: 240, Train Acc: 0.8190, Test Acc: 0.6400, Train Loss: 0.5050, Test Loss: 0.6352\n",
      "Epoch: 250, Train Acc: 0.8103, Test Acc: 0.6400, Train Loss: 0.4944, Test Loss: 0.6344\n",
      "Epoch: 260, Train Acc: 0.7888, Test Acc: 0.6300, Train Loss: 0.4827, Test Loss: 0.6356\n",
      "Epoch: 270, Train Acc: 0.8147, Test Acc: 0.6500, Train Loss: 0.4622, Test Loss: 0.6310\n",
      "Epoch: 280, Train Acc: 0.8103, Test Acc: 0.6400, Train Loss: 0.4513, Test Loss: 0.6318\n",
      "Epoch: 290, Train Acc: 0.8405, Test Acc: 0.6550, Train Loss: 0.4288, Test Loss: 0.6273\n",
      "Epoch: 300, Train Acc: 0.8276, Test Acc: 0.6450, Train Loss: 0.4196, Test Loss: 0.6329\n",
      "Epoch: 310, Train Acc: 0.8319, Test Acc: 0.6550, Train Loss: 0.4031, Test Loss: 0.6325\n",
      "Epoch: 320, Train Acc: 0.8599, Test Acc: 0.6550, Train Loss: 0.3849, Test Loss: 0.6321\n",
      "Epoch: 330, Train Acc: 0.8685, Test Acc: 0.6550, Train Loss: 0.3752, Test Loss: 0.6351\n",
      "Epoch: 340, Train Acc: 0.8556, Test Acc: 0.6600, Train Loss: 0.3662, Test Loss: 0.6415\n",
      "Epoch: 350, Train Acc: 0.8556, Test Acc: 0.6550, Train Loss: 0.3622, Test Loss: 0.6528\n",
      "Epoch: 360, Train Acc: 0.8987, Test Acc: 0.6550, Train Loss: 0.3257, Test Loss: 0.6426\n",
      "Epoch: 370, Train Acc: 0.8728, Test Acc: 0.6600, Train Loss: 0.3318, Test Loss: 0.6565\n",
      "Epoch: 380, Train Acc: 0.9159, Test Acc: 0.6600, Train Loss: 0.2977, Test Loss: 0.6528\n",
      "Epoch: 390, Train Acc: 0.8858, Test Acc: 0.6750, Train Loss: 0.3110, Test Loss: 0.6673\n",
      "Epoch: 400, Train Acc: 0.9246, Test Acc: 0.6750, Train Loss: 0.2742, Test Loss: 0.6684\n",
      "Epoch: 410, Train Acc: 0.9095, Test Acc: 0.6550, Train Loss: 0.2861, Test Loss: 0.6761\n",
      "Epoch: 420, Train Acc: 0.9332, Test Acc: 0.6600, Train Loss: 0.2527, Test Loss: 0.6760\n",
      "Epoch: 430, Train Acc: 0.9310, Test Acc: 0.6500, Train Loss: 0.2439, Test Loss: 0.6772\n",
      "Epoch: 440, Train Acc: 0.9418, Test Acc: 0.6600, Train Loss: 0.2275, Test Loss: 0.6889\n",
      "Epoch: 450, Train Acc: 0.9483, Test Acc: 0.6600, Train Loss: 0.2182, Test Loss: 0.6925\n",
      "Epoch: 460, Train Acc: 0.9504, Test Acc: 0.6600, Train Loss: 0.2132, Test Loss: 0.6967\n",
      "Epoch: 470, Train Acc: 0.9504, Test Acc: 0.6500, Train Loss: 0.2059, Test Loss: 0.7039\n",
      "Epoch: 480, Train Acc: 0.9655, Test Acc: 0.6800, Train Loss: 0.1900, Test Loss: 0.7294\n",
      "Epoch: 490, Train Acc: 0.9612, Test Acc: 0.6550, Train Loss: 0.1837, Test Loss: 0.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▂▂▂▁▁▁▁▂▃▃▄▄▅▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇█</td></tr><tr><td>Test F1</td><td>▇▇▇▇▆▆▆▆▆▆▆▆▇▇▆▆▃▃▂▁▁▂▁▃▃▃▃▄▅▄▃█▇▅▇▆▇▅▄▇</td></tr><tr><td>Test Loss</td><td>▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▅▅▆▇▇█</td></tr><tr><td>Test Sensitivity</td><td>████▇▇▇▇▇▇▆▆▆▆▄▃▂▂▁▁▁▁▁▂▂▁▂▂▃▂▂▄▃▃▃▃▄▃▂▃</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▆▇███████████▇██▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▄▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇█▇█</td></tr><tr><td>Train Loss</td><td>██████████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>████████▇▇▇▆▆▆▄▃▂▁▂▁▁▂▁▂▃▂▃▄▅▄▄▆▆▅▆▆▇▆▆▇</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▄▆▆▇▇▇▇▇▇▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.655</td></tr><tr><td>Test F1</td><td>0.66341</td></tr><tr><td>Test Loss</td><td>0.72501</td></tr><tr><td>Test Sensitivity</td><td>0.66019</td></tr><tr><td>Test Specificity</td><td>0.64948</td></tr><tr><td>Train Accuracy</td><td>0.96767</td></tr><tr><td>Train F1</td><td>0.96881</td></tr><tr><td>Train Loss</td><td>0.17546</td></tr><tr><td>Train Sensitivity</td><td>0.94715</td></tr><tr><td>Train Specificity</td><td>0.99083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Shuffle graph - Run 3 - 500 epochs</strong> at: <a href='https://wandb.ai/dylan-home/train-final-model/runs/aamdxrp5' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/aamdxrp5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250701_165303-aamdxrp5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run_name = f'Run 7 - {epochs} epochs - lr {learning_rate}'\n",
    "run_name = f'Shuffle graph - Run 3 - {epochs} epochs'\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = cutoff_distance,\n",
    "            edge_weight_func = edge_weight_func,\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = hidden_channels,\n",
    "            learning_rate = learning_rate,\n",
    "            wd = wd,\n",
    "            dropout = dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= edge_weight_lambda,\n",
    "            early_stop=False,\n",
    "            save_path= f'saved_models/{project}/{run_name}',\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': f'{run_name}',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, f'saved_models/{project}/{run_name} - 0.80198 Test F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
