{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n"
     ]
    }
   ],
   "source": [
    "# with open('datasets/normed_singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "    # graph_dict = pkl.load(f)\n",
    "with open('datasets/x19_exp_l2_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)\n",
    "    \n",
    "print(len(graph_dict['train']) + len(graph_dict['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in graph_dict:\n",
    "    for sample in graph_dict[t]:\n",
    "        col_select = [i for i in range(19) if i != 14]\n",
    "        new_feats = graph_dict[t][sample]['graph'].dataset[0].x[:, col_select]\n",
    "        \n",
    "        graph_dict[t][sample]['graph'].dataset[0].x = new_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Best param value ranges from WandB sweeps\n",
    "\n",
    "- Cutoff distance = 11 - 12.5\n",
    "- Dropout = 0.4-0.5\n",
    "- Edge weights = \"exp\"\n",
    "- Edge weight lambda = 2\n",
    "- Hidden channels = 320\n",
    "- Learning rate = 3.5e-5 - 4.5e-5\n",
    "- Weight decay = 1e-6 - 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "cutoff_distance = 12\n",
    "\n",
    "# gcn params - from best wandb sweep\n",
    "num_node_features = 18\n",
    "batch_size = 256\n",
    "hidden_channels = 256\n",
    "dropout = 0.6\n",
    "\n",
    "edge_weight_func = \"exp\"\n",
    "edge_weight_lambda = 2\n",
    "\n",
    "learning_rate = 4e-5\n",
    "wd = 5e-6\n",
    "epochs = 2000\n",
    "\n",
    "\n",
    "wt_seq = 'MRALIIVDVQNDFCEGGSLAVTGGAALARAISDYLAEAADYHHVVATKDFHIDPGDHFSGTPDYSSSWPPHCVSGTPGADFHPSLDTSAIEAVFYKGAYTGAYSGFEGVDENGTPLLNWLRQRGVDEVDVVGIATDHCVRQTAEDAVRNGLATRVLVDLTAGVSADTTVAALEEMRTASVELVCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'train-final-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_215732-by1qa1tg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/train-final-model/runs/by1qa1tg' target=\"_blank\">18 node feats - Run 5 - 2000 epochs</a></strong> to <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/train-final-model' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/train-final-model/runs/by1qa1tg' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/by1qa1tg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Acc: 0.4935, Test Acc: 0.5200, Train Loss: 0.6933, Test Loss: 0.6931\n",
      "Epoch: 010, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6920\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.4800, Train Loss: 0.6899, Test Loss: 0.6907\n",
      "Epoch: 030, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6876, Test Loss: 0.6898\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6864, Test Loss: 0.6895\n",
      "Epoch: 050, Train Acc: 0.5259, Test Acc: 0.5200, Train Loss: 0.6849, Test Loss: 0.6879\n",
      "Epoch: 060, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6840, Test Loss: 0.6862\n",
      "Epoch: 070, Train Acc: 0.5474, Test Acc: 0.5100, Train Loss: 0.6815, Test Loss: 0.6850\n",
      "Epoch: 080, Train Acc: 0.5797, Test Acc: 0.5150, Train Loss: 0.6793, Test Loss: 0.6827\n",
      "Epoch: 090, Train Acc: 0.5884, Test Acc: 0.5300, Train Loss: 0.6766, Test Loss: 0.6800\n",
      "Epoch: 100, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6722, Test Loss: 0.6779\n",
      "Epoch: 110, Train Acc: 0.5776, Test Acc: 0.5300, Train Loss: 0.6676, Test Loss: 0.6734\n",
      "Epoch: 120, Train Acc: 0.6616, Test Acc: 0.6200, Train Loss: 0.6632, Test Loss: 0.6675\n",
      "Epoch: 130, Train Acc: 0.6746, Test Acc: 0.6100, Train Loss: 0.6554, Test Loss: 0.6621\n",
      "Epoch: 140, Train Acc: 0.7155, Test Acc: 0.6750, Train Loss: 0.6477, Test Loss: 0.6547\n",
      "Epoch: 150, Train Acc: 0.7263, Test Acc: 0.6700, Train Loss: 0.6379, Test Loss: 0.6468\n",
      "Epoch: 160, Train Acc: 0.7371, Test Acc: 0.6950, Train Loss: 0.6274, Test Loss: 0.6383\n",
      "Epoch: 170, Train Acc: 0.7435, Test Acc: 0.6750, Train Loss: 0.6166, Test Loss: 0.6298\n",
      "Epoch: 180, Train Acc: 0.7328, Test Acc: 0.6750, Train Loss: 0.6055, Test Loss: 0.6217\n",
      "Epoch: 190, Train Acc: 0.7565, Test Acc: 0.6900, Train Loss: 0.5931, Test Loss: 0.6130\n",
      "Epoch: 200, Train Acc: 0.7586, Test Acc: 0.6850, Train Loss: 0.5812, Test Loss: 0.6046\n",
      "Epoch: 210, Train Acc: 0.7586, Test Acc: 0.6900, Train Loss: 0.5718, Test Loss: 0.5974\n",
      "Epoch: 220, Train Acc: 0.7629, Test Acc: 0.7050, Train Loss: 0.5596, Test Loss: 0.5906\n",
      "Epoch: 230, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5483, Test Loss: 0.5852\n",
      "Epoch: 240, Train Acc: 0.7608, Test Acc: 0.7050, Train Loss: 0.5437, Test Loss: 0.5802\n",
      "Epoch: 250, Train Acc: 0.7823, Test Acc: 0.7050, Train Loss: 0.5312, Test Loss: 0.5753\n",
      "Epoch: 260, Train Acc: 0.7737, Test Acc: 0.7050, Train Loss: 0.5242, Test Loss: 0.5712\n",
      "Epoch: 270, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.5185, Test Loss: 0.5689\n",
      "Epoch: 280, Train Acc: 0.7565, Test Acc: 0.6950, Train Loss: 0.5164, Test Loss: 0.5673\n",
      "Epoch: 290, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.5084, Test Loss: 0.5615\n",
      "Epoch: 300, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.5018, Test Loss: 0.5593\n",
      "Epoch: 310, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4928, Test Loss: 0.5569\n",
      "Epoch: 320, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.4951, Test Loss: 0.5550\n",
      "Epoch: 330, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4853, Test Loss: 0.5535\n",
      "Epoch: 340, Train Acc: 0.7931, Test Acc: 0.7350, Train Loss: 0.4822, Test Loss: 0.5510\n",
      "Epoch: 350, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.4931, Test Loss: 0.5537\n",
      "Epoch: 360, Train Acc: 0.7996, Test Acc: 0.7500, Train Loss: 0.4730, Test Loss: 0.5490\n",
      "Epoch: 370, Train Acc: 0.7909, Test Acc: 0.7200, Train Loss: 0.4727, Test Loss: 0.5456\n",
      "Epoch: 380, Train Acc: 0.7953, Test Acc: 0.7200, Train Loss: 0.4704, Test Loss: 0.5439\n",
      "Epoch: 390, Train Acc: 0.8060, Test Acc: 0.7450, Train Loss: 0.4649, Test Loss: 0.5457\n",
      "Epoch: 400, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4598, Test Loss: 0.5418\n",
      "Epoch: 410, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.4682, Test Loss: 0.5433\n",
      "Epoch: 420, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4538, Test Loss: 0.5398\n",
      "Epoch: 430, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.4572, Test Loss: 0.5390\n",
      "Epoch: 440, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4599, Test Loss: 0.5377\n",
      "Epoch: 450, Train Acc: 0.8147, Test Acc: 0.7300, Train Loss: 0.4489, Test Loss: 0.5341\n",
      "Epoch: 460, Train Acc: 0.8190, Test Acc: 0.7350, Train Loss: 0.4439, Test Loss: 0.5331\n",
      "Epoch: 470, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4486, Test Loss: 0.5338\n",
      "Epoch: 480, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4359, Test Loss: 0.5329\n",
      "Epoch: 490, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4412, Test Loss: 0.5294\n",
      "Epoch: 500, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4376, Test Loss: 0.5285\n",
      "Epoch: 510, Train Acc: 0.8125, Test Acc: 0.7600, Train Loss: 0.4316, Test Loss: 0.5325\n",
      "Epoch: 520, Train Acc: 0.8190, Test Acc: 0.7400, Train Loss: 0.4314, Test Loss: 0.5274\n",
      "Epoch: 530, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4256, Test Loss: 0.5280\n",
      "Epoch: 540, Train Acc: 0.8233, Test Acc: 0.7400, Train Loss: 0.4310, Test Loss: 0.5258\n",
      "Epoch: 550, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4260, Test Loss: 0.5256\n",
      "Epoch: 560, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4229, Test Loss: 0.5236\n",
      "Epoch: 570, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4253, Test Loss: 0.5227\n",
      "Epoch: 580, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.4160, Test Loss: 0.5261\n",
      "Epoch: 590, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4132, Test Loss: 0.5218\n",
      "Epoch: 600, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4234, Test Loss: 0.5220\n",
      "Epoch: 610, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4130, Test Loss: 0.5201\n",
      "Epoch: 620, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4091, Test Loss: 0.5201\n",
      "Epoch: 630, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4054, Test Loss: 0.5215\n",
      "Epoch: 640, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4045, Test Loss: 0.5230\n",
      "Epoch: 650, Train Acc: 0.8297, Test Acc: 0.7450, Train Loss: 0.4228, Test Loss: 0.5256\n",
      "Epoch: 660, Train Acc: 0.8190, Test Acc: 0.7750, Train Loss: 0.4018, Test Loss: 0.5293\n",
      "Epoch: 670, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.3996, Test Loss: 0.5169\n",
      "Epoch: 680, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3966, Test Loss: 0.5171\n",
      "Epoch: 690, Train Acc: 0.8341, Test Acc: 0.7800, Train Loss: 0.3957, Test Loss: 0.5214\n",
      "Epoch: 700, Train Acc: 0.8384, Test Acc: 0.7650, Train Loss: 0.3944, Test Loss: 0.5173\n",
      "Epoch: 710, Train Acc: 0.8233, Test Acc: 0.7850, Train Loss: 0.3907, Test Loss: 0.5258\n",
      "Epoch: 720, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4082, Test Loss: 0.5240\n",
      "Epoch: 730, Train Acc: 0.8233, Test Acc: 0.7800, Train Loss: 0.3908, Test Loss: 0.5268\n",
      "Epoch: 740, Train Acc: 0.8427, Test Acc: 0.7850, Train Loss: 0.3851, Test Loss: 0.5191\n",
      "Epoch: 750, Train Acc: 0.8384, Test Acc: 0.7750, Train Loss: 0.3975, Test Loss: 0.5168\n",
      "Epoch: 760, Train Acc: 0.8427, Test Acc: 0.7650, Train Loss: 0.3871, Test Loss: 0.5163\n",
      "Epoch: 770, Train Acc: 0.8448, Test Acc: 0.7650, Train Loss: 0.3872, Test Loss: 0.5167\n",
      "Epoch: 780, Train Acc: 0.8448, Test Acc: 0.7800, Train Loss: 0.3830, Test Loss: 0.5189\n",
      "Epoch: 790, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.3862, Test Loss: 0.5442\n",
      "Epoch: 800, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4161, Test Loss: 0.5289\n",
      "Epoch: 810, Train Acc: 0.8362, Test Acc: 0.7900, Train Loss: 0.3767, Test Loss: 0.5277\n",
      "Epoch: 820, Train Acc: 0.8448, Test Acc: 0.7800, Train Loss: 0.3788, Test Loss: 0.5164\n",
      "Epoch: 830, Train Acc: 0.8448, Test Acc: 0.7850, Train Loss: 0.3761, Test Loss: 0.5167\n",
      "Epoch: 840, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.3766, Test Loss: 0.5412\n",
      "Epoch: 850, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4382, Test Loss: 0.5491\n",
      "Epoch: 860, Train Acc: 0.8491, Test Acc: 0.8000, Train Loss: 0.3667, Test Loss: 0.5220\n",
      "Epoch: 870, Train Acc: 0.8470, Test Acc: 0.7950, Train Loss: 0.3755, Test Loss: 0.5163\n",
      "Epoch: 880, Train Acc: 0.8491, Test Acc: 0.8000, Train Loss: 0.3601, Test Loss: 0.5258\n",
      "Epoch: 890, Train Acc: 0.8491, Test Acc: 0.7750, Train Loss: 0.3765, Test Loss: 0.5197\n",
      "Epoch: 900, Train Acc: 0.8534, Test Acc: 0.7850, Train Loss: 0.3570, Test Loss: 0.5210\n",
      "Epoch: 910, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3603, Test Loss: 0.5380\n",
      "Epoch: 920, Train Acc: 0.8513, Test Acc: 0.7850, Train Loss: 0.3590, Test Loss: 0.5205\n",
      "Epoch: 930, Train Acc: 0.8556, Test Acc: 0.7900, Train Loss: 0.3543, Test Loss: 0.5240\n",
      "Epoch: 940, Train Acc: 0.8578, Test Acc: 0.8000, Train Loss: 0.3510, Test Loss: 0.5247\n",
      "Epoch: 950, Train Acc: 0.8491, Test Acc: 0.7800, Train Loss: 0.3545, Test Loss: 0.5331\n",
      "Epoch: 960, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.3918, Test Loss: 0.5367\n",
      "Epoch: 970, Train Acc: 0.8599, Test Acc: 0.7850, Train Loss: 0.3567, Test Loss: 0.5210\n",
      "Epoch: 980, Train Acc: 0.8513, Test Acc: 0.7800, Train Loss: 0.3537, Test Loss: 0.5366\n",
      "Epoch: 990, Train Acc: 0.8578, Test Acc: 0.7850, Train Loss: 0.3471, Test Loss: 0.5237\n",
      "Epoch: 1000, Train Acc: 0.8642, Test Acc: 0.7950, Train Loss: 0.3396, Test Loss: 0.5253\n",
      "Epoch: 1010, Train Acc: 0.8621, Test Acc: 0.7750, Train Loss: 0.3570, Test Loss: 0.5257\n",
      "Epoch: 1020, Train Acc: 0.8599, Test Acc: 0.7950, Train Loss: 0.3439, Test Loss: 0.5392\n",
      "Epoch: 1030, Train Acc: 0.8642, Test Acc: 0.7950, Train Loss: 0.3397, Test Loss: 0.5241\n",
      "Epoch: 1040, Train Acc: 0.8707, Test Acc: 0.7850, Train Loss: 0.3487, Test Loss: 0.5246\n",
      "Epoch: 1050, Train Acc: 0.8664, Test Acc: 0.7950, Train Loss: 0.3359, Test Loss: 0.5258\n",
      "Epoch: 1060, Train Acc: 0.8685, Test Acc: 0.7900, Train Loss: 0.3331, Test Loss: 0.5252\n",
      "Epoch: 1070, Train Acc: 0.8534, Test Acc: 0.7350, Train Loss: 0.3472, Test Loss: 0.5626\n",
      "Epoch: 1080, Train Acc: 0.8621, Test Acc: 0.7950, Train Loss: 0.3270, Test Loss: 0.5316\n",
      "Epoch: 1090, Train Acc: 0.8664, Test Acc: 0.7950, Train Loss: 0.3272, Test Loss: 0.5315\n",
      "Epoch: 1100, Train Acc: 0.8707, Test Acc: 0.7900, Train Loss: 0.3315, Test Loss: 0.5269\n",
      "Epoch: 1110, Train Acc: 0.8750, Test Acc: 0.7950, Train Loss: 0.3232, Test Loss: 0.5318\n",
      "Epoch: 1120, Train Acc: 0.8685, Test Acc: 0.7950, Train Loss: 0.3182, Test Loss: 0.5433\n",
      "Epoch: 1130, Train Acc: 0.8793, Test Acc: 0.7850, Train Loss: 0.3269, Test Loss: 0.5295\n",
      "Epoch: 1140, Train Acc: 0.8793, Test Acc: 0.7950, Train Loss: 0.3214, Test Loss: 0.5341\n",
      "Epoch: 1150, Train Acc: 0.8793, Test Acc: 0.7850, Train Loss: 0.3241, Test Loss: 0.5335\n",
      "Epoch: 1160, Train Acc: 0.8707, Test Acc: 0.8000, Train Loss: 0.3167, Test Loss: 0.5400\n",
      "Epoch: 1170, Train Acc: 0.8685, Test Acc: 0.7850, Train Loss: 0.3286, Test Loss: 0.5339\n",
      "Epoch: 1180, Train Acc: 0.8728, Test Acc: 0.7950, Train Loss: 0.3157, Test Loss: 0.5458\n",
      "Epoch: 1190, Train Acc: 0.8793, Test Acc: 0.7650, Train Loss: 0.3185, Test Loss: 0.5566\n",
      "Epoch: 1200, Train Acc: 0.8664, Test Acc: 0.7750, Train Loss: 0.3294, Test Loss: 0.5403\n",
      "Epoch: 1210, Train Acc: 0.8685, Test Acc: 0.7800, Train Loss: 0.3219, Test Loss: 0.5372\n",
      "Epoch: 1220, Train Acc: 0.8815, Test Acc: 0.7600, Train Loss: 0.3087, Test Loss: 0.5558\n",
      "Epoch: 1230, Train Acc: 0.8858, Test Acc: 0.7850, Train Loss: 0.3113, Test Loss: 0.5368\n",
      "Epoch: 1240, Train Acc: 0.8836, Test Acc: 0.7850, Train Loss: 0.3058, Test Loss: 0.5373\n",
      "Epoch: 1250, Train Acc: 0.8642, Test Acc: 0.7500, Train Loss: 0.3218, Test Loss: 0.5801\n",
      "Epoch: 1260, Train Acc: 0.8879, Test Acc: 0.7850, Train Loss: 0.3033, Test Loss: 0.5395\n",
      "Epoch: 1270, Train Acc: 0.8922, Test Acc: 0.7900, Train Loss: 0.3013, Test Loss: 0.5448\n",
      "Epoch: 1280, Train Acc: 0.8922, Test Acc: 0.7850, Train Loss: 0.2979, Test Loss: 0.5445\n",
      "Epoch: 1290, Train Acc: 0.9052, Test Acc: 0.7850, Train Loss: 0.2951, Test Loss: 0.5495\n",
      "Epoch: 1300, Train Acc: 0.8685, Test Acc: 0.7500, Train Loss: 0.3106, Test Loss: 0.5842\n",
      "Epoch: 1310, Train Acc: 0.8707, Test Acc: 0.7500, Train Loss: 0.2990, Test Loss: 0.5736\n",
      "Epoch: 1320, Train Acc: 0.7953, Test Acc: 0.6750, Train Loss: 0.3753, Test Loss: 0.6756\n",
      "Epoch: 1330, Train Acc: 0.9052, Test Acc: 0.7800, Train Loss: 0.2916, Test Loss: 0.5546\n",
      "Epoch: 1340, Train Acc: 0.8944, Test Acc: 0.7800, Train Loss: 0.2891, Test Loss: 0.5502\n",
      "Epoch: 1350, Train Acc: 0.8728, Test Acc: 0.7750, Train Loss: 0.3013, Test Loss: 0.5509\n",
      "Epoch: 1360, Train Acc: 0.8901, Test Acc: 0.7750, Train Loss: 0.2858, Test Loss: 0.5503\n",
      "Epoch: 1370, Train Acc: 0.9030, Test Acc: 0.7850, Train Loss: 0.2824, Test Loss: 0.5539\n",
      "Epoch: 1380, Train Acc: 0.9052, Test Acc: 0.7800, Train Loss: 0.2804, Test Loss: 0.5569\n",
      "Epoch: 1390, Train Acc: 0.8750, Test Acc: 0.7550, Train Loss: 0.2913, Test Loss: 0.5895\n",
      "Epoch: 1400, Train Acc: 0.9116, Test Acc: 0.7800, Train Loss: 0.2740, Test Loss: 0.5608\n",
      "Epoch: 1410, Train Acc: 0.8944, Test Acc: 0.7550, Train Loss: 0.2839, Test Loss: 0.5828\n",
      "Epoch: 1420, Train Acc: 0.8793, Test Acc: 0.7550, Train Loss: 0.2869, Test Loss: 0.5957\n",
      "Epoch: 1430, Train Acc: 0.9030, Test Acc: 0.7550, Train Loss: 0.2823, Test Loss: 0.5863\n",
      "Epoch: 1440, Train Acc: 0.9030, Test Acc: 0.7550, Train Loss: 0.2752, Test Loss: 0.5811\n",
      "Epoch: 1450, Train Acc: 0.8922, Test Acc: 0.7550, Train Loss: 0.2826, Test Loss: 0.5915\n",
      "Epoch: 1460, Train Acc: 0.9009, Test Acc: 0.7550, Train Loss: 0.2788, Test Loss: 0.5926\n",
      "Epoch: 1470, Train Acc: 0.9138, Test Acc: 0.7750, Train Loss: 0.2671, Test Loss: 0.5671\n",
      "Epoch: 1480, Train Acc: 0.9030, Test Acc: 0.7750, Train Loss: 0.2703, Test Loss: 0.5609\n",
      "Epoch: 1490, Train Acc: 0.8815, Test Acc: 0.7750, Train Loss: 0.3066, Test Loss: 0.5725\n",
      "Epoch: 1500, Train Acc: 0.9009, Test Acc: 0.7700, Train Loss: 0.2696, Test Loss: 0.5615\n",
      "Epoch: 1510, Train Acc: 0.9116, Test Acc: 0.7700, Train Loss: 0.2604, Test Loss: 0.5741\n",
      "Epoch: 1520, Train Acc: 0.9073, Test Acc: 0.7750, Train Loss: 0.2617, Test Loss: 0.5647\n",
      "Epoch: 1530, Train Acc: 0.9073, Test Acc: 0.7650, Train Loss: 0.2632, Test Loss: 0.5885\n",
      "Epoch: 1540, Train Acc: 0.9009, Test Acc: 0.7500, Train Loss: 0.2650, Test Loss: 0.6002\n",
      "Epoch: 1550, Train Acc: 0.8987, Test Acc: 0.7500, Train Loss: 0.2673, Test Loss: 0.6076\n",
      "Epoch: 1560, Train Acc: 0.9203, Test Acc: 0.7750, Train Loss: 0.2516, Test Loss: 0.5714\n",
      "Epoch: 1570, Train Acc: 0.9181, Test Acc: 0.7750, Train Loss: 0.2537, Test Loss: 0.5845\n",
      "Epoch: 1580, Train Acc: 0.9181, Test Acc: 0.7650, Train Loss: 0.2501, Test Loss: 0.5848\n",
      "Epoch: 1590, Train Acc: 0.9073, Test Acc: 0.7750, Train Loss: 0.2556, Test Loss: 0.5699\n",
      "Epoch: 1600, Train Acc: 0.8599, Test Acc: 0.7150, Train Loss: 0.2975, Test Loss: 0.6675\n",
      "Epoch: 1610, Train Acc: 0.9095, Test Acc: 0.7750, Train Loss: 0.2551, Test Loss: 0.5708\n",
      "Epoch: 1620, Train Acc: 0.9159, Test Acc: 0.7700, Train Loss: 0.2493, Test Loss: 0.5752\n",
      "Epoch: 1630, Train Acc: 0.9246, Test Acc: 0.7700, Train Loss: 0.2405, Test Loss: 0.5806\n",
      "Epoch: 1640, Train Acc: 0.9095, Test Acc: 0.7650, Train Loss: 0.2518, Test Loss: 0.5788\n",
      "Epoch: 1650, Train Acc: 0.9159, Test Acc: 0.7750, Train Loss: 0.2421, Test Loss: 0.5982\n",
      "Epoch: 1660, Train Acc: 0.9052, Test Acc: 0.7350, Train Loss: 0.2568, Test Loss: 0.6255\n",
      "Epoch: 1670, Train Acc: 0.9289, Test Acc: 0.7700, Train Loss: 0.2374, Test Loss: 0.5830\n",
      "Epoch: 1680, Train Acc: 0.9181, Test Acc: 0.7700, Train Loss: 0.2381, Test Loss: 0.5833\n",
      "Epoch: 1690, Train Acc: 0.8922, Test Acc: 0.7350, Train Loss: 0.2673, Test Loss: 0.6563\n",
      "Epoch: 1700, Train Acc: 0.8987, Test Acc: 0.7350, Train Loss: 0.2568, Test Loss: 0.6410\n",
      "Epoch: 1710, Train Acc: 0.9310, Test Acc: 0.7700, Train Loss: 0.2277, Test Loss: 0.5880\n",
      "Epoch: 1720, Train Acc: 0.9073, Test Acc: 0.7300, Train Loss: 0.2458, Test Loss: 0.6311\n",
      "Epoch: 1730, Train Acc: 0.9138, Test Acc: 0.7700, Train Loss: 0.2332, Test Loss: 0.6093\n",
      "Epoch: 1740, Train Acc: 0.8987, Test Acc: 0.7300, Train Loss: 0.2571, Test Loss: 0.6557\n",
      "Epoch: 1750, Train Acc: 0.9181, Test Acc: 0.7750, Train Loss: 0.2365, Test Loss: 0.5894\n",
      "Epoch: 1760, Train Acc: 0.9073, Test Acc: 0.7300, Train Loss: 0.2466, Test Loss: 0.6519\n",
      "Epoch: 1770, Train Acc: 0.9246, Test Acc: 0.7700, Train Loss: 0.2285, Test Loss: 0.5914\n",
      "Epoch: 1780, Train Acc: 0.9224, Test Acc: 0.7700, Train Loss: 0.2280, Test Loss: 0.5919\n",
      "Epoch: 1790, Train Acc: 0.8944, Test Acc: 0.7200, Train Loss: 0.2534, Test Loss: 0.6680\n",
      "Epoch: 1800, Train Acc: 0.9246, Test Acc: 0.7700, Train Loss: 0.2185, Test Loss: 0.6159\n",
      "Epoch: 1810, Train Acc: 0.9289, Test Acc: 0.7650, Train Loss: 0.2218, Test Loss: 0.5966\n",
      "Epoch: 1820, Train Acc: 0.9030, Test Acc: 0.7750, Train Loss: 0.2490, Test Loss: 0.6096\n",
      "Epoch: 1830, Train Acc: 0.8858, Test Acc: 0.7650, Train Loss: 0.2779, Test Loss: 0.6278\n",
      "Epoch: 1840, Train Acc: 0.9332, Test Acc: 0.7650, Train Loss: 0.2141, Test Loss: 0.6124\n",
      "Epoch: 1850, Train Acc: 0.9181, Test Acc: 0.7450, Train Loss: 0.2250, Test Loss: 0.6493\n",
      "Epoch: 1860, Train Acc: 0.9267, Test Acc: 0.7550, Train Loss: 0.2143, Test Loss: 0.6352\n",
      "Epoch: 1870, Train Acc: 0.9203, Test Acc: 0.7300, Train Loss: 0.2281, Test Loss: 0.6544\n",
      "Epoch: 1880, Train Acc: 0.9353, Test Acc: 0.7650, Train Loss: 0.2050, Test Loss: 0.6196\n",
      "Epoch: 1890, Train Acc: 0.9332, Test Acc: 0.7650, Train Loss: 0.2061, Test Loss: 0.6200\n",
      "Epoch: 1900, Train Acc: 0.9332, Test Acc: 0.7750, Train Loss: 0.2028, Test Loss: 0.6135\n",
      "Epoch: 1910, Train Acc: 0.9310, Test Acc: 0.7700, Train Loss: 0.2047, Test Loss: 0.6310\n",
      "Epoch: 1920, Train Acc: 0.9332, Test Acc: 0.7650, Train Loss: 0.1981, Test Loss: 0.6216\n",
      "Epoch: 1930, Train Acc: 0.8815, Test Acc: 0.7100, Train Loss: 0.2681, Test Loss: 0.7380\n",
      "Epoch: 1940, Train Acc: 0.9289, Test Acc: 0.7650, Train Loss: 0.2106, Test Loss: 0.6142\n",
      "Epoch: 1950, Train Acc: 0.9310, Test Acc: 0.7700, Train Loss: 0.2079, Test Loss: 0.6165\n",
      "Epoch: 1960, Train Acc: 0.9332, Test Acc: 0.7700, Train Loss: 0.2007, Test Loss: 0.6156\n",
      "Epoch: 1970, Train Acc: 0.9353, Test Acc: 0.7650, Train Loss: 0.1923, Test Loss: 0.6199\n",
      "Epoch: 1980, Train Acc: 0.9353, Test Acc: 0.7650, Train Loss: 0.1920, Test Loss: 0.6209\n",
      "Epoch: 1990, Train Acc: 0.9332, Test Acc: 0.7650, Train Loss: 0.1886, Test Loss: 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▅▅▆▅▇▆▆▇▆▇▇▇██████▆██▇███▆▆▇▇▇▇▇▅▇▇▆▆</td></tr><tr><td>Test F1</td><td>▂▂▂▃▁▂▁▅▄▄▇▃▆▅▆▇█▇▇▇█▆█▇▇▇▇▇▅▅▇▆▆▇▇▄▇▇▅▅</td></tr><tr><td>Test Loss</td><td>▅▅▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▄▄▂▃▃▃▃█▃▄▅▅</td></tr><tr><td>Test Sensitivity</td><td>██▇▃▁▂▁▃▃▂▅▂▄▂▃▄▅▄▄▄▅▅▅▄▅▄▄▄▅▅▄▅▃▄▅▆▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>▁▁▂▇▇▇█▇▇█▇█▇██▇▇▇▇█▇▆▇█▇█▇▇▆▆▇▇█▇▇▄▇▇▆▆</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇██▆▇█▇▇██▆████</td></tr><tr><td>Train F1</td><td>▁▁▂▃▃▃▃▅▄▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▆▆█▇▇██▅████</td></tr><tr><td>Train Loss</td><td>███▇▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▁▁▃▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██▇▂▂▂▁▄▃▃▄▂▄▃▃▄▅▄▅▄▅▆▅▄▆▄▅▅▇▇▆▆▄▆▆▇▆▆▇▇</td></tr><tr><td>Train Specificity</td><td>▁▁▂▆▇▇▇▇▇▇▇█▇█▇▇▇▇▇█▇▇▇█▇███▆▇█▇███▅██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.765</td></tr><tr><td>Test F1</td><td>0.77725</td></tr><tr><td>Test Loss</td><td>0.64293</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.73196</td></tr><tr><td>Train Accuracy</td><td>0.94181</td></tr><tr><td>Train F1</td><td>0.94433</td></tr><tr><td>Train Loss</td><td>0.19398</td></tr><tr><td>Train Sensitivity</td><td>0.93089</td></tr><tr><td>Train Specificity</td><td>0.95413</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">18 node feats - Run 5 - 2000 epochs</strong> at: <a href='https://wandb.ai/dylan-home/train-final-model/runs/by1qa1tg' target=\"_blank\">https://wandb.ai/dylan-home/train-final-model/runs/by1qa1tg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_215732-by1qa1tg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run_name = f'Run 7 - {epochs} epochs - lr {learning_rate}'\n",
    "run_name = f'18 node feats - Run 5 - {epochs} epochs'\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = cutoff_distance,\n",
    "            edge_weight_func = edge_weight_func,\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = hidden_channels,\n",
    "            learning_rate = learning_rate,\n",
    "            wd = wd,\n",
    "            dropout = dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= edge_weight_lambda,\n",
    "            early_stop=False,\n",
    "            # no_node_chem_feats=True,\n",
    "            save_path= f'saved_models/{project}/{run_name}',\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': f'{run_name}',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, f'saved_models/{project}/{run_name} - 0.80198 Test F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[185, 18], edge_index=[2, 5452], edge_attr=[5452, 1], y=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dict['train']['pnca_mut_0']['graph'].dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
