{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PncA WandB Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running via SSH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "if \"SSH_CONNECTION\" in os.environ:\n",
    "    display(\"Running via SSH\")\n",
    "else:\n",
    "    display(\"Running locally\")\n",
    "    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.join('..', '/Users/dylandissanayake/Desktop/DPhil/Comp Disc/Repositories/TB-PNCA-GNN') if \"SSH_CONNECTION\" not in os.environ else os.path.join('..', '/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(os.path.abspath(path))\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import run_model, protein_graph, gcn_model, evaluation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%aimport src\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('datasets/singletons_af_graph_dict.pkl', 'rb') as f:\n",
    "#     graph_dict = pkl.load(f)\n",
    "# with open('datasets/singletons_af_w_pza_graph_dict.pkl', 'rb') as f:\n",
    "#     graph_dict = pkl.load(f)\n",
    "# with open('datasets/singletons_af_no_mut_feats_graph_dict.pkl', 'rb') as f:\n",
    "#     graph_dict = pkl.load(f)\n",
    "\n",
    "with open('datasets/x19_exp_l2_graph_dict.pkl', 'rb') as f:\n",
    "    graph_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_dict['train']) + len(graph_dict['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Params and Sweep Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# logging params (only used for wandb metrics)\n",
    "n_samples = len(graph_dict['train']) + len(graph_dict['test'])\n",
    "# cutoff_distance = 6.3  \n",
    "\n",
    "# gcn params\n",
    "# num_node_features = 16\n",
    "num_node_features = 19\n",
    "batch_size = 256\n",
    "# hidden_channels = 64\n",
    "# learning_rate = 0.001\n",
    "# wd = 5e-5\n",
    "epochs = 2000\n",
    "\n",
    "wt_seq = 'MRALIIVDVQNDFCEGGSLAVTGGAALARAISDYLAEAADYHHVVATKDFHIDPGDHFSGTPDYSSSWPPHCVSGTPGADFHPSLDTSAIEAVFYKGAYTGAYSGFEGVDENGTPLLNWLRQRGVDEVDVVGIATDHCVRQTAEDAVRNGLATRVLVDLTAGVSADTTVAALEEMRTASVELVCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First sweep:\n",
    "\n",
    "# sweep_config = {\n",
    "#     'method': 'random'\n",
    "#     }\n",
    "\n",
    "# metric = {\n",
    "#     'name': 'Test Accuracy',\n",
    "#     'goal': 'maximize'   \n",
    "#     }\n",
    "\n",
    "# sweep_config['metric'] = metric\n",
    "\n",
    "# parameters_dict = {\n",
    "#     'hidden_channels': {\n",
    "#         'values': [64, 128, 192, 256, 320, 384]\n",
    "#         },\n",
    "#     'weight_decay': {\n",
    "#         'distribution': 'log_uniform_values',\n",
    "#         'min': 1e-8,\n",
    "#         'max': 1e-2\n",
    "#         },\n",
    "#     'dropout': {\n",
    "#           'values': [0.2, 0.4, 0.5, 0.6, 0.8]\n",
    "#         },\n",
    "#     'cutoff_distance': {\n",
    "#         'distribution': 'uniform',\n",
    "#         'min': 4,\n",
    "#         'max': 12 \n",
    "#         },\n",
    "#     'learning_rate': {\n",
    "#         'distribution': 'log_uniform_values',\n",
    "#         'min': 1e-8,\n",
    "#         'max': 1e-1\n",
    "#       },\n",
    "#     }\n",
    "\n",
    "# sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "# # Second sweep:\n",
    "\n",
    "# parameters_dict.update({\n",
    "#     'learning_rate': {\n",
    "#         'distribution': 'log_uniform_values',\n",
    "#         'min': 1e-5,\n",
    "#         'max': 1e-2 \n",
    "#         },\n",
    "#     'hidden_channels': {\n",
    "#         'values': [128, 192, 256, 320, 384]\n",
    "#         },\n",
    "#     })\n",
    "\n",
    "# # Third sweep:\n",
    "\n",
    "# parameters_dict.update({\n",
    "#     'learning_rate': {\n",
    "#         'distribution': 'log_uniform_values',\n",
    "#         'min': 1e-5,\n",
    "#         'max': 1e-3 \n",
    "#         },\n",
    "#     'edge_weights': {\n",
    "#         'values': [\"dist\", \"1-(dist/cutoff)\", \"1/dist\"]\n",
    "#         },\n",
    "#     })\n",
    "\n",
    "# # Fourth sweep:\n",
    "\n",
    "# parameters_dict.update({\n",
    "#     'edge_weights': {\n",
    "#         'values': [\"dist\", \"1-(dist/cutoff)\", \"1/dist\", \"l=0.1\", \"l=0.2\", \"l=0.3\", \"l=0.4\", \"l=0.5\", \"l=0.8\", \"l=1.0\", \"l=1.2\", \"l=1.5\", \"l=2.0\"]\n",
    "#         },\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "'method': 'random'\n",
    "}\n",
    "\n",
    "metric = {\n",
    "    'name': 'Test Accuracy',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'hidden_channels': {\n",
    "        'values': [128, 192, 256, 320, 384]\n",
    "        },\n",
    "    'weight_decay': {\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-8,\n",
    "        'max': 1e-2\n",
    "        },\n",
    "    'dropout': {\n",
    "        'values': [0.2, 0.4, 0.5, 0.6, 0.8]\n",
    "        },\n",
    "    # 'cutoff_distance': {\n",
    "    #     'distribution': 'uniform',\n",
    "    #     'min': 6,\n",
    "    #     'max': 15 \n",
    "    #     },\n",
    "    'learning_rate': {\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-6,\n",
    "        'max': 1e-2\n",
    "    },\n",
    "    # 'lambda_param': {\n",
    "    #     'values': [0.2, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "    #     },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'Test Accuracy'},\n",
      " 'parameters': {'dropout': {'values': [0.2, 0.4, 0.5, 0.6, 0.8]},\n",
      "                'hidden_channels': {'values': [128, 192, 256, 320, 384]},\n",
      "                'learning_rate': {'distribution': 'log_uniform_values',\n",
      "                                  'max': 0.01,\n",
      "                                  'min': 1e-06},\n",
      "                'weight_decay': {'distribution': 'log_uniform_values',\n",
      "                                 'max': 0.01,\n",
      "                                 'min': 1e-08}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project = \"pnca-af-singletons-sweep-w-mutation-feats\"\n",
    "# project = \"pnca-af-singletons-sweep-NO-mutation-feats\"\n",
    "# project = \"pnca-af-singletons-sweep-w-mutation-feats-exp-edge-weights\"\n",
    "\n",
    "project = \"19-node-feats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: uuv8rla0\n",
      "Sweep URL: https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=project)\n",
    "## project 1\n",
    "# sweep_id = 'x0k5kbpt'\n",
    "# sweep_id = 'mnkuowkk'\n",
    "# sweep_id = 'jp3xzyp5'\n",
    "#! sweeps from here include proper pza distance\n",
    "# sweep_id = '9b3bkt5y'\n",
    "# sweep_id = 'w1bgy5pd'\n",
    "# sweep_id = 'r7865la3'\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_config, project=project)\n",
    "# sweep_id = 'fypk3i0y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = \"dylan-home/19-node-feats/431g130a\"\n",
    "# api = wandb.Api()\n",
    "# best_conf = api.run(run_path).config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.6,\n",
       " 'lambda_param': 2,\n",
       " 'weight_decay': 0.004281527452568532,\n",
       " 'learning_rate': 0.0005,\n",
       " 'cutoff_distance': 11.74916595319417,\n",
       " 'hidden_channels': 320}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_conf['learning_rate'] = 5e-4\n",
    "\n",
    "# best_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting edge index and attaching edge weights for cutoff distance 11.74916595319417\n",
      "Using CUDA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_111352-8z19v2ee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/8z19v2ee' target=\"_blank\">run 5 light GraphNorm1+2</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/8z19v2ee' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/8z19v2ee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7103, Test Loss: 0.7182\n",
      "Epoch: 010, Train Acc: 0.5948, Test Acc: 0.5900, Train Loss: 0.6782, Test Loss: 0.6767\n",
      "Epoch: 020, Train Acc: 0.6897, Test Acc: 0.6550, Train Loss: 0.6402, Test Loss: 0.6429\n",
      "Epoch: 030, Train Acc: 0.7414, Test Acc: 0.6750, Train Loss: 0.5773, Test Loss: 0.5958\n",
      "Epoch: 040, Train Acc: 0.7500, Test Acc: 0.6900, Train Loss: 0.5347, Test Loss: 0.5593\n",
      "Epoch: 050, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.4887, Test Loss: 0.5463\n",
      "Epoch: 060, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.4663, Test Loss: 0.5538\n",
      "Epoch: 070, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4728, Test Loss: 0.5986\n",
      "Epoch: 080, Train Acc: 0.7974, Test Acc: 0.7200, Train Loss: 0.4423, Test Loss: 0.5234\n",
      "Epoch: 090, Train Acc: 0.8190, Test Acc: 0.7350, Train Loss: 0.4352, Test Loss: 0.5500\n",
      "Epoch: 100, Train Acc: 0.8147, Test Acc: 0.7300, Train Loss: 0.4165, Test Loss: 0.5173\n",
      "Epoch: 110, Train Acc: 0.8060, Test Acc: 0.7450, Train Loss: 0.4075, Test Loss: 0.5128\n",
      "Epoch: 120, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.3996, Test Loss: 0.5144\n",
      "Epoch: 130, Train Acc: 0.8082, Test Acc: 0.7500, Train Loss: 0.3924, Test Loss: 0.5122\n",
      "Epoch: 140, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.3799, Test Loss: 0.5183\n",
      "Epoch: 150, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.3777, Test Loss: 0.5191\n",
      "Epoch: 160, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.3888, Test Loss: 0.5440\n",
      "Epoch: 170, Train Acc: 0.8427, Test Acc: 0.7400, Train Loss: 0.3670, Test Loss: 0.5441\n",
      "Epoch: 180, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.3570, Test Loss: 0.5238\n",
      "Epoch: 190, Train Acc: 0.8405, Test Acc: 0.7500, Train Loss: 0.3518, Test Loss: 0.5303\n",
      "Epoch: 200, Train Acc: 0.8470, Test Acc: 0.7400, Train Loss: 0.3412, Test Loss: 0.5760\n",
      "Epoch: 210, Train Acc: 0.8599, Test Acc: 0.7500, Train Loss: 0.3214, Test Loss: 0.5429\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▃▄▅▅▆▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇██████▇▇██▇▇▇▇</td></tr><tr><td>Test F1</td><td>▃▁▂▄▇▅▂▁▃▄▄▄▅▅▅▇▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇█▆▆▇▇▆▆▆▆</td></tr><tr><td>Test Loss</td><td>██▇▇▆▅▄▄▃▃▃▂▂▂▄▁▂▂▂▂▂▂▃▁▁▂▁▂▂▂▁▁▃▃▂▂▃▄▄▅</td></tr><tr><td>Test Sensitivity</td><td>▇▃▃▅█▄▁▁▂▂▂▃▃▃▂▅▄▃▃▄▄▃▃▄▄▄▄▅▅▄▅▅▄▄▅▄▄▃▄▃</td></tr><tr><td>Test Specificity</td><td>▁▅▆▅▃▆▇█▇▇█▇▇▇█▇▇▇█▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▃▄▃▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇████</td></tr><tr><td>Train F1</td><td>▃▁▃▄▅▆▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████</td></tr><tr><td>Train Loss</td><td>███▇▇▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▆▁▂▅█▆▄▃▄▄▄▅▅▅▄▆▆▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▆▇▆▆▅▆▅</td></tr><tr><td>Train Specificity</td><td>▁▄▅▄▁▅▇▇▇▇▇▆▆▆█▆▆▇▇▇▇▇▇▆▆▇▆▇▆▆▆▆▇▇▆▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.73</td></tr><tr><td>Test F1</td><td>0.68966</td></tr><tr><td>Test Loss</td><td>0.61165</td></tr><tr><td>Test Sensitivity</td><td>0.58252</td></tr><tr><td>Test Specificity</td><td>0.8866</td></tr><tr><td>Train Accuracy</td><td>0.87716</td></tr><tr><td>Train F1</td><td>0.87473</td></tr><tr><td>Train Loss</td><td>0.31481</td></tr><tr><td>Train Sensitivity</td><td>0.80894</td></tr><tr><td>Train Specificity</td><td>0.95413</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run 5 light GraphNorm1+2</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/8z19v2ee' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/8z19v2ee</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_111352-8z19v2ee/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a single run\n",
    "\n",
    "# cutoff_distance=12.224281635103226\n",
    "# dropout=0.4\n",
    "\n",
    "# edge_weights=\"exp\"\n",
    "# hidden_channels=320\n",
    "# lambda_param=1.9594\n",
    "# learning_rate=0.000043988\n",
    "# weight_decay=8.2056e-7\n",
    "\n",
    "# params = {\n",
    "#   \"dropout\": 0.4,\n",
    "#   \"edge_weights\": \"exp\",\n",
    "#   \"lambda_param\": 1.9593979073129404,\n",
    "#   \"weight_decay\": 8.205598117080135e-7,\n",
    "#   \"learning_rate\": 0.000043987923400618824,\n",
    "#   \"cutoff_distance\": 12.224281635103226,\n",
    "#   \"hidden_channels\": 320\n",
    "# }\n",
    "\n",
    "\n",
    "model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            cutoff_distance = best_conf['cutoff_distance'],\n",
    "            edge_weight_func = 'exp',\n",
    "            batch_size = batch_size,\n",
    "            num_node_features = num_node_features,\n",
    "            hidden_channels = best_conf['hidden_channels'],\n",
    "            learning_rate = best_conf['learning_rate'],\n",
    "            wd = best_conf['weight_decay'],\n",
    "            dropout = best_conf['dropout'],\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            lambda_param= best_conf['lambda_param'],\n",
    "            wandb_params={\n",
    "              'use_wandb': True, \n",
    "              'wandb_project': f'{project}', \n",
    "              'wandb_name': 'run 5 light GraphNorm1+2',\n",
    "              'n_samples': n_samples,\n",
    "              'sweep': False\n",
    "              }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(f'saved_models/carter_ds_aug/{project}/8hxle9sc', exist_ok=True)\n",
    "        \n",
    "# torch.save(model, f'saved_models/carter_ds_aug/{project}/8hxle9sc/hopeful-sweep-190')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in graph_dict:\n",
    "    for sample in graph_dict[t]:\n",
    "        col_select = [i for i in range(19) if i != 14]\n",
    "        new_feats = graph_dict[t][sample]['graph'].dataset[0].x[:, col_select]\n",
    "        \n",
    "        graph_dict[t][sample]['graph'].dataset[0].x = new_feats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_run():\n",
    "\n",
    "    with wandb.init() as run:\n",
    "        config = run.config\n",
    "\n",
    "        model = run_model.pnca_GCN_vary_graph(\n",
    "            self_loops = False,\n",
    "            # cutoff_distance = config.cutoff_distance,\n",
    "            cutoff_distance = 12,\n",
    "            edge_weight_func = 'exp',\n",
    "            batch_size = batch_size,\n",
    "            # num_node_features = num_node_features,\n",
    "            num_node_features = 18,\n",
    "            hidden_channels = config.hidden_channels,\n",
    "            learning_rate = config.learning_rate,\n",
    "            wd = config.weight_decay,\n",
    "            dropout = config.dropout,\n",
    "            lr_scheduling=False,\n",
    "            epochs = epochs,\n",
    "            graph_dict= graph_dict,\n",
    "            normalise_ews=True,\n",
    "            # lambda_param=config.lambda_param,\n",
    "            lambda_param=2,\n",
    "            wandb_params={\n",
    "                'use_wandb': False,\n",
    "                'sweep': True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # os.makedirs(f'saved_models/carter_ds_aug/{project}/{sweep_id}', exist_ok=True)\n",
    "        \n",
    "        # torch.save(model, f'saved_models/carter_ds_aug/{project}/{sweep_id}/{run.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9u2t0od4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.4130211118325083e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.004071546397518974\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylan-home\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_164320-9u2t0od4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/9u2t0od4' target=\"_blank\">robust-sweep-1</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/9u2t0od4' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/9u2t0od4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6963, Test Loss: 0.6952\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6991, Test Loss: 0.6967\n",
      "Epoch: 020, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6989, Test Loss: 0.6970\n",
      "Epoch: 030, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6975, Test Loss: 0.6962\n",
      "Epoch: 040, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6961, Test Loss: 0.6951\n",
      "Epoch: 050, Train Acc: 0.4720, Test Acc: 0.4850, Train Loss: 0.6945, Test Loss: 0.6942\n",
      "Epoch: 060, Train Acc: 0.4612, Test Acc: 0.4950, Train Loss: 0.6936, Test Loss: 0.6937\n",
      "Epoch: 070, Train Acc: 0.5237, Test Acc: 0.5000, Train Loss: 0.6928, Test Loss: 0.6933\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6924, Test Loss: 0.6931\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6922, Test Loss: 0.6930\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6919, Test Loss: 0.6930\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6930\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6929\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6930\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6930\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6930\n",
      "Epoch: 160, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6930\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6929\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6929\n",
      "Epoch: 190, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6929\n",
      "Epoch: 200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6929\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6929\n",
      "Epoch: 220, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6928\n",
      "Epoch: 230, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6928\n",
      "Epoch: 240, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6927\n",
      "Epoch: 250, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6927\n",
      "Epoch: 260, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6926\n",
      "Epoch: 270, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6926\n",
      "Epoch: 280, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6926\n",
      "Epoch: 290, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6925\n",
      "Epoch: 300, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6925\n",
      "Epoch: 310, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6924\n",
      "Epoch: 320, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6924\n",
      "Epoch: 330, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6923\n",
      "Epoch: 340, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6923\n",
      "Epoch: 350, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6923\n",
      "Epoch: 360, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6922\n",
      "Epoch: 370, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6922\n",
      "Epoch: 380, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6922\n",
      "Epoch: 390, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6921\n",
      "Epoch: 400, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6921\n",
      "Epoch: 410, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6920\n",
      "Epoch: 420, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6920\n",
      "Epoch: 430, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6920\n",
      "Epoch: 440, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6920\n",
      "Epoch: 450, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 460, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6919\n",
      "Epoch: 470, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6919\n",
      "Epoch: 480, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6918\n",
      "Epoch: 490, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6918\n",
      "Epoch: 500, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6918\n",
      "Epoch: 510, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6917\n",
      "Epoch: 520, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6917\n",
      "Epoch: 530, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6917\n",
      "Epoch: 540, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6917\n",
      "Epoch: 550, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6917\n",
      "Epoch: 560, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6916\n",
      "Epoch: 570, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6916\n",
      "Epoch: 580, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6916\n",
      "Epoch: 590, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6915\n",
      "Epoch: 600, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6915\n",
      "Epoch: 610, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6915\n",
      "Epoch: 620, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6914\n",
      "Epoch: 630, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6914\n",
      "Epoch: 640, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6913\n",
      "Epoch: 650, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6913\n",
      "Epoch: 660, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6913\n",
      "Epoch: 670, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6913\n",
      "Epoch: 680, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6912\n",
      "Epoch: 690, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6912\n",
      "Epoch: 700, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6912\n",
      "Epoch: 710, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6912\n",
      "Epoch: 720, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6912\n",
      "Epoch: 730, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6912\n",
      "Epoch: 740, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6912\n",
      "Epoch: 750, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6911\n",
      "Epoch: 760, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6911\n",
      "Epoch: 770, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6910\n",
      "Epoch: 780, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6910\n",
      "Epoch: 790, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6910\n",
      "Epoch: 800, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6910\n",
      "Epoch: 810, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6909\n",
      "Epoch: 820, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6909\n",
      "Epoch: 830, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6909\n",
      "Epoch: 840, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6909\n",
      "Epoch: 850, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6909\n",
      "Epoch: 860, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6908\n",
      "Epoch: 870, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6908\n",
      "Epoch: 880, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6909\n",
      "Epoch: 890, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6908\n",
      "Epoch: 900, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6908\n",
      "Epoch: 910, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6908\n",
      "Epoch: 920, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6907\n",
      "Epoch: 930, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6907\n",
      "Epoch: 940, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6906\n",
      "Epoch: 950, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6906\n",
      "Epoch: 960, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6906\n",
      "Epoch: 970, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6906\n",
      "Epoch: 980, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6906\n",
      "Epoch: 990, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6905\n",
      "Epoch: 1000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6905\n",
      "Epoch: 1010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6905\n",
      "Epoch: 1020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6904\n",
      "Epoch: 1030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6904\n",
      "Epoch: 1040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6904\n",
      "Epoch: 1050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6904\n",
      "Epoch: 1060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6904\n",
      "Epoch: 1070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6903\n",
      "Epoch: 1080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6903\n",
      "Epoch: 1090, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6902\n",
      "Epoch: 1100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6902\n",
      "Epoch: 1110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6902\n",
      "Epoch: 1120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6902\n",
      "Epoch: 1130, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6902\n",
      "Epoch: 1140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6901\n",
      "Epoch: 1150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6901\n",
      "Epoch: 1160, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6901\n",
      "Epoch: 1170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6901\n",
      "Epoch: 1180, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6900\n",
      "Epoch: 1190, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6900\n",
      "Epoch: 1200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6900\n",
      "Epoch: 1210, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6899\n",
      "Epoch: 1220, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6899\n",
      "Epoch: 1230, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6899\n",
      "Epoch: 1240, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6899\n",
      "Epoch: 1250, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6899\n",
      "Epoch: 1260, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6898\n",
      "Epoch: 1270, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6898\n",
      "Epoch: 1280, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6898\n",
      "Epoch: 1290, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6898\n",
      "Epoch: 1300, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6898\n",
      "Epoch: 1310, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6898\n",
      "Epoch: 1320, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6897\n",
      "Epoch: 1330, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6873, Test Loss: 0.6897\n",
      "Epoch: 1340, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6897\n",
      "Epoch: 1350, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6872, Test Loss: 0.6896\n",
      "Epoch: 1360, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6871, Test Loss: 0.6896\n",
      "Epoch: 1370, Train Acc: 0.5345, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6896\n",
      "Epoch: 1380, Train Acc: 0.5345, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6896\n",
      "Epoch: 1390, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6869, Test Loss: 0.6896\n",
      "Epoch: 1400, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6870, Test Loss: 0.6895\n",
      "Epoch: 1410, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6895\n",
      "Epoch: 1420, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6869, Test Loss: 0.6894\n",
      "Epoch: 1430, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6873, Test Loss: 0.6894\n",
      "Epoch: 1440, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6877, Test Loss: 0.6893\n",
      "Epoch: 1450, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6893\n",
      "Epoch: 1460, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6872, Test Loss: 0.6893\n",
      "Epoch: 1470, Train Acc: 0.5431, Test Acc: 0.5250, Train Loss: 0.6859, Test Loss: 0.6893\n",
      "Epoch: 1480, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6868, Test Loss: 0.6893\n",
      "Epoch: 1490, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6865, Test Loss: 0.6892\n",
      "Epoch: 1500, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6862, Test Loss: 0.6892\n",
      "Epoch: 1510, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6892\n",
      "Epoch: 1520, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6892\n",
      "Epoch: 1530, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6891\n",
      "Epoch: 1540, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6891\n",
      "Epoch: 1550, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6891\n",
      "Epoch: 1560, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6891\n",
      "Epoch: 1570, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6862, Test Loss: 0.6891\n",
      "Epoch: 1580, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6890\n",
      "Epoch: 1590, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6863, Test Loss: 0.6890\n",
      "Epoch: 1600, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6889\n",
      "Epoch: 1610, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6889\n",
      "Epoch: 1620, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6889\n",
      "Epoch: 1630, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6861, Test Loss: 0.6889\n",
      "Epoch: 1640, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6856, Test Loss: 0.6888\n",
      "Epoch: 1650, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6888\n",
      "Epoch: 1660, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6887\n",
      "Epoch: 1670, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6887\n",
      "Epoch: 1680, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6887\n",
      "Epoch: 1690, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6887\n",
      "Epoch: 1700, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6887\n",
      "Epoch: 1710, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6858, Test Loss: 0.6887\n",
      "Epoch: 1720, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6855, Test Loss: 0.6886\n",
      "Epoch: 1730, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6860, Test Loss: 0.6885\n",
      "Epoch: 1740, Train Acc: 0.5496, Test Acc: 0.5300, Train Loss: 0.6858, Test Loss: 0.6885\n",
      "Epoch: 1750, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 1760, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 1770, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6856, Test Loss: 0.6885\n",
      "Epoch: 1780, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6885\n",
      "Epoch: 1790, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6884\n",
      "Epoch: 1800, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6884\n",
      "Epoch: 1810, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6883\n",
      "Epoch: 1820, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6849, Test Loss: 0.6883\n",
      "Epoch: 1830, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6853, Test Loss: 0.6882\n",
      "Epoch: 1840, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6882\n",
      "Epoch: 1850, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6856, Test Loss: 0.6882\n",
      "Epoch: 1860, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6882\n",
      "Epoch: 1870, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6855, Test Loss: 0.6881\n",
      "Epoch: 1880, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6851, Test Loss: 0.6881\n",
      "Epoch: 1890, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6853, Test Loss: 0.6881\n",
      "Epoch: 1900, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6847, Test Loss: 0.6880\n",
      "Epoch: 1910, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6859, Test Loss: 0.6880\n",
      "Epoch: 1920, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6854, Test Loss: 0.6880\n",
      "Epoch: 1930, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6851, Test Loss: 0.6880\n",
      "Epoch: 1940, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6847, Test Loss: 0.6879\n",
      "Epoch: 1950, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6851, Test Loss: 0.6879\n",
      "Epoch: 1960, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6858, Test Loss: 0.6879\n",
      "Epoch: 1970, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6848, Test Loss: 0.6879\n",
      "Epoch: 1980, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6847, Test Loss: 0.6878\n",
      "Epoch: 1990, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6853, Test Loss: 0.6878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test F1</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>Test Loss</td><td>█▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▂██████████████████████████████████████</td></tr><tr><td>Test Specificity</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇██▇██▇█████</td></tr><tr><td>Train F1</td><td>▁▄██████████████████████████████████████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▂██████████████████████████████████████</td></tr><tr><td>Train Specificity</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.52</td></tr><tr><td>Test F1</td><td>0.67785</td></tr><tr><td>Test Loss</td><td>0.68774</td></tr><tr><td>Test Sensitivity</td><td>0.98058</td></tr><tr><td>Test Specificity</td><td>0.03093</td></tr><tr><td>Train Accuracy</td><td>0.55819</td></tr><tr><td>Train F1</td><td>0.69985</td></tr><tr><td>Train Loss</td><td>0.68476</td></tr><tr><td>Train Sensitivity</td><td>0.97154</td></tr><tr><td>Train Specificity</td><td>0.09174</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-sweep-1</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/9u2t0od4' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/9u2t0od4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_164320-9u2t0od4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hav5iwwh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.608231051322591e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0007307800797066199\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165320-hav5iwwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/hav5iwwh' target=\"_blank\">legendary-sweep-2</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/hav5iwwh' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/hav5iwwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6924, Test Loss: 0.6932\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6922, Test Loss: 0.6933\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6917, Test Loss: 0.6933\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6933\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6933\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██████▅▅▅▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅███████████████</td></tr><tr><td>Test F1</td><td>██████▅▅▅▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅███████████████</td></tr><tr><td>Test Loss</td><td>█▆▄▁▁▂▄▅▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████▇▇▇</td></tr><tr><td>Test Sensitivity</td><td>██████▄▄▄▁▁▁▁▄▄▄▄▄▄▄▄▄▄▄▄███████████████</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▅▅▅▅▅▅▅█▅▁▁▁▁▅▅████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Train F1</td><td>▆▆▆▆▆▆▆█▅▁▁▁▁▅▅████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Train Loss</td><td>▂▃▃▄▄▆▇▇████▇▇▇▆▆▅▅▅▄▅▄▄▃▄▃▅▁▃▃▃▄▂▃▄▄▁▂▄</td></tr><tr><td>Train Sensitivity</td><td>████████▅▁▁▁▁▅▅█████████████████████████</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69328</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69182</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-sweep-2</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/hav5iwwh' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/hav5iwwh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165320-hav5iwwh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 574hw3z8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.5716573751926411e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.297523758882771e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165346-574hw3z8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/574hw3z8' target=\"_blank\">classic-sweep-3</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/574hw3z8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/574hw3z8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6941, Test Loss: 0.6936\n",
      "Epoch: 010, Train Acc: 0.4957, Test Acc: 0.5200, Train Loss: 0.6935, Test Loss: 0.6931\n",
      "Epoch: 020, Train Acc: 0.4720, Test Acc: 0.4950, Train Loss: 0.6947, Test Loss: 0.6937\n",
      "Epoch: 030, Train Acc: 0.5151, Test Acc: 0.5400, Train Loss: 0.6936, Test Loss: 0.6931\n",
      "Epoch: 040, Train Acc: 0.5237, Test Acc: 0.4800, Train Loss: 0.6923, Test Loss: 0.6926\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6916, Test Loss: 0.6924\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6924\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6924\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6924\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6925\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6925\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▂▃▆▇▄▃▃▃▅▅█▂▅▆▁▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Test F1</td><td>▁▁▁▂▃▂▁▁▁▂▂▄▅▇▇▇████████████████████████</td></tr><tr><td>Test Loss</td><td>▇▇▆▅▅▆▇██▇▇▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▂▂▁▁▁▁▁▁▂▃▅▆▇▇███████████████████████</td></tr><tr><td>Test Specificity</td><td>███████████▇▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▃▄▁▁▁▁▁▂▆▄▆▆▇▆▇▇█████████████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▂▂▁▁▁▁▁▁▄▆▇▇▇████████████████████████</td></tr><tr><td>Train Loss</td><td>▇▇▆▆▆▇▇███▇▆▆▅▅▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▂▁▁▁▁▁▁▂▄▅▆▆▇███████████████████████</td></tr><tr><td>Train Specificity</td><td>███████████▇▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69247</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69088</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-3</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/574hw3z8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/574hw3z8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165346-574hw3z8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ktlogm9l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.437897620119788e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.2242712727727626e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165448-ktlogm9l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/ktlogm9l' target=\"_blank\">daily-sweep-4</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/ktlogm9l' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/ktlogm9l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6945\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6942\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6942\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6945\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6945\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6943\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>▇▄▂▁▁▂▃▄▄▄▄▄▃▃▃▃▄▄▅▆▆▇▇███████▇▇▇▇▆▆▆▆▅▅</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▃▁▅▄▅█▄█▃▄▄█▃▂▃▆▃▄▂▅▂▆▆▆▆▆▃▆▅▃▃▃▃▅▃▅▂▆▄▄</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.6943</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69127</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-4</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/ktlogm9l' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/ktlogm9l</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165448-ktlogm9l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c5uokg9h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009061174944367512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.764785776458101e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165514-c5uokg9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/c5uokg9h' target=\"_blank\">sage-sweep-5</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/c5uokg9h' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/c5uokg9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5603, Test Acc: 0.5100, Train Loss: 0.6881, Test Loss: 0.6881\n",
      "Epoch: 030, Train Acc: 0.5517, Test Acc: 0.5750, Train Loss: 0.6863, Test Loss: 0.6836\n",
      "Epoch: 040, Train Acc: 0.5991, Test Acc: 0.6200, Train Loss: 0.6479, Test Loss: 0.6513\n",
      "Epoch: 050, Train Acc: 0.6918, Test Acc: 0.6550, Train Loss: 0.5702, Test Loss: 0.5990\n",
      "Epoch: 060, Train Acc: 0.7306, Test Acc: 0.6600, Train Loss: 0.5384, Test Loss: 0.5909\n",
      "Epoch: 070, Train Acc: 0.7004, Test Acc: 0.6900, Train Loss: 0.5787, Test Loss: 0.6207\n",
      "Epoch: 080, Train Acc: 0.7177, Test Acc: 0.7200, Train Loss: 0.5805, Test Loss: 0.6221\n",
      "Epoch: 090, Train Acc: 0.6767, Test Acc: 0.6900, Train Loss: 0.6443, Test Loss: 0.6875\n",
      "Epoch: 100, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4304, Test Loss: 0.5129\n",
      "Epoch: 110, Train Acc: 0.8211, Test Acc: 0.7600, Train Loss: 0.4341, Test Loss: 0.5155\n",
      "Epoch: 120, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4438, Test Loss: 0.5249\n",
      "Epoch: 130, Train Acc: 0.6164, Test Acc: 0.6550, Train Loss: 0.8934, Test Loss: 0.8998\n",
      "Epoch: 140, Train Acc: 0.8082, Test Acc: 0.7600, Train Loss: 0.4407, Test Loss: 0.5213\n",
      "Epoch: 150, Train Acc: 0.6746, Test Acc: 0.7100, Train Loss: 0.7246, Test Loss: 0.7700\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▁▂▁▂▂▂▄▅▄▄▄▄▅▄▅▅▅▆▆▄▅▅▅▆█▇█▇▆▇▃▅▅▇▇▅█▇</td></tr><tr><td>Test F1</td><td>▁▇▁▇▁▇▃▇▅▆▄▅▅▅▆▅▆▆▅▆▆▅▅▇▆▇█▇█▇▇▇▇▇▆▇▇▇█▇</td></tr><tr><td>Test Loss</td><td>▅▅▅▅▅▄▄▄▄▄▄▃▄▄▃▅▄▄▆▃▃█▇▂▆▂▁▁▁▂▃▂▆▃▇▄▄▅▁▂</td></tr><tr><td>Test Sensitivity</td><td>▁█▁█▁█▂█▄▄▃▃▃▃▄▃▄▄▃▄▄▃▃▇▄▇▆▅▇▅▅▅▇▇▄▅▅▇▆▅</td></tr><tr><td>Test Specificity</td><td>█▁█▁█▁█▂▇▇████▇█▇▇█████▅█▅▇▇▆▇▇▇▃▅███▄▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▁▂▁▂▁▃▄▄▃▃▃▃▄▄▅▅▄▅▆▄▄▆▅▇███▇▇█▅▇▅▆▆▅█▇</td></tr><tr><td>Train F1</td><td>▁▇▁▇▁▇▂▇▅▆▄▅▄▄▆▅▆▆▅▆▆▄▅█▅█████▇█▇█▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>▆▅▆▅▆▅▅▅▅▅▅▄▅▅▄▆▄▄▆▄▄█▇▂▆▂▁▂▁▂▃▂▄▂▇▄▄▃▁▂</td></tr><tr><td>Train Sensitivity</td><td>▁█▁█▁█▁▇▄▄▂▃▃▃▄▃▄▄▃▄▄▃▃▇▄▇▆▆▇▆▅▆█▇▄▄▅█▆▆</td></tr><tr><td>Train Specificity</td><td>█▁█▁█▁█▂▇▇█████████████▅█▆▇▇▇███▃▅███▄▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.735</td></tr><tr><td>Test F1</td><td>0.69364</td></tr><tr><td>Test Loss</td><td>0.55988</td></tr><tr><td>Test Sensitivity</td><td>0.58252</td></tr><tr><td>Test Specificity</td><td>0.89691</td></tr><tr><td>Train Accuracy</td><td>0.79957</td></tr><tr><td>Train F1</td><td>0.77482</td></tr><tr><td>Train Loss</td><td>0.46571</td></tr><tr><td>Train Sensitivity</td><td>0.65041</td></tr><tr><td>Train Specificity</td><td>0.96789</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-sweep-5</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/c5uokg9h' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/c5uokg9h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165514-c5uokg9h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zfo8296q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000526241873322437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0013270318696142931\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165626-zfo8296q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/zfo8296q' target=\"_blank\">proud-sweep-6</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/zfo8296q' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/zfo8296q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6945\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6915\n",
      "Epoch: 020, Train Acc: 0.5905, Test Acc: 0.5950, Train Loss: 0.6862, Test Loss: 0.6869\n",
      "Epoch: 030, Train Acc: 0.5539, Test Acc: 0.5800, Train Loss: 0.6760, Test Loss: 0.6770\n",
      "Epoch: 040, Train Acc: 0.5862, Test Acc: 0.6000, Train Loss: 0.6369, Test Loss: 0.6476\n",
      "Epoch: 050, Train Acc: 0.5625, Test Acc: 0.5700, Train Loss: 0.7239, Test Loss: 0.7406\n",
      "Epoch: 060, Train Acc: 0.6487, Test Acc: 0.6200, Train Loss: 0.6169, Test Loss: 0.6575\n",
      "Epoch: 070, Train Acc: 0.7112, Test Acc: 0.6700, Train Loss: 0.5592, Test Loss: 0.6148\n",
      "Epoch: 080, Train Acc: 0.5948, Test Acc: 0.6250, Train Loss: 0.8516, Test Loss: 0.8665\n",
      "Epoch: 090, Train Acc: 0.6250, Test Acc: 0.6250, Train Loss: 0.7333, Test Loss: 0.7652\n",
      "Epoch: 100, Train Acc: 0.6875, Test Acc: 0.7000, Train Loss: 0.6100, Test Loss: 0.6620\n",
      "Epoch: 110, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4351, Test Loss: 0.5301\n",
      "Epoch: 120, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.4193, Test Loss: 0.5214\n",
      "Epoch: 130, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4677, Test Loss: 0.5499\n",
      "Epoch: 140, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4444, Test Loss: 0.5349\n",
      "Epoch: 150, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4278, Test Loss: 0.5398\n",
      "Epoch: 160, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4374, Test Loss: 0.5476\n",
      "Epoch: 170, Train Acc: 0.8534, Test Acc: 0.8000, Train Loss: 0.3821, Test Loss: 0.5263\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▂▁▃▃▂▂▂▃▄▃▃▅▅▅▅▅▄▄▇▇▇▆▆▆▆▆▆▇▆▆▆▆▆▇▇█</td></tr><tr><td>Test F1</td><td>▇▇▇▆▂▁▅▄▁▂▃▃▄▄▄▆▆▆▆▅▄▄▇▇▇▇▆▆▇▆▆▇▆▆▇▇▆▇▇█</td></tr><tr><td>Test Loss</td><td>▅▅▅▅▅▅▅▄▅▅▅▅▄▅▆▂▂▃▂▄█▆▁▁▁▂▃▃▂▃▃▁▄▃▂▃▄▁▂▁</td></tr><tr><td>Test Sensitivity</td><td>███▆▁▁▃▃▁▁▂▂▃▃▃▄▄▄▄▄▂▃▆▅▅▅▄▄▇▅▄▅▄▄▅▅▄▅▅▆</td></tr><tr><td>Test Specificity</td><td>▁▁▁▃██▇█████▇██▇▇▇▇███▇▇▇▇▇▇▅▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▁▄▃▁▂▂▂▃▃▃▆▆▆▆▄▃▄▇▇▇▇▆▆▇▆▆▇▅▆▇▆▅▇▇█</td></tr><tr><td>Train F1</td><td>▆▆▆▅▂▁▅▄▁▂▂▃▄▄▄▇▇▇▇▅▄▄█▇█▇▆▇█▇▆█▆▆▇▆▆█▇█</td></tr><tr><td>Train Loss</td><td>▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▃▃▃▃▅█▇▂▂▂▃▄▃▂▃▄▂▄▄▂▃▅▂▂▁</td></tr><tr><td>Train Sensitivity</td><td>███▅▂▁▄▂▁▁▂▂▃▃▃▅▅▅▅▃▂▃▆▆▆▅▄▅▇▅▅▆▄▄▅▄▄▆▆▇</td></tr><tr><td>Train Specificity</td><td>▁▁▁▄██▇████████▇██████▇▇▇███▆██▇███████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.765</td></tr><tr><td>Test F1</td><td>0.74317</td></tr><tr><td>Test Loss</td><td>0.54104</td></tr><tr><td>Test Sensitivity</td><td>0.66019</td></tr><tr><td>Test Specificity</td><td>0.87629</td></tr><tr><td>Train Accuracy</td><td>0.83836</td></tr><tr><td>Train F1</td><td>0.82993</td></tr><tr><td>Train Loss</td><td>0.40401</td></tr><tr><td>Train Sensitivity</td><td>0.7439</td></tr><tr><td>Train Specificity</td><td>0.94495</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-6</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/zfo8296q' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/zfo8296q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165626-zfo8296q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6lsi88bv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004566819781112849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.686220401718469e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165738-6lsi88bv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/6lsi88bv' target=\"_blank\">hardy-sweep-7</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/6lsi88bv' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/6lsi88bv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4849, Test Acc: 0.4600, Train Loss: 0.6932, Test Loss: 0.6932\n",
      "Epoch: 010, Train Acc: 0.5409, Test Acc: 0.5350, Train Loss: 0.6916, Test Loss: 0.6916\n",
      "Epoch: 020, Train Acc: 0.6013, Test Acc: 0.6100, Train Loss: 0.6834, Test Loss: 0.6846\n",
      "Epoch: 030, Train Acc: 0.5970, Test Acc: 0.6200, Train Loss: 0.6586, Test Loss: 0.6629\n",
      "Epoch: 040, Train Acc: 0.7134, Test Acc: 0.6550, Train Loss: 0.5822, Test Loss: 0.6053\n",
      "Epoch: 050, Train Acc: 0.7155, Test Acc: 0.6550, Train Loss: 0.5447, Test Loss: 0.5877\n",
      "Epoch: 060, Train Acc: 0.6961, Test Acc: 0.6800, Train Loss: 0.5728, Test Loss: 0.6194\n",
      "Epoch: 070, Train Acc: 0.7306, Test Acc: 0.7050, Train Loss: 0.5382, Test Loss: 0.5930\n",
      "Epoch: 080, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.4838, Test Loss: 0.5464\n",
      "Epoch: 090, Train Acc: 0.7608, Test Acc: 0.7100, Train Loss: 0.4935, Test Loss: 0.5663\n",
      "Epoch: 100, Train Acc: 0.6552, Test Acc: 0.6650, Train Loss: 0.7134, Test Loss: 0.7433\n",
      "Epoch: 110, Train Acc: 0.7069, Test Acc: 0.7200, Train Loss: 0.6060, Test Loss: 0.6554\n",
      "Epoch: 120, Train Acc: 0.7845, Test Acc: 0.6900, Train Loss: 0.4511, Test Loss: 0.5740\n",
      "Epoch: 130, Train Acc: 0.7543, Test Acc: 0.7200, Train Loss: 0.5306, Test Loss: 0.6048\n",
      "Epoch: 140, Train Acc: 0.6875, Test Acc: 0.7150, Train Loss: 0.6726, Test Loss: 0.7141\n",
      "Epoch: 150, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4238, Test Loss: 0.5302\n",
      "Epoch: 160, Train Acc: 0.6078, Test Acc: 0.6250, Train Loss: 0.9807, Test Loss: 0.9992\n",
      "Epoch: 170, Train Acc: 0.6164, Test Acc: 0.6400, Train Loss: 0.9330, Test Loss: 0.9708\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▃▁▁▃▄▅▅▄▅▃▃▅▅▆▆▆▆▆▆▆▆▆▇▇█▇█▇▇▇█▇▆▇▆▇▄▇</td></tr><tr><td>Test F1</td><td>▁▅▅▂▁▃▅▆▇▅▆▄▄▆▆▇▇▆▇▇▇▇▇█▇████▇█▇█▇▇▇▇▇▅▇</td></tr><tr><td>Test Loss</td><td>▄▄▄▄▄▄▄▃▃▃▃▅▆▃▃▂▃▃▃▂▃▂▃▂▃▁▁▁▁▂▁▂▁▂▂▁▄▂█▄</td></tr><tr><td>Test Sensitivity</td><td>▁▄▃▁▁▂▄▅▆▃▄▃▃▄▅▆▅▅▅▅▅▅▅█▅▇▇█▇▆▆▆▇▆▆▆▅▆▄▅</td></tr><tr><td>Test Specificity</td><td>█▃▆███▆▅▅▇▆▇▇▇▇▅▇▇▇▆▇▇▇▁▇▅▄▃▅▇▆▆▅▆▆▆▇▇█▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▁▁▂▄▅▅▃▅▃▃▄▅▇▆▅▅▆▅▆▆▇▅█▇▇█▇█▇█▇▇█▅▇▄▅</td></tr><tr><td>Train F1</td><td>▁▅▄▁▁▃▅▆▇▄▆▄▄▆▆█▇▆▆▇▆▇▇█▆████▇█▇█▇▇█▆▇▅▆</td></tr><tr><td>Train Loss</td><td>▅▅▅▅▅▅▅▄▄▄▃▆▆▄▃▂▃▄▃▃▃▃▃▂▄▁▁▁▁▃▁▂▁▂▂▁▄▂█▄</td></tr><tr><td>Train Sensitivity</td><td>▁▄▃▁▁▂▄▅▆▃▅▃▃▄▅▇▅▄▅▆▅▅▅█▅▇▇█▇▆▇▆▇▆▆▇▅▆▃▅</td></tr><tr><td>Train Specificity</td><td>█▁▄██▇▆▅▄▇▆██▇▇▅▇▇▇▇▇▇▇▂▇▅▄▂▅▇▆▇▆▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.725</td></tr><tr><td>Test F1</td><td>0.65409</td></tr><tr><td>Test Loss</td><td>0.72391</td></tr><tr><td>Test Sensitivity</td><td>0.50485</td></tr><tr><td>Test Specificity</td><td>0.95876</td></tr><tr><td>Train Accuracy</td><td>0.71121</td></tr><tr><td>Train F1</td><td>0.62983</td></tr><tr><td>Train Loss</td><td>0.64142</td></tr><tr><td>Train Sensitivity</td><td>0.46341</td></tr><tr><td>Train Specificity</td><td>0.99083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-7</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/6lsi88bv' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/6lsi88bv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165738-6lsi88bv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7x6pqlih with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.144364685457157e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.003809529645017331\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165850-7x6pqlih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/7x6pqlih' target=\"_blank\">apricot-sweep-8</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7x6pqlih' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7x6pqlih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6964, Test Loss: 0.6952\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6995, Test Loss: 0.6970\n",
      "Epoch: 020, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.7005, Test Loss: 0.6981\n",
      "Epoch: 030, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.7001, Test Loss: 0.6981\n",
      "Epoch: 040, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6992, Test Loss: 0.6972\n",
      "Epoch: 050, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6975, Test Loss: 0.6963\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>▁▁▁▂▃▃▄▄▅▆▆▇▇▇▇██████████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▁▁▁▂▃▃▃▄▆▆▇▆▇▆▇███▇█▆▇▇▇▇▇▇▆▆▆▅▆▅▄▄▅▄▄▃▃</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.485</td></tr><tr><td>Test F1</td><td>0.0</td></tr><tr><td>Test Loss</td><td>0.69626</td></tr><tr><td>Test Sensitivity</td><td>0.0</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.46983</td></tr><tr><td>Train F1</td><td>0.0</td></tr><tr><td>Train Loss</td><td>0.69751</td></tr><tr><td>Train Sensitivity</td><td>0.0</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-8</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7x6pqlih' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7x6pqlih</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165850-7x6pqlih/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s3aiho76 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0030216138312152523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0030746913805615285\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_165915-s3aiho76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/s3aiho76' target=\"_blank\">lunar-sweep-9</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/s3aiho76' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/s3aiho76</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6931, Test Loss: 0.6961\n",
      "Epoch: 010, Train Acc: 0.4677, Test Acc: 0.4900, Train Loss: 0.6942, Test Loss: 0.6934\n",
      "Epoch: 020, Train Acc: 0.5151, Test Acc: 0.5550, Train Loss: 0.6931, Test Loss: 0.6927\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6915\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6902\n",
      "Epoch: 050, Train Acc: 0.5776, Test Acc: 0.5400, Train Loss: 0.6795, Test Loss: 0.6809\n",
      "Epoch: 060, Train Acc: 0.6444, Test Acc: 0.6300, Train Loss: 0.5947, Test Loss: 0.6175\n",
      "Epoch: 070, Train Acc: 0.5647, Test Acc: 0.5900, Train Loss: 1.0497, Test Loss: 1.0052\n",
      "Epoch: 080, Train Acc: 0.6573, Test Acc: 0.6850, Train Loss: 0.6770, Test Loss: 0.6775\n",
      "Epoch: 090, Train Acc: 0.7241, Test Acc: 0.7200, Train Loss: 0.5800, Test Loss: 0.6066\n",
      "Epoch: 100, Train Acc: 0.7953, Test Acc: 0.7450, Train Loss: 0.4918, Test Loss: 0.5271\n",
      "Epoch: 110, Train Acc: 0.8039, Test Acc: 0.7550, Train Loss: 0.4731, Test Loss: 0.5186\n",
      "Epoch: 120, Train Acc: 0.7155, Test Acc: 0.7500, Train Loss: 0.5679, Test Loss: 0.5834\n",
      "Epoch: 130, Train Acc: 0.6444, Test Acc: 0.6550, Train Loss: 0.8272, Test Loss: 0.8317\n",
      "Epoch: 140, Train Acc: 0.8233, Test Acc: 0.7750, Train Loss: 0.4479, Test Loss: 0.5182\n",
      "Epoch: 150, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4217, Test Loss: 0.5449\n",
      "Epoch: 160, Train Acc: 0.6293, Test Acc: 0.6500, Train Loss: 0.9028, Test Loss: 0.9196\n",
      "Epoch: 170, Train Acc: 0.6013, Test Acc: 0.6400, Train Loss: 1.0878, Test Loss: 1.1007\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▁▂▂▁▂▂▂▂▂▂▅▄▄▅▅▇▄▆▆▆▆▇▆█▇▄▆▄▅▇▇▇▇▇▆▆▅▆</td></tr><tr><td>Test F1</td><td>▁▇▁▇▇▇▇▇▇▇▇▇▇▅▆▆▅▇▅▆▆▇▇▇▆█▇▅█▅▆▇▇▇▇▇▆▇▇▆</td></tr><tr><td>Test Loss</td><td>▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▄▁▆▃▂▂▂▂▃▁▁▅▁█▄▂▂▂▁▂▄▃▃▅</td></tr><tr><td>Test Sensitivity</td><td>▁█▁██▇██████▆▃▄▄▃▅▃▄▄▄▄▅▄▇▅▃▇▃▄▅▅▅▅▅▄▄▇▄</td></tr><tr><td>Test Specificity</td><td>█▁█▁▁▁▁▁▁▁▁▁▅▇▇▇█▇█████▇█▆▇█▅███▇▇▇▇██▄█</td></tr><tr><td>Train Accuracy</td><td>▁▂▁▂▂▂▂▂▂▂▂▂▆▄▅▄▄▇▃▅▆▆▆▇▅██▄▇▃▅▆▇▇█▇▅▆▆▅</td></tr><tr><td>Train F1</td><td>▁▇▁▇▇▇▇▇▇▇▇▇▇▅▆▅▅▇▄▆▆▇▇▇▆██▄█▄▅▆▇▇█▇▆▆█▆</td></tr><tr><td>Train Loss</td><td>▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▄▂▆▃▃▂▂▂▃▁▂▆▁█▄▂▂▂▁▂▄▃▂▄</td></tr><tr><td>Train Sensitivity</td><td>▁█▁██▇██████▆▃▄▄▃▅▃▄▄▅▅▅▄▇▆▃▇▂▃▄▅▅▆▅▄▄▇▄</td></tr><tr><td>Train Specificity</td><td>█▁█▁▁▂▁▁▁▁▁▁▆█▇██▇███████▇██▆█████████▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.575</td></tr><tr><td>Test F1</td><td>0.29752</td></tr><tr><td>Test Loss</td><td>1.68134</td></tr><tr><td>Test Sensitivity</td><td>0.17476</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.53233</td></tr><tr><td>Train F1</td><td>0.21091</td></tr><tr><td>Train Loss</td><td>1.77567</td></tr><tr><td>Train Sensitivity</td><td>0.11789</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-9</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/s3aiho76' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/s3aiho76</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_165915-s3aiho76/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: td7hhmmb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.7093832514974952e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.6035450597489493e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_170017-td7hhmmb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/td7hhmmb' target=\"_blank\">polar-sweep-10</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/td7hhmmb' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/td7hhmmb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6939, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5043, Test Acc: 0.5100, Train Loss: 0.6927, Test Loss: 0.6926\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6913, Test Loss: 0.6916\n",
      "Epoch: 030, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6917\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6916\n",
      "Epoch: 050, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6916\n",
      "Epoch: 060, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6915\n",
      "Epoch: 070, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6914\n",
      "Epoch: 080, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6913\n",
      "Epoch: 090, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6912\n",
      "Epoch: 100, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6911\n",
      "Epoch: 110, Train Acc: 0.5216, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6911\n",
      "Epoch: 120, Train Acc: 0.5259, Test Acc: 0.5100, Train Loss: 0.6896, Test Loss: 0.6910\n",
      "Epoch: 130, Train Acc: 0.5259, Test Acc: 0.5100, Train Loss: 0.6896, Test Loss: 0.6910\n",
      "Epoch: 140, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6891, Test Loss: 0.6909\n",
      "Epoch: 150, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6895, Test Loss: 0.6907\n",
      "Epoch: 160, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6894, Test Loss: 0.6907\n",
      "Epoch: 170, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6907\n",
      "Epoch: 180, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6890, Test Loss: 0.6907\n",
      "Epoch: 190, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6893, Test Loss: 0.6906\n",
      "Epoch: 200, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6885, Test Loss: 0.6905\n",
      "Epoch: 210, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6904\n",
      "Epoch: 220, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6889, Test Loss: 0.6904\n",
      "Epoch: 230, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6886, Test Loss: 0.6904\n",
      "Epoch: 240, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6903\n",
      "Epoch: 250, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6903\n",
      "Epoch: 260, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6902\n",
      "Epoch: 270, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6901\n",
      "Epoch: 280, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6900\n",
      "Epoch: 290, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6900\n",
      "Epoch: 300, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6899\n",
      "Epoch: 310, Train Acc: 0.5366, Test Acc: 0.5100, Train Loss: 0.6888, Test Loss: 0.6899\n",
      "Epoch: 320, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6899\n",
      "Epoch: 330, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6897\n",
      "Epoch: 340, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6897\n",
      "Epoch: 350, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6896\n",
      "Epoch: 360, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6895\n",
      "Epoch: 370, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6895\n",
      "Epoch: 380, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6894\n",
      "Epoch: 390, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6892\n",
      "Epoch: 400, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6892\n",
      "Epoch: 410, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6892\n",
      "Epoch: 420, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6891\n",
      "Epoch: 430, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6890\n",
      "Epoch: 440, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6890\n",
      "Epoch: 450, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6890\n",
      "Epoch: 460, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6889\n",
      "Epoch: 470, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6888\n",
      "Epoch: 480, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6861, Test Loss: 0.6887\n",
      "Epoch: 490, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6887\n",
      "Epoch: 500, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6886\n",
      "Epoch: 510, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6885\n",
      "Epoch: 520, Train Acc: 0.5388, Test Acc: 0.5100, Train Loss: 0.6864, Test Loss: 0.6885\n",
      "Epoch: 530, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6884\n",
      "Epoch: 540, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6883\n",
      "Epoch: 550, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6883\n",
      "Epoch: 560, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6858, Test Loss: 0.6882\n",
      "Epoch: 570, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6856, Test Loss: 0.6880\n",
      "Epoch: 580, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6859, Test Loss: 0.6880\n",
      "Epoch: 590, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6861, Test Loss: 0.6879\n",
      "Epoch: 600, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6858, Test Loss: 0.6878\n",
      "Epoch: 610, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6856, Test Loss: 0.6877\n",
      "Epoch: 620, Train Acc: 0.5603, Test Acc: 0.5250, Train Loss: 0.6856, Test Loss: 0.6876\n",
      "Epoch: 630, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6851, Test Loss: 0.6876\n",
      "Epoch: 640, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6852, Test Loss: 0.6875\n",
      "Epoch: 650, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6849, Test Loss: 0.6874\n",
      "Epoch: 660, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6845, Test Loss: 0.6873\n",
      "Epoch: 670, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6847, Test Loss: 0.6873\n",
      "Epoch: 680, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6846, Test Loss: 0.6872\n",
      "Epoch: 690, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6846, Test Loss: 0.6872\n",
      "Epoch: 700, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6843, Test Loss: 0.6871\n",
      "Epoch: 710, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6869\n",
      "Epoch: 720, Train Acc: 0.5560, Test Acc: 0.5250, Train Loss: 0.6847, Test Loss: 0.6868\n",
      "Epoch: 730, Train Acc: 0.5560, Test Acc: 0.5250, Train Loss: 0.6840, Test Loss: 0.6867\n",
      "Epoch: 740, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6839, Test Loss: 0.6867\n",
      "Epoch: 750, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6841, Test Loss: 0.6865\n",
      "Epoch: 760, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6843, Test Loss: 0.6864\n",
      "Epoch: 770, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6836, Test Loss: 0.6864\n",
      "Epoch: 780, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6839, Test Loss: 0.6863\n",
      "Epoch: 790, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6833, Test Loss: 0.6862\n",
      "Epoch: 800, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6832, Test Loss: 0.6862\n",
      "Epoch: 810, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6830, Test Loss: 0.6860\n",
      "Epoch: 820, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6828, Test Loss: 0.6859\n",
      "Epoch: 830, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6827, Test Loss: 0.6857\n",
      "Epoch: 840, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6831, Test Loss: 0.6856\n",
      "Epoch: 850, Train Acc: 0.5733, Test Acc: 0.5250, Train Loss: 0.6822, Test Loss: 0.6855\n",
      "Epoch: 860, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6830, Test Loss: 0.6854\n",
      "Epoch: 870, Train Acc: 0.5841, Test Acc: 0.5350, Train Loss: 0.6824, Test Loss: 0.6853\n",
      "Epoch: 880, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6823, Test Loss: 0.6853\n",
      "Epoch: 890, Train Acc: 0.5690, Test Acc: 0.5200, Train Loss: 0.6822, Test Loss: 0.6852\n",
      "Epoch: 900, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6823, Test Loss: 0.6850\n",
      "Epoch: 910, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6849\n",
      "Epoch: 920, Train Acc: 0.5841, Test Acc: 0.5350, Train Loss: 0.6822, Test Loss: 0.6847\n",
      "Epoch: 930, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6813, Test Loss: 0.6847\n",
      "Epoch: 940, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6806, Test Loss: 0.6845\n",
      "Epoch: 950, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6810, Test Loss: 0.6844\n",
      "Epoch: 960, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6811, Test Loss: 0.6843\n",
      "Epoch: 970, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6811, Test Loss: 0.6842\n",
      "Epoch: 980, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6806, Test Loss: 0.6841\n",
      "Epoch: 990, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6809, Test Loss: 0.6840\n",
      "Epoch: 1000, Train Acc: 0.5948, Test Acc: 0.5400, Train Loss: 0.6799, Test Loss: 0.6837\n",
      "Epoch: 1010, Train Acc: 0.5905, Test Acc: 0.5300, Train Loss: 0.6795, Test Loss: 0.6836\n",
      "Epoch: 1020, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6802, Test Loss: 0.6836\n",
      "Epoch: 1030, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6798, Test Loss: 0.6835\n",
      "Epoch: 1040, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6801, Test Loss: 0.6833\n",
      "Epoch: 1050, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6791, Test Loss: 0.6832\n",
      "Epoch: 1060, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6787, Test Loss: 0.6831\n",
      "Epoch: 1070, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6788, Test Loss: 0.6829\n",
      "Epoch: 1080, Train Acc: 0.6121, Test Acc: 0.5350, Train Loss: 0.6791, Test Loss: 0.6827\n",
      "Epoch: 1090, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6785, Test Loss: 0.6826\n",
      "Epoch: 1100, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6788, Test Loss: 0.6825\n",
      "Epoch: 1110, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6777, Test Loss: 0.6823\n",
      "Epoch: 1120, Train Acc: 0.6056, Test Acc: 0.5300, Train Loss: 0.6782, Test Loss: 0.6821\n",
      "Epoch: 1130, Train Acc: 0.5797, Test Acc: 0.5250, Train Loss: 0.6773, Test Loss: 0.6821\n",
      "Epoch: 1140, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6775, Test Loss: 0.6819\n",
      "Epoch: 1150, Train Acc: 0.6121, Test Acc: 0.5350, Train Loss: 0.6780, Test Loss: 0.6817\n",
      "Epoch: 1160, Train Acc: 0.5970, Test Acc: 0.5250, Train Loss: 0.6771, Test Loss: 0.6816\n",
      "Epoch: 1170, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6763, Test Loss: 0.6815\n",
      "Epoch: 1180, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6768, Test Loss: 0.6812\n",
      "Epoch: 1190, Train Acc: 0.6121, Test Acc: 0.5300, Train Loss: 0.6765, Test Loss: 0.6810\n",
      "Epoch: 1200, Train Acc: 0.6099, Test Acc: 0.5300, Train Loss: 0.6765, Test Loss: 0.6809\n",
      "Epoch: 1210, Train Acc: 0.6078, Test Acc: 0.5300, Train Loss: 0.6763, Test Loss: 0.6807\n",
      "Epoch: 1220, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6764, Test Loss: 0.6806\n",
      "Epoch: 1230, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6757, Test Loss: 0.6805\n",
      "Epoch: 1240, Train Acc: 0.6099, Test Acc: 0.5300, Train Loss: 0.6750, Test Loss: 0.6802\n",
      "Epoch: 1250, Train Acc: 0.6056, Test Acc: 0.5300, Train Loss: 0.6745, Test Loss: 0.6801\n",
      "Epoch: 1260, Train Acc: 0.6056, Test Acc: 0.5300, Train Loss: 0.6753, Test Loss: 0.6799\n",
      "Epoch: 1270, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6742, Test Loss: 0.6797\n",
      "Epoch: 1280, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6742, Test Loss: 0.6796\n",
      "Epoch: 1290, Train Acc: 0.6142, Test Acc: 0.5300, Train Loss: 0.6746, Test Loss: 0.6793\n",
      "Epoch: 1300, Train Acc: 0.6142, Test Acc: 0.5300, Train Loss: 0.6741, Test Loss: 0.6791\n",
      "Epoch: 1310, Train Acc: 0.6164, Test Acc: 0.5350, Train Loss: 0.6732, Test Loss: 0.6789\n",
      "Epoch: 1320, Train Acc: 0.6185, Test Acc: 0.5350, Train Loss: 0.6736, Test Loss: 0.6787\n",
      "Epoch: 1330, Train Acc: 0.6078, Test Acc: 0.5300, Train Loss: 0.6734, Test Loss: 0.6786\n",
      "Epoch: 1340, Train Acc: 0.6099, Test Acc: 0.5350, Train Loss: 0.6731, Test Loss: 0.6784\n",
      "Epoch: 1350, Train Acc: 0.6142, Test Acc: 0.5350, Train Loss: 0.6730, Test Loss: 0.6782\n",
      "Epoch: 1360, Train Acc: 0.6185, Test Acc: 0.5350, Train Loss: 0.6731, Test Loss: 0.6779\n",
      "Epoch: 1370, Train Acc: 0.6185, Test Acc: 0.5350, Train Loss: 0.6722, Test Loss: 0.6777\n",
      "Epoch: 1380, Train Acc: 0.6315, Test Acc: 0.5400, Train Loss: 0.6718, Test Loss: 0.6774\n",
      "Epoch: 1390, Train Acc: 0.6293, Test Acc: 0.5400, Train Loss: 0.6728, Test Loss: 0.6773\n",
      "Epoch: 1400, Train Acc: 0.6358, Test Acc: 0.5600, Train Loss: 0.6717, Test Loss: 0.6770\n",
      "Epoch: 1410, Train Acc: 0.6228, Test Acc: 0.5400, Train Loss: 0.6709, Test Loss: 0.6769\n",
      "Epoch: 1420, Train Acc: 0.6336, Test Acc: 0.5350, Train Loss: 0.6710, Test Loss: 0.6766\n",
      "Epoch: 1430, Train Acc: 0.6336, Test Acc: 0.5350, Train Loss: 0.6705, Test Loss: 0.6764\n",
      "Epoch: 1440, Train Acc: 0.6358, Test Acc: 0.5600, Train Loss: 0.6705, Test Loss: 0.6761\n",
      "Epoch: 1450, Train Acc: 0.6358, Test Acc: 0.5600, Train Loss: 0.6700, Test Loss: 0.6759\n",
      "Epoch: 1460, Train Acc: 0.6358, Test Acc: 0.5600, Train Loss: 0.6697, Test Loss: 0.6756\n",
      "Epoch: 1470, Train Acc: 0.6315, Test Acc: 0.5450, Train Loss: 0.6693, Test Loss: 0.6755\n",
      "Epoch: 1480, Train Acc: 0.6228, Test Acc: 0.5450, Train Loss: 0.6700, Test Loss: 0.6753\n",
      "Epoch: 1490, Train Acc: 0.6336, Test Acc: 0.5550, Train Loss: 0.6694, Test Loss: 0.6750\n",
      "Epoch: 1500, Train Acc: 0.6293, Test Acc: 0.5450, Train Loss: 0.6692, Test Loss: 0.6748\n",
      "Epoch: 1510, Train Acc: 0.6422, Test Acc: 0.5650, Train Loss: 0.6688, Test Loss: 0.6744\n",
      "Epoch: 1520, Train Acc: 0.6401, Test Acc: 0.5650, Train Loss: 0.6682, Test Loss: 0.6742\n",
      "Epoch: 1530, Train Acc: 0.6444, Test Acc: 0.5650, Train Loss: 0.6675, Test Loss: 0.6739\n",
      "Epoch: 1540, Train Acc: 0.6444, Test Acc: 0.5700, Train Loss: 0.6672, Test Loss: 0.6736\n",
      "Epoch: 1550, Train Acc: 0.6487, Test Acc: 0.5650, Train Loss: 0.6665, Test Loss: 0.6734\n",
      "Epoch: 1560, Train Acc: 0.6466, Test Acc: 0.5650, Train Loss: 0.6658, Test Loss: 0.6731\n",
      "Epoch: 1570, Train Acc: 0.6444, Test Acc: 0.5650, Train Loss: 0.6665, Test Loss: 0.6729\n",
      "Epoch: 1580, Train Acc: 0.6444, Test Acc: 0.5650, Train Loss: 0.6661, Test Loss: 0.6727\n",
      "Epoch: 1590, Train Acc: 0.6444, Test Acc: 0.5650, Train Loss: 0.6657, Test Loss: 0.6724\n",
      "Epoch: 1600, Train Acc: 0.6444, Test Acc: 0.5700, Train Loss: 0.6657, Test Loss: 0.6720\n",
      "Epoch: 1610, Train Acc: 0.6487, Test Acc: 0.5650, Train Loss: 0.6640, Test Loss: 0.6718\n",
      "Epoch: 1620, Train Acc: 0.6487, Test Acc: 0.5700, Train Loss: 0.6649, Test Loss: 0.6714\n",
      "Epoch: 1630, Train Acc: 0.6509, Test Acc: 0.5650, Train Loss: 0.6645, Test Loss: 0.6712\n",
      "Epoch: 1640, Train Acc: 0.6530, Test Acc: 0.5700, Train Loss: 0.6629, Test Loss: 0.6709\n",
      "Epoch: 1650, Train Acc: 0.6509, Test Acc: 0.5700, Train Loss: 0.6631, Test Loss: 0.6706\n",
      "Epoch: 1660, Train Acc: 0.6487, Test Acc: 0.5700, Train Loss: 0.6630, Test Loss: 0.6704\n",
      "Epoch: 1670, Train Acc: 0.6552, Test Acc: 0.5800, Train Loss: 0.6627, Test Loss: 0.6700\n",
      "Epoch: 1680, Train Acc: 0.6552, Test Acc: 0.5750, Train Loss: 0.6619, Test Loss: 0.6698\n",
      "Epoch: 1690, Train Acc: 0.6552, Test Acc: 0.5850, Train Loss: 0.6615, Test Loss: 0.6694\n",
      "Epoch: 1700, Train Acc: 0.6552, Test Acc: 0.5800, Train Loss: 0.6612, Test Loss: 0.6691\n",
      "Epoch: 1710, Train Acc: 0.6552, Test Acc: 0.5800, Train Loss: 0.6602, Test Loss: 0.6689\n",
      "Epoch: 1720, Train Acc: 0.6595, Test Acc: 0.5800, Train Loss: 0.6603, Test Loss: 0.6685\n",
      "Epoch: 1730, Train Acc: 0.6659, Test Acc: 0.5950, Train Loss: 0.6600, Test Loss: 0.6682\n",
      "Epoch: 1740, Train Acc: 0.6573, Test Acc: 0.5800, Train Loss: 0.6599, Test Loss: 0.6680\n",
      "Epoch: 1750, Train Acc: 0.6616, Test Acc: 0.5900, Train Loss: 0.6592, Test Loss: 0.6676\n",
      "Epoch: 1760, Train Acc: 0.6659, Test Acc: 0.5950, Train Loss: 0.6590, Test Loss: 0.6672\n",
      "Epoch: 1770, Train Acc: 0.6746, Test Acc: 0.6050, Train Loss: 0.6586, Test Loss: 0.6668\n",
      "Epoch: 1780, Train Acc: 0.6724, Test Acc: 0.5950, Train Loss: 0.6582, Test Loss: 0.6666\n",
      "Epoch: 1790, Train Acc: 0.6789, Test Acc: 0.6000, Train Loss: 0.6560, Test Loss: 0.6663\n",
      "Epoch: 1800, Train Acc: 0.6767, Test Acc: 0.6050, Train Loss: 0.6572, Test Loss: 0.6659\n",
      "Epoch: 1810, Train Acc: 0.6746, Test Acc: 0.6150, Train Loss: 0.6565, Test Loss: 0.6656\n",
      "Epoch: 1820, Train Acc: 0.6767, Test Acc: 0.6100, Train Loss: 0.6557, Test Loss: 0.6653\n",
      "Epoch: 1830, Train Acc: 0.6853, Test Acc: 0.6050, Train Loss: 0.6560, Test Loss: 0.6648\n",
      "Epoch: 1840, Train Acc: 0.6918, Test Acc: 0.6100, Train Loss: 0.6556, Test Loss: 0.6644\n",
      "Epoch: 1850, Train Acc: 0.6832, Test Acc: 0.6100, Train Loss: 0.6550, Test Loss: 0.6642\n",
      "Epoch: 1860, Train Acc: 0.6918, Test Acc: 0.6150, Train Loss: 0.6552, Test Loss: 0.6638\n",
      "Epoch: 1870, Train Acc: 0.6897, Test Acc: 0.6100, Train Loss: 0.6536, Test Loss: 0.6634\n",
      "Epoch: 1880, Train Acc: 0.6983, Test Acc: 0.6150, Train Loss: 0.6536, Test Loss: 0.6631\n",
      "Epoch: 1890, Train Acc: 0.6961, Test Acc: 0.6200, Train Loss: 0.6524, Test Loss: 0.6627\n",
      "Epoch: 1900, Train Acc: 0.6983, Test Acc: 0.6200, Train Loss: 0.6527, Test Loss: 0.6623\n",
      "Epoch: 1910, Train Acc: 0.6961, Test Acc: 0.6200, Train Loss: 0.6524, Test Loss: 0.6620\n",
      "Epoch: 1920, Train Acc: 0.7004, Test Acc: 0.6150, Train Loss: 0.6506, Test Loss: 0.6615\n",
      "Epoch: 1930, Train Acc: 0.6961, Test Acc: 0.6150, Train Loss: 0.6509, Test Loss: 0.6612\n",
      "Epoch: 1940, Train Acc: 0.6983, Test Acc: 0.6250, Train Loss: 0.6490, Test Loss: 0.6608\n",
      "Epoch: 1950, Train Acc: 0.7004, Test Acc: 0.6250, Train Loss: 0.6503, Test Loss: 0.6605\n",
      "Epoch: 1960, Train Acc: 0.6983, Test Acc: 0.6200, Train Loss: 0.6488, Test Loss: 0.6599\n",
      "Epoch: 1970, Train Acc: 0.7026, Test Acc: 0.6200, Train Loss: 0.6491, Test Loss: 0.6596\n",
      "Epoch: 1980, Train Acc: 0.7134, Test Acc: 0.6150, Train Loss: 0.6487, Test Loss: 0.6592\n",
      "Epoch: 1990, Train Acc: 0.7112, Test Acc: 0.6200, Train Loss: 0.6486, Test Loss: 0.6588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▅▃▅▅▅▅▆▇████</td></tr><tr><td>Test F1</td><td>▁▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▄▄▄▄▅▅▅▄▄▄▅▆▅▆▆▆▆▇███▇▇</td></tr><tr><td>Test Loss</td><td>███████▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▄███████████▇█████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▂▁▁</td></tr><tr><td>Test Specificity</td><td>▃▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▁▂▂▂▂▂▃▂▂▂▃▄▃▄▄▅▅▅▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▆▅▆▆▆▇▇▇▇█</td></tr><tr><td>Train F1</td><td>▁▃▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>Train Loss</td><td>████▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▁</td></tr><tr><td>Train Sensitivity</td><td>▂█████████▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▃▂▂▁</td></tr><tr><td>Train Specificity</td><td>▃▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▂▂▃▃▃▃▃▄▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.62</td></tr><tr><td>Test F1</td><td>0.696</td></tr><tr><td>Test Loss</td><td>0.65845</td></tr><tr><td>Test Sensitivity</td><td>0.84466</td></tr><tr><td>Test Specificity</td><td>0.38144</td></tr><tr><td>Train Accuracy</td><td>0.70905</td></tr><tr><td>Train F1</td><td>0.76106</td></tr><tr><td>Train Loss</td><td>0.64839</td></tr><tr><td>Train Sensitivity</td><td>0.87398</td></tr><tr><td>Train Specificity</td><td>0.52294</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-10</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/td7hhmmb' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/td7hhmmb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_170017-td7hhmmb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mvm5pm4d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003864491955420415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.7291882211579945e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_171130-mvm5pm4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/mvm5pm4d' target=\"_blank\">snowy-sweep-11</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mvm5pm4d' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mvm5pm4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6916, Test Loss: 0.6943\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6920\n",
      "Epoch: 020, Train Acc: 0.5539, Test Acc: 0.5100, Train Loss: 0.6875, Test Loss: 0.6894\n",
      "Epoch: 030, Train Acc: 0.5625, Test Acc: 0.5450, Train Loss: 0.6823, Test Loss: 0.6848\n",
      "Epoch: 040, Train Acc: 0.6207, Test Acc: 0.5650, Train Loss: 0.6711, Test Loss: 0.6766\n",
      "Epoch: 050, Train Acc: 0.5797, Test Acc: 0.6000, Train Loss: 0.6627, Test Loss: 0.6674\n",
      "Epoch: 060, Train Acc: 0.5927, Test Acc: 0.6000, Train Loss: 0.6402, Test Loss: 0.6486\n",
      "Epoch: 070, Train Acc: 0.6293, Test Acc: 0.6300, Train Loss: 0.6089, Test Loss: 0.6272\n",
      "Epoch: 080, Train Acc: 0.6034, Test Acc: 0.6100, Train Loss: 0.6290, Test Loss: 0.6478\n",
      "Epoch: 090, Train Acc: 0.6487, Test Acc: 0.6250, Train Loss: 0.6004, Test Loss: 0.6375\n",
      "Epoch: 100, Train Acc: 0.7457, Test Acc: 0.6800, Train Loss: 0.5268, Test Loss: 0.5811\n",
      "Epoch: 110, Train Acc: 0.7091, Test Acc: 0.6850, Train Loss: 0.5539, Test Loss: 0.6034\n",
      "Epoch: 120, Train Acc: 0.8060, Test Acc: 0.7650, Train Loss: 0.4673, Test Loss: 0.5389\n",
      "Epoch: 130, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4595, Test Loss: 0.5336\n",
      "Epoch: 140, Train Acc: 0.7543, Test Acc: 0.7050, Train Loss: 0.5136, Test Loss: 0.5722\n",
      "Epoch: 150, Train Acc: 0.7263, Test Acc: 0.7000, Train Loss: 0.5652, Test Loss: 0.6231\n",
      "Epoch: 160, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4621, Test Loss: 0.5366\n",
      "Epoch: 170, Train Acc: 0.7091, Test Acc: 0.7200, Train Loss: 0.6024, Test Loss: 0.6521\n",
      "Epoch: 180, Train Acc: 0.6961, Test Acc: 0.7150, Train Loss: 0.6294, Test Loss: 0.6763\n",
      "Epoch: 190, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.4117, Test Loss: 0.5207\n",
      "Epoch: 200, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4335, Test Loss: 0.5346\n",
      "Epoch: 210, Train Acc: 0.8427, Test Acc: 0.7900, Train Loss: 0.3947, Test Loss: 0.5230\n",
      "Epoch: 220, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4099, Test Loss: 0.5321\n",
      "Epoch: 230, Train Acc: 0.8448, Test Acc: 0.8050, Train Loss: 0.3763, Test Loss: 0.5179\n",
      "Epoch: 240, Train Acc: 0.8427, Test Acc: 0.7600, Train Loss: 0.4005, Test Loss: 0.5312\n",
      "Epoch: 250, Train Acc: 0.8362, Test Acc: 0.7900, Train Loss: 0.3722, Test Loss: 0.5205\n",
      "Epoch: 260, Train Acc: 0.7435, Test Acc: 0.7200, Train Loss: 0.5488, Test Loss: 0.6515\n",
      "Epoch: 270, Train Acc: 0.8578, Test Acc: 0.8050, Train Loss: 0.3569, Test Loss: 0.5284\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▃▃▃▃▂▄▄▅▄▆▆▅▇▇▆▇▇▆▇▇▆▆▇▇▇▆▇██▇▄▆▆▇▆</td></tr><tr><td>Test F1</td><td>▆▆▆▆▆▅▂▂▂▁▃▃▅▃▆▅▅▇█▆██▆▇▇▆▆▆▇▇▆▇█▇▇▇▇▆▇▇</td></tr><tr><td>Test Loss</td><td>█████▇▇▇▇▆▆▅▄▇▃▄▃▂▂▃▁▂▅▁▁▂▄▂▁▂▃▂▂▁▂█▃▅▂▄</td></tr><tr><td>Test Sensitivity</td><td>█████▅▂▁▁▁▂▂▃▂▅▄▄▅▆▄▆▆▄▅▅▄▄▄▅▅▄▅▆▅▅▇▇▄▅▇</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▅██████▇█▇█▇▇▇█▇▆█▇▇▇█▇▇▇█▇▇▇▇▄▅█▇▅</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▃▂▂▂▃▄▅▃▇▅▆▇▇▆▇▇▅██▇▆▇█▇▇▇███▆▇▆█▇</td></tr><tr><td>Train F1</td><td>▆▆▆▆▆▅▃▁▂▁▃▄▆▃▇▆▆▇█▆██▅██▇▇▇█▇▇▇███▇█▆██</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▅▇▄▄▄▃▃▄▂▂▅▂▂▃▄▃▂▂▃▂▁▁▂▄▁▄▁▁</td></tr><tr><td>Train Sensitivity</td><td>█████▄▂▁▁▁▂▃▄▂▆▄▅▆▆▄▆▇▄▆▆▅▄▅▆▅▅▅▇▆▆▇▇▄▆▇</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▅██████▇█▇██▇▇█▇▆█▇▇███████▇██▅▆██▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.73</td></tr><tr><td>Test F1</td><td>0.68966</td></tr><tr><td>Test Loss</td><td>0.5744</td></tr><tr><td>Test Sensitivity</td><td>0.58252</td></tr><tr><td>Test Specificity</td><td>0.8866</td></tr><tr><td>Train Accuracy</td><td>0.81034</td></tr><tr><td>Train F1</td><td>0.78537</td></tr><tr><td>Train Loss</td><td>0.45025</td></tr><tr><td>Train Sensitivity</td><td>0.65447</td></tr><tr><td>Train Specificity</td><td>0.98624</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-sweep-11</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mvm5pm4d' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mvm5pm4d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_171130-mvm5pm4d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3jr6rtdh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00040067005590311704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.23331406957444e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_171251-3jr6rtdh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/3jr6rtdh' target=\"_blank\">fallen-sweep-12</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/3jr6rtdh' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/3jr6rtdh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4677, Test Acc: 0.4900, Train Loss: 0.6934, Test Loss: 0.6932\n",
      "Epoch: 010, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6923, Test Loss: 0.6918\n",
      "Epoch: 020, Train Acc: 0.5065, Test Acc: 0.5200, Train Loss: 0.6910, Test Loss: 0.6892\n",
      "Epoch: 030, Train Acc: 0.5237, Test Acc: 0.5500, Train Loss: 0.6822, Test Loss: 0.6811\n",
      "Epoch: 040, Train Acc: 0.5690, Test Acc: 0.5850, Train Loss: 0.6515, Test Loss: 0.6590\n",
      "Epoch: 050, Train Acc: 0.6897, Test Acc: 0.6550, Train Loss: 0.5755, Test Loss: 0.6077\n",
      "Epoch: 060, Train Acc: 0.7629, Test Acc: 0.6650, Train Loss: 0.5122, Test Loss: 0.5733\n",
      "Epoch: 070, Train Acc: 0.6121, Test Acc: 0.6300, Train Loss: 0.7210, Test Loss: 0.7537\n",
      "Epoch: 080, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4607, Test Loss: 0.5510\n",
      "Epoch: 090, Train Acc: 0.8082, Test Acc: 0.7100, Train Loss: 0.4594, Test Loss: 0.5464\n",
      "Epoch: 100, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4349, Test Loss: 0.5388\n",
      "Epoch: 110, Train Acc: 0.7371, Test Acc: 0.7150, Train Loss: 0.5601, Test Loss: 0.6277\n",
      "Epoch: 120, Train Acc: 0.6659, Test Acc: 0.6700, Train Loss: 0.7236, Test Loss: 0.7745\n",
      "Epoch: 130, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4093, Test Loss: 0.5309\n",
      "Epoch: 140, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4887, Test Loss: 0.5754\n",
      "Epoch: 150, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.3824, Test Loss: 0.5241\n",
      "Epoch: 160, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4751, Test Loss: 0.5806\n",
      "Epoch: 170, Train Acc: 0.7522, Test Acc: 0.7150, Train Loss: 0.5550, Test Loss: 0.6449\n",
      "Epoch: 180, Train Acc: 0.7953, Test Acc: 0.7200, Train Loss: 0.4667, Test Loss: 0.5906\n",
      "Epoch: 190, Train Acc: 0.8685, Test Acc: 0.7700, Train Loss: 0.3588, Test Loss: 0.5270\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▃▁▂▃▂▃▃▄▆▅▅▄▅▅▆▆▆▇▇▆▅▆▇▇▇▇█▇▇█▇▇▆█▇▆▇</td></tr><tr><td>Test F1</td><td>▁▁▅▄▂▃▄▃▄▄▅▇▅▆▅▆▆▇▇▆▇▇▆▆▇█▇▇▇█▇▇██▇▇█▇██</td></tr><tr><td>Test Loss</td><td>▆▆▆▆▆▆▆▆▅▅▅▃▅▃▇▅▅▃▂▅▃▄▆█▃▁▂▂▂▁▂▂▁▁▂▅▁▄▄▂</td></tr><tr><td>Test Sensitivity</td><td>▁▁▄▃▁▂▃▂▃▃▃▆▄▅▄▄▅▅▆▅▅▅▅▄▅▇▆▆▆▇▆▆▇▆▆▅▇▆█▆</td></tr><tr><td>Test Specificity</td><td>██▃▇██▇███▇▅▇▆▇▇▇▆▆▇▇▇▇▇▇▄▆▆▆▅▆▆▅▆▆▇▅▇▁▆</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▁▂▃▂▃▂▃▆▄▆▄▅▅▆▇▅▆▆▅▅▆▇▇▇▇█▇▇██▇▆█▆▇█</td></tr><tr><td>Train F1</td><td>▁▁▅▃▁▃▄▃▄▃▄▇▅▇▅▆▆▇▇▆▇▆▆▆▇█▇████▇███▇█▇██</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▇▆▄▆▄█▆▆▄▃▆▄▅▆█▄▂▃▂▂▁▂▂▁▂▂▅▁▄▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁▁▄▂▁▂▃▂▃▂▃▆▄▅▃▄▄▅▆▄▅▅▄▄▅▇▆▆▆▇▆▆▇▇▇▅▇▅█▇</td></tr><tr><td>Train Specificity</td><td>██▁▇██▇███▇▅▇▆▇▇▇▇▆▇▇▇██▇▅▇▇▇▆▇▇▆▇▇█▇█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.775</td></tr><tr><td>Test F1</td><td>0.78049</td></tr><tr><td>Test Loss</td><td>0.54053</td></tr><tr><td>Test Sensitivity</td><td>0.7767</td></tr><tr><td>Test Specificity</td><td>0.7732</td></tr><tr><td>Train Accuracy</td><td>0.87069</td></tr><tr><td>Train F1</td><td>0.87395</td></tr><tr><td>Train Loss</td><td>0.35832</td></tr><tr><td>Train Sensitivity</td><td>0.84553</td></tr><tr><td>Train Specificity</td><td>0.89908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-12</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/3jr6rtdh' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/3jr6rtdh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_171251-3jr6rtdh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mrx15wjz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.7178444031073062e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0003088424167226442\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_171419-mrx15wjz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/mrx15wjz' target=\"_blank\">bright-sweep-13</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mrx15wjz' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mrx15wjz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6943\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6929\n",
      "Epoch: 020, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6924\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6903, Test Loss: 0.6918\n",
      "Epoch: 040, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6919\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6917\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6916\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6914\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6911\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6911\n",
      "Epoch: 100, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6888, Test Loss: 0.6908\n",
      "Epoch: 110, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6892, Test Loss: 0.6906\n",
      "Epoch: 120, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6887, Test Loss: 0.6905\n",
      "Epoch: 130, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6882, Test Loss: 0.6904\n",
      "Epoch: 140, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6902\n",
      "Epoch: 150, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6900\n",
      "Epoch: 160, Train Acc: 0.5409, Test Acc: 0.5250, Train Loss: 0.6873, Test Loss: 0.6898\n",
      "Epoch: 170, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6868, Test Loss: 0.6895\n",
      "Epoch: 180, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6870, Test Loss: 0.6890\n",
      "Epoch: 190, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6851, Test Loss: 0.6888\n",
      "Epoch: 200, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6885\n",
      "Epoch: 210, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6856, Test Loss: 0.6880\n",
      "Epoch: 220, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6849, Test Loss: 0.6877\n",
      "Epoch: 230, Train Acc: 0.5711, Test Acc: 0.5250, Train Loss: 0.6848, Test Loss: 0.6870\n",
      "Epoch: 240, Train Acc: 0.5603, Test Acc: 0.5200, Train Loss: 0.6832, Test Loss: 0.6866\n",
      "Epoch: 250, Train Acc: 0.5862, Test Acc: 0.5400, Train Loss: 0.6824, Test Loss: 0.6857\n",
      "Epoch: 260, Train Acc: 0.5560, Test Acc: 0.5100, Train Loss: 0.6815, Test Loss: 0.6854\n",
      "Epoch: 270, Train Acc: 0.5927, Test Acc: 0.5400, Train Loss: 0.6805, Test Loss: 0.6842\n",
      "Epoch: 280, Train Acc: 0.5884, Test Acc: 0.5300, Train Loss: 0.6797, Test Loss: 0.6834\n",
      "Epoch: 290, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6785, Test Loss: 0.6822\n",
      "Epoch: 300, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6769, Test Loss: 0.6813\n",
      "Epoch: 310, Train Acc: 0.5991, Test Acc: 0.5350, Train Loss: 0.6758, Test Loss: 0.6800\n",
      "Epoch: 320, Train Acc: 0.6056, Test Acc: 0.5350, Train Loss: 0.6738, Test Loss: 0.6785\n",
      "Epoch: 330, Train Acc: 0.6078, Test Acc: 0.5400, Train Loss: 0.6726, Test Loss: 0.6773\n",
      "Epoch: 340, Train Acc: 0.6078, Test Acc: 0.5600, Train Loss: 0.6710, Test Loss: 0.6756\n",
      "Epoch: 350, Train Acc: 0.6078, Test Acc: 0.5550, Train Loss: 0.6681, Test Loss: 0.6740\n",
      "Epoch: 360, Train Acc: 0.6121, Test Acc: 0.5600, Train Loss: 0.6669, Test Loss: 0.6724\n",
      "Epoch: 370, Train Acc: 0.6487, Test Acc: 0.5800, Train Loss: 0.6643, Test Loss: 0.6702\n",
      "Epoch: 380, Train Acc: 0.6703, Test Acc: 0.6000, Train Loss: 0.6619, Test Loss: 0.6680\n",
      "Epoch: 390, Train Acc: 0.6810, Test Acc: 0.6000, Train Loss: 0.6593, Test Loss: 0.6659\n",
      "Epoch: 400, Train Acc: 0.6746, Test Acc: 0.6050, Train Loss: 0.6568, Test Loss: 0.6638\n",
      "Epoch: 410, Train Acc: 0.6875, Test Acc: 0.6200, Train Loss: 0.6533, Test Loss: 0.6614\n",
      "Epoch: 420, Train Acc: 0.7026, Test Acc: 0.6250, Train Loss: 0.6519, Test Loss: 0.6588\n",
      "Epoch: 430, Train Acc: 0.7134, Test Acc: 0.6400, Train Loss: 0.6469, Test Loss: 0.6561\n",
      "Epoch: 440, Train Acc: 0.7198, Test Acc: 0.6750, Train Loss: 0.6431, Test Loss: 0.6530\n",
      "Epoch: 450, Train Acc: 0.7241, Test Acc: 0.6750, Train Loss: 0.6411, Test Loss: 0.6504\n",
      "Epoch: 460, Train Acc: 0.7371, Test Acc: 0.6650, Train Loss: 0.6359, Test Loss: 0.6473\n",
      "Epoch: 470, Train Acc: 0.7500, Test Acc: 0.6750, Train Loss: 0.6330, Test Loss: 0.6443\n",
      "Epoch: 480, Train Acc: 0.7522, Test Acc: 0.6850, Train Loss: 0.6277, Test Loss: 0.6412\n",
      "Epoch: 490, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6244, Test Loss: 0.6380\n",
      "Epoch: 500, Train Acc: 0.7565, Test Acc: 0.6750, Train Loss: 0.6195, Test Loss: 0.6348\n",
      "Epoch: 510, Train Acc: 0.7565, Test Acc: 0.6850, Train Loss: 0.6146, Test Loss: 0.6318\n",
      "Epoch: 520, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.6109, Test Loss: 0.6287\n",
      "Epoch: 530, Train Acc: 0.7565, Test Acc: 0.6900, Train Loss: 0.6073, Test Loss: 0.6252\n",
      "Epoch: 540, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.6025, Test Loss: 0.6223\n",
      "Epoch: 550, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5986, Test Loss: 0.6189\n",
      "Epoch: 560, Train Acc: 0.7608, Test Acc: 0.6900, Train Loss: 0.5939, Test Loss: 0.6161\n",
      "Epoch: 570, Train Acc: 0.7629, Test Acc: 0.7000, Train Loss: 0.5913, Test Loss: 0.6128\n",
      "Epoch: 580, Train Acc: 0.7672, Test Acc: 0.7000, Train Loss: 0.5861, Test Loss: 0.6100\n",
      "Epoch: 590, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5824, Test Loss: 0.6075\n",
      "Epoch: 600, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5789, Test Loss: 0.6047\n",
      "Epoch: 610, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5739, Test Loss: 0.6017\n",
      "Epoch: 620, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5687, Test Loss: 0.5993\n",
      "Epoch: 630, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5664, Test Loss: 0.5966\n",
      "Epoch: 640, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5611, Test Loss: 0.5947\n",
      "Epoch: 650, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5568, Test Loss: 0.5918\n",
      "Epoch: 660, Train Acc: 0.7651, Test Acc: 0.7000, Train Loss: 0.5536, Test Loss: 0.5911\n",
      "Epoch: 670, Train Acc: 0.7759, Test Acc: 0.7050, Train Loss: 0.5508, Test Loss: 0.5887\n",
      "Epoch: 680, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5490, Test Loss: 0.5864\n",
      "Epoch: 690, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5427, Test Loss: 0.5845\n",
      "Epoch: 700, Train Acc: 0.7823, Test Acc: 0.7000, Train Loss: 0.5408, Test Loss: 0.5818\n",
      "Epoch: 710, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.5389, Test Loss: 0.5809\n",
      "Epoch: 720, Train Acc: 0.7888, Test Acc: 0.6950, Train Loss: 0.5363, Test Loss: 0.5792\n",
      "Epoch: 730, Train Acc: 0.7888, Test Acc: 0.6950, Train Loss: 0.5317, Test Loss: 0.5778\n",
      "Epoch: 740, Train Acc: 0.7823, Test Acc: 0.7100, Train Loss: 0.5291, Test Loss: 0.5755\n",
      "Epoch: 750, Train Acc: 0.7866, Test Acc: 0.7050, Train Loss: 0.5256, Test Loss: 0.5748\n",
      "Epoch: 760, Train Acc: 0.7845, Test Acc: 0.7150, Train Loss: 0.5244, Test Loss: 0.5729\n",
      "Epoch: 770, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5227, Test Loss: 0.5720\n",
      "Epoch: 780, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.5187, Test Loss: 0.5709\n",
      "Epoch: 790, Train Acc: 0.7866, Test Acc: 0.7150, Train Loss: 0.5164, Test Loss: 0.5693\n",
      "Epoch: 800, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.5150, Test Loss: 0.5685\n",
      "Epoch: 810, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5112, Test Loss: 0.5668\n",
      "Epoch: 820, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.5108, Test Loss: 0.5667\n",
      "Epoch: 830, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.5063, Test Loss: 0.5655\n",
      "Epoch: 840, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.5024, Test Loss: 0.5648\n",
      "Epoch: 850, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.5008, Test Loss: 0.5638\n",
      "Epoch: 860, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.5025, Test Loss: 0.5632\n",
      "Epoch: 870, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.4988, Test Loss: 0.5618\n",
      "Epoch: 880, Train Acc: 0.7953, Test Acc: 0.7050, Train Loss: 0.4951, Test Loss: 0.5619\n",
      "Epoch: 890, Train Acc: 0.7931, Test Acc: 0.7050, Train Loss: 0.4950, Test Loss: 0.5606\n",
      "Epoch: 900, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.4944, Test Loss: 0.5594\n",
      "Epoch: 910, Train Acc: 0.7931, Test Acc: 0.7100, Train Loss: 0.4916, Test Loss: 0.5581\n",
      "Epoch: 920, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4902, Test Loss: 0.5596\n",
      "Epoch: 930, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.4890, Test Loss: 0.5574\n",
      "Epoch: 940, Train Acc: 0.8039, Test Acc: 0.7200, Train Loss: 0.4889, Test Loss: 0.5582\n",
      "Epoch: 950, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4875, Test Loss: 0.5581\n",
      "Epoch: 960, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4872, Test Loss: 0.5571\n",
      "Epoch: 970, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4861, Test Loss: 0.5559\n",
      "Epoch: 980, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4842, Test Loss: 0.5559\n",
      "Epoch: 990, Train Acc: 0.7931, Test Acc: 0.7050, Train Loss: 0.4814, Test Loss: 0.5532\n",
      "Epoch: 1000, Train Acc: 0.8039, Test Acc: 0.7200, Train Loss: 0.4784, Test Loss: 0.5551\n",
      "Epoch: 1010, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4817, Test Loss: 0.5549\n",
      "Epoch: 1020, Train Acc: 0.7953, Test Acc: 0.7100, Train Loss: 0.4780, Test Loss: 0.5505\n",
      "Epoch: 1030, Train Acc: 0.7931, Test Acc: 0.7050, Train Loss: 0.4765, Test Loss: 0.5506\n",
      "Epoch: 1040, Train Acc: 0.7953, Test Acc: 0.7100, Train Loss: 0.4779, Test Loss: 0.5495\n",
      "Epoch: 1050, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4735, Test Loss: 0.5532\n",
      "Epoch: 1060, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4716, Test Loss: 0.5507\n",
      "Epoch: 1070, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4692, Test Loss: 0.5500\n",
      "Epoch: 1080, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4698, Test Loss: 0.5487\n",
      "Epoch: 1090, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4680, Test Loss: 0.5487\n",
      "Epoch: 1100, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4662, Test Loss: 0.5504\n",
      "Epoch: 1110, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4693, Test Loss: 0.5484\n",
      "Epoch: 1120, Train Acc: 0.7996, Test Acc: 0.7350, Train Loss: 0.4686, Test Loss: 0.5465\n",
      "Epoch: 1130, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4681, Test Loss: 0.5468\n",
      "Epoch: 1140, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4634, Test Loss: 0.5461\n",
      "Epoch: 1150, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4618, Test Loss: 0.5464\n",
      "Epoch: 1160, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4623, Test Loss: 0.5460\n",
      "Epoch: 1170, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4626, Test Loss: 0.5465\n",
      "Epoch: 1180, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4591, Test Loss: 0.5440\n",
      "Epoch: 1190, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4602, Test Loss: 0.5438\n",
      "Epoch: 1200, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4592, Test Loss: 0.5454\n",
      "Epoch: 1210, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4578, Test Loss: 0.5432\n",
      "Epoch: 1220, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4586, Test Loss: 0.5418\n",
      "Epoch: 1230, Train Acc: 0.8017, Test Acc: 0.7350, Train Loss: 0.4571, Test Loss: 0.5442\n",
      "Epoch: 1240, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4573, Test Loss: 0.5407\n",
      "Epoch: 1250, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4567, Test Loss: 0.5409\n",
      "Epoch: 1260, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4524, Test Loss: 0.5405\n",
      "Epoch: 1270, Train Acc: 0.8039, Test Acc: 0.7350, Train Loss: 0.4545, Test Loss: 0.5406\n",
      "Epoch: 1280, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4507, Test Loss: 0.5403\n",
      "Epoch: 1290, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4510, Test Loss: 0.5405\n",
      "Epoch: 1300, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4498, Test Loss: 0.5400\n",
      "Epoch: 1310, Train Acc: 0.8039, Test Acc: 0.7350, Train Loss: 0.4459, Test Loss: 0.5404\n",
      "Epoch: 1320, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4489, Test Loss: 0.5378\n",
      "Epoch: 1330, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4436, Test Loss: 0.5363\n",
      "Epoch: 1340, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4463, Test Loss: 0.5368\n",
      "Epoch: 1350, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4460, Test Loss: 0.5362\n",
      "Epoch: 1360, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4450, Test Loss: 0.5359\n",
      "Epoch: 1370, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4448, Test Loss: 0.5390\n",
      "Epoch: 1380, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4451, Test Loss: 0.5349\n",
      "Epoch: 1390, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4422, Test Loss: 0.5355\n",
      "Epoch: 1400, Train Acc: 0.8082, Test Acc: 0.7450, Train Loss: 0.4415, Test Loss: 0.5364\n",
      "Epoch: 1410, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4477, Test Loss: 0.5342\n",
      "Epoch: 1420, Train Acc: 0.8060, Test Acc: 0.7450, Train Loss: 0.4455, Test Loss: 0.5379\n",
      "Epoch: 1430, Train Acc: 0.8060, Test Acc: 0.7450, Train Loss: 0.4425, Test Loss: 0.5374\n",
      "Epoch: 1440, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4401, Test Loss: 0.5356\n",
      "Epoch: 1450, Train Acc: 0.8082, Test Acc: 0.7450, Train Loss: 0.4394, Test Loss: 0.5350\n",
      "Epoch: 1460, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4361, Test Loss: 0.5326\n",
      "Epoch: 1470, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4351, Test Loss: 0.5340\n",
      "Epoch: 1480, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4382, Test Loss: 0.5315\n",
      "Epoch: 1490, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4271, Test Loss: 0.5308\n",
      "Epoch: 1500, Train Acc: 0.8082, Test Acc: 0.7450, Train Loss: 0.4331, Test Loss: 0.5322\n",
      "Epoch: 1510, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4349, Test Loss: 0.5303\n",
      "Epoch: 1520, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4367, Test Loss: 0.5317\n",
      "Epoch: 1530, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4352, Test Loss: 0.5311\n",
      "Epoch: 1540, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4324, Test Loss: 0.5307\n",
      "Epoch: 1550, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4332, Test Loss: 0.5302\n",
      "Epoch: 1560, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4329, Test Loss: 0.5286\n",
      "Epoch: 1570, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4324, Test Loss: 0.5315\n",
      "Epoch: 1580, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4288, Test Loss: 0.5305\n",
      "Epoch: 1590, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4296, Test Loss: 0.5288\n",
      "Epoch: 1600, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4335, Test Loss: 0.5275\n",
      "Epoch: 1610, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4275, Test Loss: 0.5276\n",
      "Epoch: 1620, Train Acc: 0.8125, Test Acc: 0.7600, Train Loss: 0.4280, Test Loss: 0.5344\n",
      "Epoch: 1630, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4279, Test Loss: 0.5287\n",
      "Epoch: 1640, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4276, Test Loss: 0.5277\n",
      "Epoch: 1650, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4281, Test Loss: 0.5268\n",
      "Epoch: 1660, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4252, Test Loss: 0.5281\n",
      "Epoch: 1670, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4282, Test Loss: 0.5252\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▂▃▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▂▂▃▄▄▃▃▃▃▃▄▄▄▃▅▄▆▅▅▅▆▆▆▇▆▇▇▇▇▇██</td></tr><tr><td>Test Loss</td><td>████████▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>███████▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▃▃▂▃▃▃▃▃▃▃</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▂▃▄▅▇▇▇▇█████████████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▂▃▄▅▆▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▂▂▂▂▃▄▅▆▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>████████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██▇▇▇▇▇▇▆▄▃▂▂▁▁▁▁▁▁▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▂▂▃▅▆▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.76</td></tr><tr><td>Test F1</td><td>0.77143</td></tr><tr><td>Test Loss</td><td>0.52817</td></tr><tr><td>Test Sensitivity</td><td>0.78641</td></tr><tr><td>Test Specificity</td><td>0.73196</td></tr><tr><td>Train Accuracy</td><td>0.81681</td></tr><tr><td>Train F1</td><td>0.82328</td></tr><tr><td>Train Loss</td><td>0.41858</td></tr><tr><td>Train Sensitivity</td><td>0.80488</td></tr><tr><td>Train Specificity</td><td>0.83028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-sweep-13</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mrx15wjz' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mrx15wjz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_171419-mrx15wjz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g78gvhl1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005031187338096101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.899141543469958e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_172109-g78gvhl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/g78gvhl1' target=\"_blank\">autumn-sweep-14</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/g78gvhl1' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/g78gvhl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6927\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6910\n",
      "Epoch: 020, Train Acc: 0.5474, Test Acc: 0.5600, Train Loss: 0.6881, Test Loss: 0.6867\n",
      "Epoch: 030, Train Acc: 0.5733, Test Acc: 0.5900, Train Loss: 0.6686, Test Loss: 0.6684\n",
      "Epoch: 040, Train Acc: 0.5819, Test Acc: 0.5950, Train Loss: 0.6453, Test Loss: 0.6527\n",
      "Epoch: 050, Train Acc: 0.7091, Test Acc: 0.6500, Train Loss: 0.5493, Test Loss: 0.5819\n",
      "Epoch: 060, Train Acc: 0.6509, Test Acc: 0.6500, Train Loss: 0.6322, Test Loss: 0.6666\n",
      "Epoch: 070, Train Acc: 0.7004, Test Acc: 0.6750, Train Loss: 0.5834, Test Loss: 0.6273\n",
      "Epoch: 080, Train Acc: 0.7478, Test Acc: 0.7000, Train Loss: 0.5219, Test Loss: 0.5802\n",
      "Epoch: 090, Train Acc: 0.5948, Test Acc: 0.6350, Train Loss: 0.8788, Test Loss: 0.8981\n",
      "Epoch: 100, Train Acc: 0.7522, Test Acc: 0.7200, Train Loss: 0.5330, Test Loss: 0.5803\n",
      "Epoch: 110, Train Acc: 0.7478, Test Acc: 0.7150, Train Loss: 0.5473, Test Loss: 0.5944\n",
      "Epoch: 120, Train Acc: 0.6983, Test Acc: 0.7200, Train Loss: 0.6252, Test Loss: 0.6729\n",
      "Epoch: 130, Train Acc: 0.6659, Test Acc: 0.7050, Train Loss: 0.7171, Test Loss: 0.7459\n",
      "Epoch: 140, Train Acc: 0.7371, Test Acc: 0.7250, Train Loss: 0.5648, Test Loss: 0.6337\n",
      "Epoch: 150, Train Acc: 0.7931, Test Acc: 0.7350, Train Loss: 0.4659, Test Loss: 0.5618\n",
      "Epoch: 160, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3786, Test Loss: 0.5160\n",
      "Epoch: 170, Train Acc: 0.7500, Test Acc: 0.6400, Train Loss: 0.4759, Test Loss: 0.6592\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▁▁▁▃▃▃▃▅▅▄▅▅▅▆▆▆▆▆▅▇▄▅▄▅▇▅▇▇▇▇▇▆▅▅▇▇█</td></tr><tr><td>Test F1</td><td>▁▆▇▁▂▁▄▄▄▄▆▆▅▆▇▆▇▆▆▇▇▅█▅▅▅▆█▇██▇██▇▅▆▇██</td></tr><tr><td>Test Loss</td><td>▄▄▄▄▄▄▄▃▃▃▂▂▄▂▂▃▁▂▂▃▂▅▁█▆█▅▁▄▁▁▁▁▁▄█▆▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▆█▁▁▁▂▂▂▃▄▄▃▄▅▄▅▅▅▄▅▃▇▃▃▃▄▇▇▇▆▅▆▆▅▃▄▅▇▇</td></tr><tr><td>Test Specificity</td><td>█▃▁███████▇▇█▇▇█▇▇▇█▇█▆████▆▄▆▇▇▇▇███▇▆▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▁▁▁▂▂▃▃▅▆▄▅▆▅▇▆▆▆▆▄▇▃▄▄▅▇▅▇█▇██▅▄▅▇██</td></tr><tr><td>Train F1</td><td>▁▆▇▁▁▁▃▃▃▄▆▇▅▆▇▆▇▇▇▆▇▅█▄▅▄▅█▇██▇██▆▅▅▇██</td></tr><tr><td>Train Loss</td><td>▅▅▅▅▅▅▅▅▄▄▃▃▅▃▃▄▂▃▃▃▃▅▂█▆█▆▂▃▂▁▂▁▁▄▇▆▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▆█▁▁▁▂▂▂▃▅▅▃▅▆▄▆▅▅▅▅▄▇▃▃▃▄▇█▇▆▆▇▆▄▃▄▆▇▇</td></tr><tr><td>Train Specificity</td><td>█▃▁███████▇▇██▇█▇█████▆████▇▄▆▇█▇█████▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.8</td></tr><tr><td>Test F1</td><td>0.80392</td></tr><tr><td>Test Loss</td><td>0.51762</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.80412</td></tr><tr><td>Train Accuracy</td><td>0.85345</td></tr><tr><td>Train F1</td><td>0.85714</td></tr><tr><td>Train Loss</td><td>0.36677</td></tr><tr><td>Train Sensitivity</td><td>0.82927</td></tr><tr><td>Train Specificity</td><td>0.88073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-14</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/g78gvhl1' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/g78gvhl1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_172109-g78gvhl1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fxkrqp41 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6046745452785206e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.3822305040660817e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_172226-fxkrqp41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/fxkrqp41' target=\"_blank\">giddy-sweep-15</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/fxkrqp41' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/fxkrqp41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6938, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5151, Test Acc: 0.5100, Train Loss: 0.6927, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.4800, Train Loss: 0.6910, Test Loss: 0.6911\n",
      "Epoch: 030, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6909\n",
      "Epoch: 040, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6904\n",
      "Epoch: 050, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6882, Test Loss: 0.6904\n",
      "Epoch: 060, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6899\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6900\n",
      "Epoch: 080, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6891\n",
      "Epoch: 090, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6890\n",
      "Epoch: 100, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6888\n",
      "Epoch: 110, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6856, Test Loss: 0.6885\n",
      "Epoch: 120, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6879\n",
      "Epoch: 130, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6877\n",
      "Epoch: 140, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6843, Test Loss: 0.6872\n",
      "Epoch: 150, Train Acc: 0.5496, Test Acc: 0.5300, Train Loss: 0.6841, Test Loss: 0.6867\n",
      "Epoch: 160, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6835, Test Loss: 0.6862\n",
      "Epoch: 170, Train Acc: 0.5647, Test Acc: 0.5300, Train Loss: 0.6828, Test Loss: 0.6856\n",
      "Epoch: 180, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6820, Test Loss: 0.6853\n",
      "Epoch: 190, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6816, Test Loss: 0.6847\n",
      "Epoch: 200, Train Acc: 0.5927, Test Acc: 0.5400, Train Loss: 0.6800, Test Loss: 0.6837\n",
      "Epoch: 210, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6792, Test Loss: 0.6831\n",
      "Epoch: 220, Train Acc: 0.5711, Test Acc: 0.5250, Train Loss: 0.6787, Test Loss: 0.6826\n",
      "Epoch: 230, Train Acc: 0.5647, Test Acc: 0.5250, Train Loss: 0.6774, Test Loss: 0.6819\n",
      "Epoch: 240, Train Acc: 0.6250, Test Acc: 0.5450, Train Loss: 0.6761, Test Loss: 0.6805\n",
      "Epoch: 250, Train Acc: 0.6013, Test Acc: 0.5300, Train Loss: 0.6754, Test Loss: 0.6799\n",
      "Epoch: 260, Train Acc: 0.6013, Test Acc: 0.5300, Train Loss: 0.6738, Test Loss: 0.6788\n",
      "Epoch: 270, Train Acc: 0.6250, Test Acc: 0.5650, Train Loss: 0.6731, Test Loss: 0.6772\n",
      "Epoch: 280, Train Acc: 0.6336, Test Acc: 0.5700, Train Loss: 0.6712, Test Loss: 0.6761\n",
      "Epoch: 290, Train Acc: 0.6358, Test Acc: 0.5550, Train Loss: 0.6688, Test Loss: 0.6749\n",
      "Epoch: 300, Train Acc: 0.6466, Test Acc: 0.5700, Train Loss: 0.6666, Test Loss: 0.6732\n",
      "Epoch: 310, Train Acc: 0.6466, Test Acc: 0.5650, Train Loss: 0.6659, Test Loss: 0.6717\n",
      "Epoch: 320, Train Acc: 0.6552, Test Acc: 0.5800, Train Loss: 0.6630, Test Loss: 0.6701\n",
      "Epoch: 330, Train Acc: 0.6552, Test Acc: 0.5650, Train Loss: 0.6601, Test Loss: 0.6685\n",
      "Epoch: 340, Train Acc: 0.6961, Test Acc: 0.6100, Train Loss: 0.6576, Test Loss: 0.6659\n",
      "Epoch: 350, Train Acc: 0.6897, Test Acc: 0.6150, Train Loss: 0.6560, Test Loss: 0.6642\n",
      "Epoch: 360, Train Acc: 0.7047, Test Acc: 0.6200, Train Loss: 0.6529, Test Loss: 0.6617\n",
      "Epoch: 370, Train Acc: 0.7134, Test Acc: 0.6150, Train Loss: 0.6499, Test Loss: 0.6594\n",
      "Epoch: 380, Train Acc: 0.7177, Test Acc: 0.6300, Train Loss: 0.6458, Test Loss: 0.6570\n",
      "Epoch: 390, Train Acc: 0.7371, Test Acc: 0.6500, Train Loss: 0.6429, Test Loss: 0.6541\n",
      "Epoch: 400, Train Acc: 0.7392, Test Acc: 0.6650, Train Loss: 0.6387, Test Loss: 0.6515\n",
      "Epoch: 410, Train Acc: 0.7435, Test Acc: 0.6650, Train Loss: 0.6355, Test Loss: 0.6492\n",
      "Epoch: 420, Train Acc: 0.7435, Test Acc: 0.6750, Train Loss: 0.6304, Test Loss: 0.6461\n",
      "Epoch: 430, Train Acc: 0.7522, Test Acc: 0.6550, Train Loss: 0.6276, Test Loss: 0.6429\n",
      "Epoch: 440, Train Acc: 0.7500, Test Acc: 0.6700, Train Loss: 0.6232, Test Loss: 0.6397\n",
      "Epoch: 450, Train Acc: 0.7565, Test Acc: 0.6700, Train Loss: 0.6190, Test Loss: 0.6367\n",
      "Epoch: 460, Train Acc: 0.7629, Test Acc: 0.6700, Train Loss: 0.6138, Test Loss: 0.6337\n",
      "Epoch: 470, Train Acc: 0.7651, Test Acc: 0.6700, Train Loss: 0.6115, Test Loss: 0.6305\n",
      "Epoch: 480, Train Acc: 0.7716, Test Acc: 0.6650, Train Loss: 0.6061, Test Loss: 0.6276\n",
      "Epoch: 490, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.6024, Test Loss: 0.6242\n",
      "Epoch: 500, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.5965, Test Loss: 0.6211\n",
      "Epoch: 510, Train Acc: 0.7651, Test Acc: 0.6750, Train Loss: 0.5919, Test Loss: 0.6180\n",
      "Epoch: 520, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.5873, Test Loss: 0.6149\n",
      "Epoch: 530, Train Acc: 0.7694, Test Acc: 0.6800, Train Loss: 0.5820, Test Loss: 0.6126\n",
      "Epoch: 540, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5778, Test Loss: 0.6093\n",
      "Epoch: 550, Train Acc: 0.7759, Test Acc: 0.6700, Train Loss: 0.5732, Test Loss: 0.6063\n",
      "Epoch: 560, Train Acc: 0.7780, Test Acc: 0.6750, Train Loss: 0.5699, Test Loss: 0.6037\n",
      "Epoch: 570, Train Acc: 0.7802, Test Acc: 0.6650, Train Loss: 0.5643, Test Loss: 0.6013\n",
      "Epoch: 580, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5603, Test Loss: 0.5993\n",
      "Epoch: 590, Train Acc: 0.7823, Test Acc: 0.6750, Train Loss: 0.5569, Test Loss: 0.5966\n",
      "Epoch: 600, Train Acc: 0.7823, Test Acc: 0.6700, Train Loss: 0.5526, Test Loss: 0.5938\n",
      "Epoch: 610, Train Acc: 0.7888, Test Acc: 0.6700, Train Loss: 0.5498, Test Loss: 0.5920\n",
      "Epoch: 620, Train Acc: 0.7909, Test Acc: 0.6800, Train Loss: 0.5439, Test Loss: 0.5902\n",
      "Epoch: 630, Train Acc: 0.7888, Test Acc: 0.6750, Train Loss: 0.5409, Test Loss: 0.5878\n",
      "Epoch: 640, Train Acc: 0.7866, Test Acc: 0.6750, Train Loss: 0.5361, Test Loss: 0.5860\n",
      "Epoch: 650, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5324, Test Loss: 0.5849\n",
      "Epoch: 660, Train Acc: 0.7845, Test Acc: 0.6850, Train Loss: 0.5301, Test Loss: 0.5821\n",
      "Epoch: 670, Train Acc: 0.7823, Test Acc: 0.6750, Train Loss: 0.5293, Test Loss: 0.5802\n",
      "Epoch: 680, Train Acc: 0.7823, Test Acc: 0.6650, Train Loss: 0.5258, Test Loss: 0.5786\n",
      "Epoch: 690, Train Acc: 0.7823, Test Acc: 0.6700, Train Loss: 0.5220, Test Loss: 0.5773\n",
      "Epoch: 700, Train Acc: 0.7866, Test Acc: 0.6800, Train Loss: 0.5174, Test Loss: 0.5759\n",
      "Epoch: 710, Train Acc: 0.7909, Test Acc: 0.6800, Train Loss: 0.5160, Test Loss: 0.5747\n",
      "Epoch: 720, Train Acc: 0.7931, Test Acc: 0.6800, Train Loss: 0.5146, Test Loss: 0.5737\n",
      "Epoch: 730, Train Acc: 0.7931, Test Acc: 0.6750, Train Loss: 0.5117, Test Loss: 0.5724\n",
      "Epoch: 740, Train Acc: 0.7953, Test Acc: 0.6800, Train Loss: 0.5070, Test Loss: 0.5707\n",
      "Epoch: 750, Train Acc: 0.7953, Test Acc: 0.6800, Train Loss: 0.5039, Test Loss: 0.5696\n",
      "Epoch: 760, Train Acc: 0.7931, Test Acc: 0.6800, Train Loss: 0.5024, Test Loss: 0.5687\n",
      "Epoch: 770, Train Acc: 0.7909, Test Acc: 0.6850, Train Loss: 0.5009, Test Loss: 0.5682\n",
      "Epoch: 780, Train Acc: 0.7953, Test Acc: 0.6900, Train Loss: 0.4973, Test Loss: 0.5669\n",
      "Epoch: 790, Train Acc: 0.7996, Test Acc: 0.6850, Train Loss: 0.4959, Test Loss: 0.5658\n",
      "Epoch: 800, Train Acc: 0.8017, Test Acc: 0.6800, Train Loss: 0.4932, Test Loss: 0.5645\n",
      "Epoch: 810, Train Acc: 0.8039, Test Acc: 0.6850, Train Loss: 0.4916, Test Loss: 0.5638\n",
      "Epoch: 820, Train Acc: 0.7953, Test Acc: 0.7000, Train Loss: 0.4847, Test Loss: 0.5642\n",
      "Epoch: 830, Train Acc: 0.8039, Test Acc: 0.6900, Train Loss: 0.4860, Test Loss: 0.5621\n",
      "Epoch: 840, Train Acc: 0.8017, Test Acc: 0.6850, Train Loss: 0.4884, Test Loss: 0.5610\n",
      "Epoch: 850, Train Acc: 0.8039, Test Acc: 0.6900, Train Loss: 0.4802, Test Loss: 0.5603\n",
      "Epoch: 860, Train Acc: 0.8039, Test Acc: 0.6950, Train Loss: 0.4826, Test Loss: 0.5597\n",
      "Epoch: 870, Train Acc: 0.8039, Test Acc: 0.6950, Train Loss: 0.4831, Test Loss: 0.5589\n",
      "Epoch: 880, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4770, Test Loss: 0.5587\n",
      "Epoch: 890, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4780, Test Loss: 0.5576\n",
      "Epoch: 900, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4727, Test Loss: 0.5568\n",
      "Epoch: 910, Train Acc: 0.8017, Test Acc: 0.7150, Train Loss: 0.4771, Test Loss: 0.5562\n",
      "Epoch: 920, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4723, Test Loss: 0.5575\n",
      "Epoch: 930, Train Acc: 0.8060, Test Acc: 0.7100, Train Loss: 0.4715, Test Loss: 0.5561\n",
      "Epoch: 940, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4707, Test Loss: 0.5549\n",
      "Epoch: 950, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4672, Test Loss: 0.5546\n",
      "Epoch: 960, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4657, Test Loss: 0.5540\n",
      "Epoch: 970, Train Acc: 0.8082, Test Acc: 0.7100, Train Loss: 0.4669, Test Loss: 0.5528\n",
      "Epoch: 980, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4662, Test Loss: 0.5528\n",
      "Epoch: 990, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4617, Test Loss: 0.5523\n",
      "Epoch: 1000, Train Acc: 0.8103, Test Acc: 0.7250, Train Loss: 0.4593, Test Loss: 0.5529\n",
      "Epoch: 1010, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4567, Test Loss: 0.5519\n",
      "Epoch: 1020, Train Acc: 0.8103, Test Acc: 0.7250, Train Loss: 0.4596, Test Loss: 0.5510\n",
      "Epoch: 1030, Train Acc: 0.8082, Test Acc: 0.7250, Train Loss: 0.4581, Test Loss: 0.5514\n",
      "Epoch: 1040, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4582, Test Loss: 0.5504\n",
      "Epoch: 1050, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4505, Test Loss: 0.5490\n",
      "Epoch: 1060, Train Acc: 0.8103, Test Acc: 0.7250, Train Loss: 0.4545, Test Loss: 0.5491\n",
      "Epoch: 1070, Train Acc: 0.8103, Test Acc: 0.7250, Train Loss: 0.4541, Test Loss: 0.5489\n",
      "Epoch: 1080, Train Acc: 0.8125, Test Acc: 0.7250, Train Loss: 0.4562, Test Loss: 0.5517\n",
      "Epoch: 1090, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4481, Test Loss: 0.5494\n",
      "Epoch: 1100, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4514, Test Loss: 0.5496\n",
      "Epoch: 1110, Train Acc: 0.8147, Test Acc: 0.7250, Train Loss: 0.4452, Test Loss: 0.5468\n",
      "Epoch: 1120, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4485, Test Loss: 0.5459\n",
      "Epoch: 1130, Train Acc: 0.8190, Test Acc: 0.7300, Train Loss: 0.4428, Test Loss: 0.5452\n",
      "Epoch: 1140, Train Acc: 0.8147, Test Acc: 0.7300, Train Loss: 0.4438, Test Loss: 0.5464\n",
      "Epoch: 1150, Train Acc: 0.8168, Test Acc: 0.7350, Train Loss: 0.4442, Test Loss: 0.5465\n",
      "Epoch: 1160, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4435, Test Loss: 0.5488\n",
      "Epoch: 1170, Train Acc: 0.8190, Test Acc: 0.7400, Train Loss: 0.4410, Test Loss: 0.5464\n",
      "Epoch: 1180, Train Acc: 0.8190, Test Acc: 0.7300, Train Loss: 0.4428, Test Loss: 0.5443\n",
      "Epoch: 1190, Train Acc: 0.8211, Test Acc: 0.7350, Train Loss: 0.4426, Test Loss: 0.5446\n",
      "Epoch: 1200, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.4356, Test Loss: 0.5452\n",
      "Epoch: 1210, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.4343, Test Loss: 0.5437\n",
      "Epoch: 1220, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.4393, Test Loss: 0.5448\n",
      "Epoch: 1230, Train Acc: 0.8168, Test Acc: 0.7300, Train Loss: 0.4326, Test Loss: 0.5411\n",
      "Epoch: 1240, Train Acc: 0.8233, Test Acc: 0.7300, Train Loss: 0.4326, Test Loss: 0.5421\n",
      "Epoch: 1250, Train Acc: 0.8211, Test Acc: 0.7250, Train Loss: 0.4370, Test Loss: 0.5399\n",
      "Epoch: 1260, Train Acc: 0.8233, Test Acc: 0.7300, Train Loss: 0.4348, Test Loss: 0.5406\n",
      "Epoch: 1270, Train Acc: 0.8254, Test Acc: 0.7300, Train Loss: 0.4342, Test Loss: 0.5394\n",
      "Epoch: 1280, Train Acc: 0.8254, Test Acc: 0.7350, Train Loss: 0.4301, Test Loss: 0.5401\n",
      "Epoch: 1290, Train Acc: 0.8254, Test Acc: 0.7300, Train Loss: 0.4312, Test Loss: 0.5390\n",
      "Epoch: 1300, Train Acc: 0.8254, Test Acc: 0.7350, Train Loss: 0.4345, Test Loss: 0.5394\n",
      "Epoch: 1310, Train Acc: 0.8233, Test Acc: 0.7400, Train Loss: 0.4293, Test Loss: 0.5385\n",
      "Epoch: 1320, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4287, Test Loss: 0.5400\n",
      "Epoch: 1330, Train Acc: 0.8254, Test Acc: 0.7400, Train Loss: 0.4268, Test Loss: 0.5382\n",
      "Epoch: 1340, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4232, Test Loss: 0.5392\n",
      "Epoch: 1350, Train Acc: 0.8276, Test Acc: 0.7400, Train Loss: 0.4247, Test Loss: 0.5376\n",
      "Epoch: 1360, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4281, Test Loss: 0.5391\n",
      "Epoch: 1370, Train Acc: 0.8297, Test Acc: 0.7450, Train Loss: 0.4232, Test Loss: 0.5372\n",
      "Epoch: 1380, Train Acc: 0.8319, Test Acc: 0.7400, Train Loss: 0.4254, Test Loss: 0.5364\n",
      "Epoch: 1390, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4242, Test Loss: 0.5387\n",
      "Epoch: 1400, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4215, Test Loss: 0.5402\n",
      "Epoch: 1410, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4203, Test Loss: 0.5371\n",
      "Epoch: 1420, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4200, Test Loss: 0.5360\n",
      "Epoch: 1430, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4190, Test Loss: 0.5360\n",
      "Epoch: 1440, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4208, Test Loss: 0.5361\n",
      "Epoch: 1450, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4224, Test Loss: 0.5361\n",
      "Epoch: 1460, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4169, Test Loss: 0.5347\n",
      "Epoch: 1470, Train Acc: 0.8319, Test Acc: 0.7500, Train Loss: 0.4159, Test Loss: 0.5332\n",
      "Epoch: 1480, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4182, Test Loss: 0.5333\n",
      "Epoch: 1490, Train Acc: 0.8341, Test Acc: 0.7500, Train Loss: 0.4156, Test Loss: 0.5339\n",
      "Epoch: 1500, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4155, Test Loss: 0.5358\n",
      "Epoch: 1510, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4144, Test Loss: 0.5383\n",
      "Epoch: 1520, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.4103, Test Loss: 0.5342\n",
      "Epoch: 1530, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4118, Test Loss: 0.5326\n",
      "Epoch: 1540, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.4138, Test Loss: 0.5345\n",
      "Epoch: 1550, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4102, Test Loss: 0.5352\n",
      "Epoch: 1560, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4075, Test Loss: 0.5363\n",
      "Epoch: 1570, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4092, Test Loss: 0.5363\n",
      "Epoch: 1580, Train Acc: 0.8384, Test Acc: 0.7650, Train Loss: 0.4072, Test Loss: 0.5335\n",
      "Epoch: 1590, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.4069, Test Loss: 0.5321\n",
      "Epoch: 1600, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4065, Test Loss: 0.5314\n",
      "Epoch: 1610, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4008, Test Loss: 0.5358\n",
      "Epoch: 1620, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4060, Test Loss: 0.5360\n",
      "Epoch: 1630, Train Acc: 0.8233, Test Acc: 0.7650, Train Loss: 0.4053, Test Loss: 0.5381\n",
      "Epoch: 1640, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.4063, Test Loss: 0.5308\n",
      "Epoch: 1650, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4022, Test Loss: 0.5295\n",
      "Epoch: 1660, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4019, Test Loss: 0.5296\n",
      "Epoch: 1670, Train Acc: 0.8384, Test Acc: 0.7600, Train Loss: 0.4043, Test Loss: 0.5323\n",
      "Epoch: 1680, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3998, Test Loss: 0.5306\n",
      "Epoch: 1690, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3981, Test Loss: 0.5326\n",
      "Epoch: 1700, Train Acc: 0.8297, Test Acc: 0.7750, Train Loss: 0.4003, Test Loss: 0.5365\n",
      "Epoch: 1710, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.4028, Test Loss: 0.5336\n",
      "Epoch: 1720, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.4008, Test Loss: 0.5311\n",
      "Epoch: 1730, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4032, Test Loss: 0.5278\n",
      "Epoch: 1740, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.3962, Test Loss: 0.5289\n",
      "Epoch: 1750, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3998, Test Loss: 0.5295\n",
      "Epoch: 1760, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.3999, Test Loss: 0.5277\n",
      "Epoch: 1770, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.3934, Test Loss: 0.5280\n",
      "Epoch: 1780, Train Acc: 0.8384, Test Acc: 0.7700, Train Loss: 0.3957, Test Loss: 0.5293\n",
      "Epoch: 1790, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.3939, Test Loss: 0.5281\n",
      "Epoch: 1800, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.3948, Test Loss: 0.5315\n",
      "Epoch: 1810, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3940, Test Loss: 0.5291\n",
      "Epoch: 1820, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.3947, Test Loss: 0.5300\n",
      "Epoch: 1830, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3929, Test Loss: 0.5301\n",
      "Epoch: 1840, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.3946, Test Loss: 0.5268\n",
      "Epoch: 1850, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.3977, Test Loss: 0.5267\n",
      "Epoch: 1860, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3938, Test Loss: 0.5283\n",
      "Epoch: 1870, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.3884, Test Loss: 0.5297\n",
      "Epoch: 1880, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.3902, Test Loss: 0.5339\n",
      "Epoch: 1890, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.3868, Test Loss: 0.5337\n",
      "Epoch: 1900, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3870, Test Loss: 0.5305\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▂▂▃▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇███▇████</td></tr><tr><td>Test F1</td><td>▁▄▄▄▄▄▅▄▅▅▅▅▄▄▆▄▅▆▅▆▆▆▆▆▆▇▇▇▇▇█▇███▇█▇██</td></tr><tr><td>Test Loss</td><td>█████▇▇▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▂████▆▇▅▃▃▂▃▁▁▂▁▁▂▂▂▃▂▂▂▂▃▃▂▃▃▃▂▄▃▄▂▃▃▃▃</td></tr><tr><td>Test Specificity</td><td>▃▁▁▁▁▂▂▄▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▂▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train F1</td><td>▁▄▄▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁████▇▇▅▄▄▃▃▃▃▃▃▃▃▃▃▄▃▃▃▄▄▄▄▄▄▄▄▄▄▄▃▄▃▄▄</td></tr><tr><td>Train Specificity</td><td>▃▁▁▁▂▃▃▅▆▆▇▇▇▇▇▇▇▇█▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.765</td></tr><tr><td>Test F1</td><td>0.77295</td></tr><tr><td>Test Loss</td><td>0.53055</td></tr><tr><td>Test Sensitivity</td><td>0.7767</td></tr><tr><td>Test Specificity</td><td>0.75258</td></tr><tr><td>Train Accuracy</td><td>0.83621</td></tr><tr><td>Train F1</td><td>0.841</td></tr><tr><td>Train Loss</td><td>0.38698</td></tr><tr><td>Train Sensitivity</td><td>0.81707</td></tr><tr><td>Train Specificity</td><td>0.8578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-15</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/fxkrqp41' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/fxkrqp41</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_172226-fxkrqp41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4vde3n8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004644189266635635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0004272354041457983\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_173308-o4vde3n8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/o4vde3n8' target=\"_blank\">stilted-sweep-16</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/o4vde3n8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/o4vde3n8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6927\n",
      "Epoch: 010, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6907\n",
      "Epoch: 020, Train Acc: 0.4978, Test Acc: 0.5250, Train Loss: 0.6892, Test Loss: 0.6871\n",
      "Epoch: 030, Train Acc: 0.5582, Test Acc: 0.5900, Train Loss: 0.6639, Test Loss: 0.6641\n",
      "Epoch: 040, Train Acc: 0.5797, Test Acc: 0.5950, Train Loss: 0.6547, Test Loss: 0.6656\n",
      "Epoch: 050, Train Acc: 0.7177, Test Acc: 0.6500, Train Loss: 0.5441, Test Loss: 0.5794\n",
      "Epoch: 060, Train Acc: 0.6940, Test Acc: 0.6700, Train Loss: 0.5733, Test Loss: 0.6171\n",
      "Epoch: 070, Train Acc: 0.7414, Test Acc: 0.6950, Train Loss: 0.5262, Test Loss: 0.5855\n",
      "Epoch: 080, Train Acc: 0.7500, Test Acc: 0.7050, Train Loss: 0.5210, Test Loss: 0.5842\n",
      "Epoch: 090, Train Acc: 0.5862, Test Acc: 0.6250, Train Loss: 0.9760, Test Loss: 0.9932\n",
      "Epoch: 100, Train Acc: 0.6638, Test Acc: 0.6700, Train Loss: 0.7085, Test Loss: 0.7404\n",
      "Epoch: 110, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4482, Test Loss: 0.5243\n",
      "Epoch: 120, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4383, Test Loss: 0.5282\n",
      "Epoch: 130, Train Acc: 0.7672, Test Acc: 0.7300, Train Loss: 0.5256, Test Loss: 0.5976\n",
      "Epoch: 140, Train Acc: 0.7931, Test Acc: 0.7400, Train Loss: 0.4555, Test Loss: 0.5566\n",
      "Epoch: 150, Train Acc: 0.7888, Test Acc: 0.7350, Train Loss: 0.4763, Test Loss: 0.5714\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▁▃▃▁▁▂▂▃▅▄▅▆▇▆▄▇▆▇▆▆▇▆▆██▆▇▇▅▅▇▆▇█▆███</td></tr><tr><td>Test F1</td><td>▁▇▁▄▆▂▁▂▂▄▆▅▇▆█▇▅▇▇▇▆▆▇▇▆██▇██▆▆▇█▇█████</td></tr><tr><td>Test Loss</td><td>▅▅▅▅▅▅▅▅▅▄▃▄▂▂▂▂▅▂▂▂▅▅▃▂▅▂▁▃▂▁▇█▂▂▂▁▂▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁█▁▂▅▁▁▂▂▂▄▃▅▄▆▅▃▅▅▅▄▄▅▅▄▇▆▅▇▆▄▃▅▇▅▆▇▆▆▆</td></tr><tr><td>Test Specificity</td><td>█▁█▇▄█████▇█▇▇▆▇█▇▇▇██▇▇█▆▆▇▅▇██▇▅▇▇▅▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▁▂▃▁▁▂▂▂▄▄▆▆▆▆▄▇▇▇▅▅▆▇▅▇▇▆▇█▄▄▇▇▇█▇███</td></tr><tr><td>Train F1</td><td>▁▇▁▃▆▁▁▂▂▃▆▅▇▇▇▇▅█▇▇▆▆▇▇▆██▇██▅▅▇███████</td></tr><tr><td>Train Loss</td><td>▆▆▆▆▆▆▆▆▆▆▅▅▃▄▃▃▆▃▃▃▅▆▄▃▅▂▂▄▂▂▇█▃▂▂▁▂▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁█▁▂▅▁▁▂▂▂▄▃▅▅▇▆▃▆▆▆▄▄▅▅▄▇▇▅▇▆▄▃▅▇▆▆▇▆▆▇</td></tr><tr><td>Train Specificity</td><td>█▁█▇▅█████▇█▇▇▆▇█▇▇▇█████▆▇█▆▇███▆█▇▆█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.77</td></tr><tr><td>Test Loss</td><td>0.52085</td></tr><tr><td>Test Sensitivity</td><td>0.74757</td></tr><tr><td>Test Specificity</td><td>0.79381</td></tr><tr><td>Train Accuracy</td><td>0.84483</td></tr><tr><td>Train F1</td><td>0.84681</td></tr><tr><td>Train Loss</td><td>0.37818</td></tr><tr><td>Train Sensitivity</td><td>0.80894</td></tr><tr><td>Train Specificity</td><td>0.88532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-16</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/o4vde3n8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/o4vde3n8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_173308-o4vde3n8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jc8ccsr5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.665120784663065e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.280513388028112e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_173415-jc8ccsr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/jc8ccsr5' target=\"_blank\">spring-sweep-17</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/jc8ccsr5' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/jc8ccsr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6944\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6938\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6932\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6929\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6928\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6926\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6925\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6925\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6924\n",
      "Epoch: 090, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6924\n",
      "Epoch: 100, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6923\n",
      "Epoch: 110, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6923\n",
      "Epoch: 120, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6922\n",
      "Epoch: 130, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6922\n",
      "Epoch: 140, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6922\n",
      "Epoch: 150, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6922\n",
      "Epoch: 160, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6922\n",
      "Epoch: 170, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6922\n",
      "Epoch: 180, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6921\n",
      "Epoch: 190, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6921\n",
      "Epoch: 200, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6921\n",
      "Epoch: 210, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6920\n",
      "Epoch: 220, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6920\n",
      "Epoch: 230, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6920\n",
      "Epoch: 240, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6920\n",
      "Epoch: 250, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6919\n",
      "Epoch: 260, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 270, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6919\n",
      "Epoch: 280, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6919\n",
      "Epoch: 290, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6918\n",
      "Epoch: 300, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6918\n",
      "Epoch: 310, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6918\n",
      "Epoch: 320, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6918\n",
      "Epoch: 330, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6918\n",
      "Epoch: 340, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6918\n",
      "Epoch: 350, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6918\n",
      "Epoch: 360, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6918\n",
      "Epoch: 370, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6917\n",
      "Epoch: 380, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6895, Test Loss: 0.6917\n",
      "Epoch: 390, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6916\n",
      "Epoch: 400, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6916\n",
      "Epoch: 410, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6916\n",
      "Epoch: 420, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6903, Test Loss: 0.6916\n",
      "Epoch: 430, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6916\n",
      "Epoch: 440, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6916\n",
      "Epoch: 450, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6915\n",
      "Epoch: 460, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6915\n",
      "Epoch: 470, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6915\n",
      "Epoch: 480, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6915\n",
      "Epoch: 490, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6914\n",
      "Epoch: 500, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6914\n",
      "Epoch: 510, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6914\n",
      "Epoch: 520, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6913\n",
      "Epoch: 530, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6913\n",
      "Epoch: 540, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6913\n",
      "Epoch: 550, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6913\n",
      "Epoch: 560, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6913\n",
      "Epoch: 570, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6912\n",
      "Epoch: 580, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6912\n",
      "Epoch: 590, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6912\n",
      "Epoch: 600, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6912\n",
      "Epoch: 610, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6912\n",
      "Epoch: 620, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6912\n",
      "Epoch: 630, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6912\n",
      "Epoch: 640, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6911\n",
      "Epoch: 650, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6911\n",
      "Epoch: 660, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6911\n",
      "Epoch: 670, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6911\n",
      "Epoch: 680, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6910\n",
      "Epoch: 690, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6910\n",
      "Epoch: 700, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6910\n",
      "Epoch: 710, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6909\n",
      "Epoch: 720, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6909\n",
      "Epoch: 730, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6909\n",
      "Epoch: 740, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6886, Test Loss: 0.6909\n",
      "Epoch: 750, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6883, Test Loss: 0.6908\n",
      "Epoch: 760, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6883, Test Loss: 0.6908\n",
      "Epoch: 770, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6891, Test Loss: 0.6908\n",
      "Epoch: 780, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6885, Test Loss: 0.6908\n",
      "Epoch: 790, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6883, Test Loss: 0.6908\n",
      "Epoch: 800, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6882, Test Loss: 0.6907\n",
      "Epoch: 810, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 820, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6887, Test Loss: 0.6907\n",
      "Epoch: 830, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6895, Test Loss: 0.6907\n",
      "Epoch: 840, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6884, Test Loss: 0.6907\n",
      "Epoch: 850, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6877, Test Loss: 0.6907\n",
      "Epoch: 860, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6887, Test Loss: 0.6906\n",
      "Epoch: 870, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6885, Test Loss: 0.6906\n",
      "Epoch: 880, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6880, Test Loss: 0.6905\n",
      "Epoch: 890, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6886, Test Loss: 0.6905\n",
      "Epoch: 900, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6905\n",
      "Epoch: 910, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6882, Test Loss: 0.6905\n",
      "Epoch: 920, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6886, Test Loss: 0.6904\n",
      "Epoch: 930, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6905\n",
      "Epoch: 940, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6904\n",
      "Epoch: 950, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6881, Test Loss: 0.6904\n",
      "Epoch: 960, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6877, Test Loss: 0.6904\n",
      "Epoch: 970, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6878, Test Loss: 0.6904\n",
      "Epoch: 980, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6880, Test Loss: 0.6903\n",
      "Epoch: 990, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6903\n",
      "Epoch: 1000, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6903\n",
      "Epoch: 1010, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6902\n",
      "Epoch: 1020, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6880, Test Loss: 0.6902\n",
      "Epoch: 1030, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6877, Test Loss: 0.6902\n",
      "Epoch: 1040, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6880, Test Loss: 0.6901\n",
      "Epoch: 1050, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6883, Test Loss: 0.6901\n",
      "Epoch: 1060, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6901\n",
      "Epoch: 1070, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6901\n",
      "Epoch: 1080, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6874, Test Loss: 0.6900\n",
      "Epoch: 1090, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6876, Test Loss: 0.6900\n",
      "Epoch: 1100, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6870, Test Loss: 0.6900\n",
      "Epoch: 1110, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6900\n",
      "Epoch: 1120, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6876, Test Loss: 0.6899\n",
      "Epoch: 1130, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6899\n",
      "Epoch: 1140, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6898\n",
      "Epoch: 1150, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6864, Test Loss: 0.6898\n",
      "Epoch: 1160, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6898\n",
      "Epoch: 1170, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6897\n",
      "Epoch: 1180, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6897\n",
      "Epoch: 1190, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6897\n",
      "Epoch: 1200, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6896\n",
      "Epoch: 1210, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6896\n",
      "Epoch: 1220, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6866, Test Loss: 0.6895\n",
      "Epoch: 1230, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6864, Test Loss: 0.6895\n",
      "Epoch: 1240, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6867, Test Loss: 0.6895\n",
      "Epoch: 1250, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6895\n",
      "Epoch: 1260, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6894\n",
      "Epoch: 1270, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6870, Test Loss: 0.6894\n",
      "Epoch: 1280, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6894\n",
      "Epoch: 1290, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6893\n",
      "Epoch: 1300, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6865, Test Loss: 0.6893\n",
      "Epoch: 1310, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6868, Test Loss: 0.6893\n",
      "Epoch: 1320, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6868, Test Loss: 0.6893\n",
      "Epoch: 1330, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6892\n",
      "Epoch: 1340, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6864, Test Loss: 0.6891\n",
      "Epoch: 1350, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6863, Test Loss: 0.6891\n",
      "Epoch: 1360, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6857, Test Loss: 0.6890\n",
      "Epoch: 1370, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6861, Test Loss: 0.6890\n",
      "Epoch: 1380, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6857, Test Loss: 0.6890\n",
      "Epoch: 1390, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6889\n",
      "Epoch: 1400, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6861, Test Loss: 0.6889\n",
      "Epoch: 1410, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6858, Test Loss: 0.6889\n",
      "Epoch: 1420, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6863, Test Loss: 0.6889\n",
      "Epoch: 1430, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6888\n",
      "Epoch: 1440, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6863, Test Loss: 0.6888\n",
      "Epoch: 1450, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6863, Test Loss: 0.6887\n",
      "Epoch: 1460, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6855, Test Loss: 0.6886\n",
      "Epoch: 1470, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6860, Test Loss: 0.6886\n",
      "Epoch: 1480, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6857, Test Loss: 0.6885\n",
      "Epoch: 1490, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6885\n",
      "Epoch: 1500, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 1510, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6855, Test Loss: 0.6884\n",
      "Epoch: 1520, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6858, Test Loss: 0.6884\n",
      "Epoch: 1530, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6883\n",
      "Epoch: 1540, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6853, Test Loss: 0.6882\n",
      "Epoch: 1550, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6858, Test Loss: 0.6882\n",
      "Epoch: 1560, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6859, Test Loss: 0.6882\n",
      "Epoch: 1570, Train Acc: 0.5603, Test Acc: 0.5250, Train Loss: 0.6853, Test Loss: 0.6881\n",
      "Epoch: 1580, Train Acc: 0.5603, Test Acc: 0.5250, Train Loss: 0.6851, Test Loss: 0.6880\n",
      "Epoch: 1590, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6855, Test Loss: 0.6880\n",
      "Epoch: 1600, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6880\n",
      "Epoch: 1610, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6845, Test Loss: 0.6879\n",
      "Epoch: 1620, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6846, Test Loss: 0.6878\n",
      "Epoch: 1630, Train Acc: 0.5603, Test Acc: 0.5250, Train Loss: 0.6850, Test Loss: 0.6878\n",
      "Epoch: 1640, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6851, Test Loss: 0.6877\n",
      "Epoch: 1650, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6840, Test Loss: 0.6876\n",
      "Epoch: 1660, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6851, Test Loss: 0.6876\n",
      "Epoch: 1670, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6840, Test Loss: 0.6875\n",
      "Epoch: 1680, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6849, Test Loss: 0.6875\n",
      "Epoch: 1690, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6846, Test Loss: 0.6874\n",
      "Epoch: 1700, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6847, Test Loss: 0.6874\n",
      "Epoch: 1710, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6841, Test Loss: 0.6873\n",
      "Epoch: 1720, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6841, Test Loss: 0.6872\n",
      "Epoch: 1730, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6841, Test Loss: 0.6872\n",
      "Epoch: 1740, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6839, Test Loss: 0.6871\n",
      "Epoch: 1750, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6842, Test Loss: 0.6870\n",
      "Epoch: 1760, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6837, Test Loss: 0.6870\n",
      "Epoch: 1770, Train Acc: 0.5603, Test Acc: 0.5200, Train Loss: 0.6835, Test Loss: 0.6869\n",
      "Epoch: 1780, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6834, Test Loss: 0.6868\n",
      "Epoch: 1790, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6836, Test Loss: 0.6867\n",
      "Epoch: 1800, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6836, Test Loss: 0.6866\n",
      "Epoch: 1810, Train Acc: 0.5754, Test Acc: 0.5300, Train Loss: 0.6837, Test Loss: 0.6866\n",
      "Epoch: 1820, Train Acc: 0.5690, Test Acc: 0.5300, Train Loss: 0.6831, Test Loss: 0.6865\n",
      "Epoch: 1830, Train Acc: 0.5668, Test Acc: 0.5200, Train Loss: 0.6827, Test Loss: 0.6865\n",
      "Epoch: 1840, Train Acc: 0.5776, Test Acc: 0.5300, Train Loss: 0.6828, Test Loss: 0.6864\n",
      "Epoch: 1850, Train Acc: 0.5776, Test Acc: 0.5300, Train Loss: 0.6830, Test Loss: 0.6863\n",
      "Epoch: 1860, Train Acc: 0.5754, Test Acc: 0.5300, Train Loss: 0.6832, Test Loss: 0.6862\n",
      "Epoch: 1870, Train Acc: 0.5819, Test Acc: 0.5300, Train Loss: 0.6827, Test Loss: 0.6861\n",
      "Epoch: 1880, Train Acc: 0.5841, Test Acc: 0.5400, Train Loss: 0.6829, Test Loss: 0.6860\n",
      "Epoch: 1890, Train Acc: 0.5862, Test Acc: 0.5400, Train Loss: 0.6831, Test Loss: 0.6860\n",
      "Epoch: 1900, Train Acc: 0.5819, Test Acc: 0.5300, Train Loss: 0.6831, Test Loss: 0.6859\n",
      "Epoch: 1910, Train Acc: 0.5841, Test Acc: 0.5300, Train Loss: 0.6824, Test Loss: 0.6858\n",
      "Epoch: 1920, Train Acc: 0.5841, Test Acc: 0.5400, Train Loss: 0.6827, Test Loss: 0.6857\n",
      "Epoch: 1930, Train Acc: 0.5884, Test Acc: 0.5400, Train Loss: 0.6818, Test Loss: 0.6856\n",
      "Epoch: 1940, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6823, Test Loss: 0.6856\n",
      "Epoch: 1950, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6820, Test Loss: 0.6855\n",
      "Epoch: 1960, Train Acc: 0.5862, Test Acc: 0.5350, Train Loss: 0.6817, Test Loss: 0.6854\n",
      "Epoch: 1970, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6828, Test Loss: 0.6854\n",
      "Epoch: 1980, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6827, Test Loss: 0.6853\n",
      "Epoch: 1990, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6806, Test Loss: 0.6852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▁▂▂▄▄▂▄▄▄▄▂▄▅▅██▂</td></tr><tr><td>Test F1</td><td>▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▅▅▅▅▅▄▄▄▁▂▂▅▅▄▅▅▅▅▄▅▆▆██▂</td></tr><tr><td>Test Loss</td><td>█▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>████████▆▆▆▆▆▆▆▆▆▆▆▆▃▃▃▁▁▁▃▃▃▃▃▃▃▃▃▃▃▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▄▅▅▅▅▄▅▅▅██▅</td></tr><tr><td>Train Accuracy</td><td>▂▁▁▁▁▁▁▁▂▁▁▂▂▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▇▇███</td></tr><tr><td>Train F1</td><td>▂▂▂▁▁▂▁▁▂▁▁▁▁▂▂▃▂▄▄▄▃▄▄▄▂▂▃▂▅▄▄▄▄▄▅▇▆███</td></tr><tr><td>Train Loss</td><td>█▇▇▇▇▆▇▆▆▆▆▆▆▆▆▆▅▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>█▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▅▅▅▁▂▂▂▅▃▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▅▆▇▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.54</td></tr><tr><td>Test F1</td><td>0.68493</td></tr><tr><td>Test Loss</td><td>0.68509</td></tr><tr><td>Test Sensitivity</td><td>0.97087</td></tr><tr><td>Test Specificity</td><td>0.08247</td></tr><tr><td>Train Accuracy</td><td>0.59052</td></tr><tr><td>Train F1</td><td>0.71386</td></tr><tr><td>Train Loss</td><td>0.68155</td></tr><tr><td>Train Sensitivity</td><td>0.96341</td></tr><tr><td>Train Specificity</td><td>0.16972</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-17</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/jc8ccsr5' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/jc8ccsr5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_173415-jc8ccsr5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qhj5i644 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.7691275688631368e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0002041043936864023\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_174233-qhj5i644</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/qhj5i644' target=\"_blank\">revived-sweep-18</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qhj5i644' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qhj5i644</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6932\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6921\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6920\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6914\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6914\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6884, Test Loss: 0.6908\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6883, Test Loss: 0.6906\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6904\n",
      "Epoch: 100, Train Acc: 0.5582, Test Acc: 0.5100, Train Loss: 0.6875, Test Loss: 0.6898\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6899\n",
      "Epoch: 120, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6874, Test Loss: 0.6895\n",
      "Epoch: 130, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6864, Test Loss: 0.6891\n",
      "Epoch: 140, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6856, Test Loss: 0.6887\n",
      "Epoch: 150, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6851, Test Loss: 0.6885\n",
      "Epoch: 160, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6841, Test Loss: 0.6878\n",
      "Epoch: 170, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6835, Test Loss: 0.6877\n",
      "Epoch: 180, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6832, Test Loss: 0.6869\n",
      "Epoch: 190, Train Acc: 0.5496, Test Acc: 0.5100, Train Loss: 0.6830, Test Loss: 0.6864\n",
      "Epoch: 200, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6825, Test Loss: 0.6859\n",
      "Epoch: 210, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6813, Test Loss: 0.6854\n",
      "Epoch: 220, Train Acc: 0.5841, Test Acc: 0.5300, Train Loss: 0.6799, Test Loss: 0.6840\n",
      "Epoch: 230, Train Acc: 0.5539, Test Acc: 0.5100, Train Loss: 0.6798, Test Loss: 0.6838\n",
      "Epoch: 240, Train Acc: 0.5948, Test Acc: 0.5350, Train Loss: 0.6781, Test Loss: 0.6823\n",
      "Epoch: 250, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6760, Test Loss: 0.6815\n",
      "Epoch: 260, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6747, Test Loss: 0.6805\n",
      "Epoch: 270, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6741, Test Loss: 0.6789\n",
      "Epoch: 280, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6717, Test Loss: 0.6776\n",
      "Epoch: 290, Train Acc: 0.6164, Test Acc: 0.5600, Train Loss: 0.6693, Test Loss: 0.6759\n",
      "Epoch: 300, Train Acc: 0.6401, Test Acc: 0.5700, Train Loss: 0.6676, Test Loss: 0.6739\n",
      "Epoch: 310, Train Acc: 0.6401, Test Acc: 0.5600, Train Loss: 0.6652, Test Loss: 0.6722\n",
      "Epoch: 320, Train Acc: 0.6681, Test Acc: 0.6000, Train Loss: 0.6622, Test Loss: 0.6699\n",
      "Epoch: 330, Train Acc: 0.6810, Test Acc: 0.6200, Train Loss: 0.6592, Test Loss: 0.6676\n",
      "Epoch: 340, Train Acc: 0.6918, Test Acc: 0.6350, Train Loss: 0.6563, Test Loss: 0.6651\n",
      "Epoch: 350, Train Acc: 0.6875, Test Acc: 0.6000, Train Loss: 0.6520, Test Loss: 0.6631\n",
      "Epoch: 360, Train Acc: 0.7155, Test Acc: 0.6700, Train Loss: 0.6498, Test Loss: 0.6596\n",
      "Epoch: 370, Train Acc: 0.7263, Test Acc: 0.6700, Train Loss: 0.6456, Test Loss: 0.6567\n",
      "Epoch: 380, Train Acc: 0.7284, Test Acc: 0.6700, Train Loss: 0.6407, Test Loss: 0.6535\n",
      "Epoch: 390, Train Acc: 0.7371, Test Acc: 0.6700, Train Loss: 0.6366, Test Loss: 0.6502\n",
      "Epoch: 400, Train Acc: 0.7435, Test Acc: 0.6750, Train Loss: 0.6329, Test Loss: 0.6469\n",
      "Epoch: 410, Train Acc: 0.7457, Test Acc: 0.6800, Train Loss: 0.6289, Test Loss: 0.6434\n",
      "Epoch: 420, Train Acc: 0.7457, Test Acc: 0.6950, Train Loss: 0.6241, Test Loss: 0.6398\n",
      "Epoch: 430, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.6184, Test Loss: 0.6363\n",
      "Epoch: 440, Train Acc: 0.7478, Test Acc: 0.6850, Train Loss: 0.6126, Test Loss: 0.6324\n",
      "Epoch: 450, Train Acc: 0.7478, Test Acc: 0.7050, Train Loss: 0.6098, Test Loss: 0.6287\n",
      "Epoch: 460, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.6032, Test Loss: 0.6251\n",
      "Epoch: 470, Train Acc: 0.7565, Test Acc: 0.6850, Train Loss: 0.5992, Test Loss: 0.6215\n",
      "Epoch: 480, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5937, Test Loss: 0.6179\n",
      "Epoch: 490, Train Acc: 0.7629, Test Acc: 0.6850, Train Loss: 0.5878, Test Loss: 0.6146\n",
      "Epoch: 500, Train Acc: 0.7672, Test Acc: 0.6850, Train Loss: 0.5849, Test Loss: 0.6113\n",
      "Epoch: 510, Train Acc: 0.7672, Test Acc: 0.6850, Train Loss: 0.5778, Test Loss: 0.6081\n",
      "Epoch: 520, Train Acc: 0.7737, Test Acc: 0.6750, Train Loss: 0.5714, Test Loss: 0.6049\n",
      "Epoch: 530, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5668, Test Loss: 0.6019\n",
      "Epoch: 540, Train Acc: 0.7716, Test Acc: 0.6750, Train Loss: 0.5642, Test Loss: 0.5988\n",
      "Epoch: 550, Train Acc: 0.7780, Test Acc: 0.6900, Train Loss: 0.5609, Test Loss: 0.5964\n",
      "Epoch: 560, Train Acc: 0.7802, Test Acc: 0.6900, Train Loss: 0.5570, Test Loss: 0.5939\n",
      "Epoch: 570, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5519, Test Loss: 0.5911\n",
      "Epoch: 580, Train Acc: 0.7759, Test Acc: 0.6900, Train Loss: 0.5493, Test Loss: 0.5886\n",
      "Epoch: 590, Train Acc: 0.7780, Test Acc: 0.6650, Train Loss: 0.5449, Test Loss: 0.5864\n",
      "Epoch: 600, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5386, Test Loss: 0.5843\n",
      "Epoch: 610, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5344, Test Loss: 0.5828\n",
      "Epoch: 620, Train Acc: 0.7845, Test Acc: 0.6950, Train Loss: 0.5322, Test Loss: 0.5810\n",
      "Epoch: 630, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.5286, Test Loss: 0.5796\n",
      "Epoch: 640, Train Acc: 0.7909, Test Acc: 0.7000, Train Loss: 0.5249, Test Loss: 0.5772\n",
      "Epoch: 650, Train Acc: 0.7866, Test Acc: 0.6850, Train Loss: 0.5211, Test Loss: 0.5753\n",
      "Epoch: 660, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5174, Test Loss: 0.5740\n",
      "Epoch: 670, Train Acc: 0.7953, Test Acc: 0.7050, Train Loss: 0.5155, Test Loss: 0.5727\n",
      "Epoch: 680, Train Acc: 0.7931, Test Acc: 0.6950, Train Loss: 0.5117, Test Loss: 0.5711\n",
      "Epoch: 690, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5125, Test Loss: 0.5696\n",
      "Epoch: 700, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.5069, Test Loss: 0.5690\n",
      "Epoch: 710, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.5035, Test Loss: 0.5679\n",
      "Epoch: 720, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.5041, Test Loss: 0.5666\n",
      "Epoch: 730, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.4984, Test Loss: 0.5658\n",
      "Epoch: 740, Train Acc: 0.8017, Test Acc: 0.6950, Train Loss: 0.4971, Test Loss: 0.5650\n",
      "Epoch: 750, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4926, Test Loss: 0.5640\n",
      "Epoch: 760, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4969, Test Loss: 0.5636\n",
      "Epoch: 770, Train Acc: 0.7974, Test Acc: 0.6950, Train Loss: 0.4927, Test Loss: 0.5608\n",
      "Epoch: 780, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4880, Test Loss: 0.5612\n",
      "Epoch: 790, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4859, Test Loss: 0.5614\n",
      "Epoch: 800, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4863, Test Loss: 0.5607\n",
      "Epoch: 810, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4835, Test Loss: 0.5583\n",
      "Epoch: 820, Train Acc: 0.8039, Test Acc: 0.7000, Train Loss: 0.4828, Test Loss: 0.5567\n",
      "Epoch: 830, Train Acc: 0.7931, Test Acc: 0.7150, Train Loss: 0.4797, Test Loss: 0.5589\n",
      "Epoch: 840, Train Acc: 0.8060, Test Acc: 0.7050, Train Loss: 0.4781, Test Loss: 0.5558\n",
      "Epoch: 850, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4776, Test Loss: 0.5561\n",
      "Epoch: 860, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4753, Test Loss: 0.5534\n",
      "Epoch: 870, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4725, Test Loss: 0.5546\n",
      "Epoch: 880, Train Acc: 0.8082, Test Acc: 0.7250, Train Loss: 0.4716, Test Loss: 0.5523\n",
      "Epoch: 890, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4715, Test Loss: 0.5516\n",
      "Epoch: 900, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4685, Test Loss: 0.5520\n",
      "Epoch: 910, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4669, Test Loss: 0.5519\n",
      "Epoch: 920, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4640, Test Loss: 0.5509\n",
      "Epoch: 930, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4616, Test Loss: 0.5509\n",
      "Epoch: 940, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4641, Test Loss: 0.5510\n",
      "Epoch: 950, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4627, Test Loss: 0.5495\n",
      "Epoch: 960, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4600, Test Loss: 0.5468\n",
      "Epoch: 970, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4605, Test Loss: 0.5472\n",
      "Epoch: 980, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4577, Test Loss: 0.5454\n",
      "Epoch: 990, Train Acc: 0.7974, Test Acc: 0.7400, Train Loss: 0.4547, Test Loss: 0.5446\n",
      "Epoch: 1000, Train Acc: 0.7996, Test Acc: 0.7400, Train Loss: 0.4548, Test Loss: 0.5439\n",
      "Epoch: 1010, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4593, Test Loss: 0.5439\n",
      "Epoch: 1020, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4529, Test Loss: 0.5442\n",
      "Epoch: 1030, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4506, Test Loss: 0.5436\n",
      "Epoch: 1040, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4499, Test Loss: 0.5429\n",
      "Epoch: 1050, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4471, Test Loss: 0.5423\n",
      "Epoch: 1060, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4495, Test Loss: 0.5430\n",
      "Epoch: 1070, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4507, Test Loss: 0.5403\n",
      "Epoch: 1080, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4485, Test Loss: 0.5399\n",
      "Epoch: 1090, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4446, Test Loss: 0.5401\n",
      "Epoch: 1100, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4453, Test Loss: 0.5414\n",
      "Epoch: 1110, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4496, Test Loss: 0.5500\n",
      "Epoch: 1120, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4443, Test Loss: 0.5386\n",
      "Epoch: 1130, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4411, Test Loss: 0.5374\n",
      "Epoch: 1140, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4417, Test Loss: 0.5372\n",
      "Epoch: 1150, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4406, Test Loss: 0.5362\n",
      "Epoch: 1160, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4411, Test Loss: 0.5367\n",
      "Epoch: 1170, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4399, Test Loss: 0.5372\n",
      "Epoch: 1180, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4356, Test Loss: 0.5386\n",
      "Epoch: 1190, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4340, Test Loss: 0.5363\n",
      "Epoch: 1200, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4376, Test Loss: 0.5357\n",
      "Epoch: 1210, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4381, Test Loss: 0.5342\n",
      "Epoch: 1220, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4287, Test Loss: 0.5343\n",
      "Epoch: 1230, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4343, Test Loss: 0.5353\n",
      "Epoch: 1240, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4306, Test Loss: 0.5392\n",
      "Epoch: 1250, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4372, Test Loss: 0.5339\n",
      "Epoch: 1260, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4292, Test Loss: 0.5332\n",
      "Epoch: 1270, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4285, Test Loss: 0.5324\n",
      "Epoch: 1280, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4300, Test Loss: 0.5311\n",
      "Epoch: 1290, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4256, Test Loss: 0.5330\n",
      "Epoch: 1300, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4294, Test Loss: 0.5306\n",
      "Epoch: 1310, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4252, Test Loss: 0.5327\n",
      "Epoch: 1320, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4214, Test Loss: 0.5323\n",
      "Epoch: 1330, Train Acc: 0.8254, Test Acc: 0.7550, Train Loss: 0.4221, Test Loss: 0.5309\n",
      "Epoch: 1340, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4233, Test Loss: 0.5329\n",
      "Epoch: 1350, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4255, Test Loss: 0.5294\n",
      "Epoch: 1360, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4235, Test Loss: 0.5304\n",
      "Epoch: 1370, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4220, Test Loss: 0.5319\n",
      "Epoch: 1380, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4213, Test Loss: 0.5302\n",
      "Epoch: 1390, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.4213, Test Loss: 0.5293\n",
      "Epoch: 1400, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4165, Test Loss: 0.5287\n",
      "Epoch: 1410, Train Acc: 0.8233, Test Acc: 0.7450, Train Loss: 0.4183, Test Loss: 0.5294\n",
      "Epoch: 1420, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4158, Test Loss: 0.5288\n",
      "Epoch: 1430, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4164, Test Loss: 0.5277\n",
      "Epoch: 1440, Train Acc: 0.8254, Test Acc: 0.7550, Train Loss: 0.4180, Test Loss: 0.5288\n",
      "Epoch: 1450, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4131, Test Loss: 0.5274\n",
      "Epoch: 1460, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4142, Test Loss: 0.5286\n",
      "Epoch: 1470, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4118, Test Loss: 0.5276\n",
      "Epoch: 1480, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4133, Test Loss: 0.5310\n",
      "Epoch: 1490, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4108, Test Loss: 0.5292\n",
      "Epoch: 1500, Train Acc: 0.8297, Test Acc: 0.7700, Train Loss: 0.4099, Test Loss: 0.5253\n",
      "Epoch: 1510, Train Acc: 0.8297, Test Acc: 0.7700, Train Loss: 0.4088, Test Loss: 0.5254\n",
      "Epoch: 1520, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4131, Test Loss: 0.5261\n",
      "Epoch: 1530, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4087, Test Loss: 0.5277\n",
      "Epoch: 1540, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4066, Test Loss: 0.5310\n",
      "Epoch: 1550, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4092, Test Loss: 0.5290\n",
      "Epoch: 1560, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4069, Test Loss: 0.5269\n",
      "Epoch: 1570, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4051, Test Loss: 0.5289\n",
      "Epoch: 1580, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4061, Test Loss: 0.5270\n",
      "Epoch: 1590, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4050, Test Loss: 0.5250\n",
      "Epoch: 1600, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4057, Test Loss: 0.5252\n",
      "Epoch: 1610, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.4040, Test Loss: 0.5251\n",
      "Epoch: 1620, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4054, Test Loss: 0.5281\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▂▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇█▇█▇████████████</td></tr><tr><td>Test F1</td><td>▁▁▁▂▁▁▁▂▂▃▂▃▂▂▂▂▃▂▄▂▄▅▅▅▆▆▆▆▆▇▇▇▇▇█▇█▇▇█</td></tr><tr><td>Test Loss</td><td>███████▇▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▇▇▄▃▂▂▂▁▁▁▂▁▂▁▂▃▃▃▂▃▂▃▂▃▃▃▃▃▄▃▄▃▃▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▂▅▆▆▇▇▇▇▇▇▇▇█▇▇▇▇███▇█████▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▃▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇█▇███████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▂▂▂▃▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▆▇▇▇████████</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██▇█▇█▇▆▄▂▃▁▁▁▁▂▂▂▂▁▂▂▃▂▂▃▂▃▂▃▃▂▃▃▃▃▃▃▃▃</td></tr><tr><td>Train Specificity</td><td>▁▁▂▁▂▂▂▃▅▆▇▇▇███████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.75</td></tr><tr><td>Test F1</td><td>0.7619</td></tr><tr><td>Test Loss</td><td>0.52654</td></tr><tr><td>Test Sensitivity</td><td>0.7767</td></tr><tr><td>Test Specificity</td><td>0.72165</td></tr><tr><td>Train Accuracy</td><td>0.83621</td></tr><tr><td>Train F1</td><td>0.84232</td></tr><tr><td>Train Loss</td><td>0.40132</td></tr><tr><td>Train Sensitivity</td><td>0.8252</td></tr><tr><td>Train Specificity</td><td>0.84862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-sweep-18</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qhj5i644' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qhj5i644</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_174233-qhj5i644/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cgfmm7c9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.5835598145792824e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.23509493627766e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_174959-cgfmm7c9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/cgfmm7c9' target=\"_blank\">vocal-sweep-19</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/cgfmm7c9' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/cgfmm7c9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6963, Test Loss: 0.6952\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6974, Test Loss: 0.6956\n",
      "Epoch: 020, Train Acc: 0.4720, Test Acc: 0.4850, Train Loss: 0.6943, Test Loss: 0.6939\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6922, Test Loss: 0.6931\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6930\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6931\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6931\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6930\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6929\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6927\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6926\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6925\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6924\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6924\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6923\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6922\n",
      "Epoch: 160, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6920\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6920\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6919\n",
      "Epoch: 190, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6919\n",
      "Epoch: 200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6918\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6918\n",
      "Epoch: 220, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6916\n",
      "Epoch: 230, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6915\n",
      "Epoch: 240, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6915\n",
      "Epoch: 250, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6914\n",
      "Epoch: 260, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6914\n",
      "Epoch: 270, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6913\n",
      "Epoch: 280, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6912\n",
      "Epoch: 290, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6911\n",
      "Epoch: 300, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6911\n",
      "Epoch: 310, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6910\n",
      "Epoch: 320, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6909\n",
      "Epoch: 330, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6909\n",
      "Epoch: 340, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6908\n",
      "Epoch: 350, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6908\n",
      "Epoch: 360, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6907\n",
      "Epoch: 370, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6907\n",
      "Epoch: 380, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6906\n",
      "Epoch: 390, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6906\n",
      "Epoch: 400, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6905\n",
      "Epoch: 410, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6904\n",
      "Epoch: 420, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6904\n",
      "Epoch: 430, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6903\n",
      "Epoch: 440, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6902\n",
      "Epoch: 450, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6902\n",
      "Epoch: 460, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6901\n",
      "Epoch: 470, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6900\n",
      "Epoch: 480, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6900\n",
      "Epoch: 490, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6899\n",
      "Epoch: 500, Train Acc: 0.5323, Test Acc: 0.5250, Train Loss: 0.6878, Test Loss: 0.6898\n",
      "Epoch: 510, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6898\n",
      "Epoch: 520, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6897\n",
      "Epoch: 530, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6897\n",
      "Epoch: 540, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6897\n",
      "Epoch: 550, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6896\n",
      "Epoch: 560, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6864, Test Loss: 0.6896\n",
      "Epoch: 570, Train Acc: 0.5302, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6894\n",
      "Epoch: 580, Train Acc: 0.5345, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6893\n",
      "Epoch: 590, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6859, Test Loss: 0.6893\n",
      "Epoch: 600, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6891\n",
      "Epoch: 610, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6891\n",
      "Epoch: 620, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6891\n",
      "Epoch: 630, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6862, Test Loss: 0.6890\n",
      "Epoch: 640, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6889\n",
      "Epoch: 650, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6889\n",
      "Epoch: 660, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6861, Test Loss: 0.6887\n",
      "Epoch: 670, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6857, Test Loss: 0.6887\n",
      "Epoch: 680, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6859, Test Loss: 0.6885\n",
      "Epoch: 690, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6862, Test Loss: 0.6886\n",
      "Epoch: 700, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 710, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6884\n",
      "Epoch: 720, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6884\n",
      "Epoch: 730, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6851, Test Loss: 0.6883\n",
      "Epoch: 740, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6854, Test Loss: 0.6882\n",
      "Epoch: 750, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6881\n",
      "Epoch: 760, Train Acc: 0.5560, Test Acc: 0.5200, Train Loss: 0.6849, Test Loss: 0.6879\n",
      "Epoch: 770, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6879\n",
      "Epoch: 780, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6847, Test Loss: 0.6878\n",
      "Epoch: 790, Train Acc: 0.5560, Test Acc: 0.5100, Train Loss: 0.6842, Test Loss: 0.6877\n",
      "Epoch: 800, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6845, Test Loss: 0.6876\n",
      "Epoch: 810, Train Acc: 0.5690, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6874\n",
      "Epoch: 820, Train Acc: 0.5690, Test Acc: 0.5250, Train Loss: 0.6834, Test Loss: 0.6874\n",
      "Epoch: 830, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6842, Test Loss: 0.6873\n",
      "Epoch: 840, Train Acc: 0.5647, Test Acc: 0.5250, Train Loss: 0.6835, Test Loss: 0.6872\n",
      "Epoch: 850, Train Acc: 0.5539, Test Acc: 0.5100, Train Loss: 0.6834, Test Loss: 0.6872\n",
      "Epoch: 860, Train Acc: 0.5647, Test Acc: 0.5100, Train Loss: 0.6839, Test Loss: 0.6870\n",
      "Epoch: 870, Train Acc: 0.5603, Test Acc: 0.5100, Train Loss: 0.6836, Test Loss: 0.6870\n",
      "Epoch: 880, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6834, Test Loss: 0.6869\n",
      "Epoch: 890, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6842, Test Loss: 0.6868\n",
      "Epoch: 900, Train Acc: 0.5668, Test Acc: 0.5200, Train Loss: 0.6837, Test Loss: 0.6866\n",
      "Epoch: 910, Train Acc: 0.5711, Test Acc: 0.5200, Train Loss: 0.6834, Test Loss: 0.6865\n",
      "Epoch: 920, Train Acc: 0.5754, Test Acc: 0.5300, Train Loss: 0.6828, Test Loss: 0.6863\n",
      "Epoch: 930, Train Acc: 0.5797, Test Acc: 0.5250, Train Loss: 0.6827, Test Loss: 0.6862\n",
      "Epoch: 940, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6830, Test Loss: 0.6861\n",
      "Epoch: 950, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6825, Test Loss: 0.6860\n",
      "Epoch: 960, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6824, Test Loss: 0.6859\n",
      "Epoch: 970, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6825, Test Loss: 0.6858\n",
      "Epoch: 980, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6818, Test Loss: 0.6857\n",
      "Epoch: 990, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6821, Test Loss: 0.6855\n",
      "Epoch: 1000, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6821, Test Loss: 0.6854\n",
      "Epoch: 1010, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6818, Test Loss: 0.6852\n",
      "Epoch: 1020, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6820, Test Loss: 0.6851\n",
      "Epoch: 1030, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6814, Test Loss: 0.6849\n",
      "Epoch: 1040, Train Acc: 0.5819, Test Acc: 0.5350, Train Loss: 0.6809, Test Loss: 0.6848\n",
      "Epoch: 1050, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6811, Test Loss: 0.6848\n",
      "Epoch: 1060, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6810, Test Loss: 0.6846\n",
      "Epoch: 1070, Train Acc: 0.5884, Test Acc: 0.5300, Train Loss: 0.6807, Test Loss: 0.6844\n",
      "Epoch: 1080, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6806, Test Loss: 0.6842\n",
      "Epoch: 1090, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6802, Test Loss: 0.6841\n",
      "Epoch: 1100, Train Acc: 0.5862, Test Acc: 0.5250, Train Loss: 0.6805, Test Loss: 0.6839\n",
      "Epoch: 1110, Train Acc: 0.5884, Test Acc: 0.5300, Train Loss: 0.6794, Test Loss: 0.6838\n",
      "Epoch: 1120, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6789, Test Loss: 0.6836\n",
      "Epoch: 1130, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6793, Test Loss: 0.6835\n",
      "Epoch: 1140, Train Acc: 0.5905, Test Acc: 0.5350, Train Loss: 0.6794, Test Loss: 0.6833\n",
      "Epoch: 1150, Train Acc: 0.5927, Test Acc: 0.5200, Train Loss: 0.6790, Test Loss: 0.6831\n",
      "Epoch: 1160, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6788, Test Loss: 0.6830\n",
      "Epoch: 1170, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6784, Test Loss: 0.6828\n",
      "Epoch: 1180, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6779, Test Loss: 0.6826\n",
      "Epoch: 1190, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6775, Test Loss: 0.6825\n",
      "Epoch: 1200, Train Acc: 0.5948, Test Acc: 0.5250, Train Loss: 0.6784, Test Loss: 0.6823\n",
      "Epoch: 1210, Train Acc: 0.5927, Test Acc: 0.5350, Train Loss: 0.6777, Test Loss: 0.6820\n",
      "Epoch: 1220, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6773, Test Loss: 0.6819\n",
      "Epoch: 1230, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6767, Test Loss: 0.6818\n",
      "Epoch: 1240, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6775, Test Loss: 0.6816\n",
      "Epoch: 1250, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6772, Test Loss: 0.6813\n",
      "Epoch: 1260, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6765, Test Loss: 0.6811\n",
      "Epoch: 1270, Train Acc: 0.6013, Test Acc: 0.5300, Train Loss: 0.6762, Test Loss: 0.6810\n",
      "Epoch: 1280, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6760, Test Loss: 0.6808\n",
      "Epoch: 1290, Train Acc: 0.5905, Test Acc: 0.5300, Train Loss: 0.6760, Test Loss: 0.6806\n",
      "Epoch: 1300, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6758, Test Loss: 0.6804\n",
      "Epoch: 1310, Train Acc: 0.6013, Test Acc: 0.5350, Train Loss: 0.6751, Test Loss: 0.6801\n",
      "Epoch: 1320, Train Acc: 0.6013, Test Acc: 0.5300, Train Loss: 0.6753, Test Loss: 0.6800\n",
      "Epoch: 1330, Train Acc: 0.6013, Test Acc: 0.5350, Train Loss: 0.6745, Test Loss: 0.6797\n",
      "Epoch: 1340, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6742, Test Loss: 0.6794\n",
      "Epoch: 1350, Train Acc: 0.6078, Test Acc: 0.5300, Train Loss: 0.6740, Test Loss: 0.6792\n",
      "Epoch: 1360, Train Acc: 0.6078, Test Acc: 0.5350, Train Loss: 0.6737, Test Loss: 0.6789\n",
      "Epoch: 1370, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6736, Test Loss: 0.6788\n",
      "Epoch: 1380, Train Acc: 0.6056, Test Acc: 0.5350, Train Loss: 0.6730, Test Loss: 0.6785\n",
      "Epoch: 1390, Train Acc: 0.6013, Test Acc: 0.5350, Train Loss: 0.6727, Test Loss: 0.6783\n",
      "Epoch: 1400, Train Acc: 0.6078, Test Acc: 0.5400, Train Loss: 0.6724, Test Loss: 0.6780\n",
      "Epoch: 1410, Train Acc: 0.6078, Test Acc: 0.5400, Train Loss: 0.6722, Test Loss: 0.6777\n",
      "Epoch: 1420, Train Acc: 0.6056, Test Acc: 0.5450, Train Loss: 0.6720, Test Loss: 0.6775\n",
      "Epoch: 1430, Train Acc: 0.6121, Test Acc: 0.5400, Train Loss: 0.6721, Test Loss: 0.6771\n",
      "Epoch: 1440, Train Acc: 0.6099, Test Acc: 0.5450, Train Loss: 0.6722, Test Loss: 0.6769\n",
      "Epoch: 1450, Train Acc: 0.6078, Test Acc: 0.5450, Train Loss: 0.6715, Test Loss: 0.6767\n",
      "Epoch: 1460, Train Acc: 0.6034, Test Acc: 0.5500, Train Loss: 0.6710, Test Loss: 0.6765\n",
      "Epoch: 1470, Train Acc: 0.6034, Test Acc: 0.5500, Train Loss: 0.6694, Test Loss: 0.6762\n",
      "Epoch: 1480, Train Acc: 0.6164, Test Acc: 0.5400, Train Loss: 0.6701, Test Loss: 0.6758\n",
      "Epoch: 1490, Train Acc: 0.6164, Test Acc: 0.5450, Train Loss: 0.6695, Test Loss: 0.6755\n",
      "Epoch: 1500, Train Acc: 0.6142, Test Acc: 0.5450, Train Loss: 0.6683, Test Loss: 0.6753\n",
      "Epoch: 1510, Train Acc: 0.6164, Test Acc: 0.5500, Train Loss: 0.6683, Test Loss: 0.6750\n",
      "Epoch: 1520, Train Acc: 0.6207, Test Acc: 0.5550, Train Loss: 0.6688, Test Loss: 0.6747\n",
      "Epoch: 1530, Train Acc: 0.6185, Test Acc: 0.5550, Train Loss: 0.6683, Test Loss: 0.6744\n",
      "Epoch: 1540, Train Acc: 0.6207, Test Acc: 0.5550, Train Loss: 0.6674, Test Loss: 0.6741\n",
      "Epoch: 1550, Train Acc: 0.6228, Test Acc: 0.5550, Train Loss: 0.6672, Test Loss: 0.6739\n",
      "Epoch: 1560, Train Acc: 0.6121, Test Acc: 0.5600, Train Loss: 0.6675, Test Loss: 0.6737\n",
      "Epoch: 1570, Train Acc: 0.6164, Test Acc: 0.5650, Train Loss: 0.6667, Test Loss: 0.6733\n",
      "Epoch: 1580, Train Acc: 0.6315, Test Acc: 0.5550, Train Loss: 0.6666, Test Loss: 0.6729\n",
      "Epoch: 1590, Train Acc: 0.6358, Test Acc: 0.5550, Train Loss: 0.6655, Test Loss: 0.6726\n",
      "Epoch: 1600, Train Acc: 0.6379, Test Acc: 0.5650, Train Loss: 0.6659, Test Loss: 0.6722\n",
      "Epoch: 1610, Train Acc: 0.6379, Test Acc: 0.5650, Train Loss: 0.6654, Test Loss: 0.6719\n",
      "Epoch: 1620, Train Acc: 0.6336, Test Acc: 0.5600, Train Loss: 0.6647, Test Loss: 0.6717\n",
      "Epoch: 1630, Train Acc: 0.6379, Test Acc: 0.5650, Train Loss: 0.6642, Test Loss: 0.6713\n",
      "Epoch: 1640, Train Acc: 0.6401, Test Acc: 0.5650, Train Loss: 0.6633, Test Loss: 0.6709\n",
      "Epoch: 1650, Train Acc: 0.6401, Test Acc: 0.5600, Train Loss: 0.6635, Test Loss: 0.6706\n",
      "Epoch: 1660, Train Acc: 0.6422, Test Acc: 0.5650, Train Loss: 0.6627, Test Loss: 0.6702\n",
      "Epoch: 1670, Train Acc: 0.6401, Test Acc: 0.5650, Train Loss: 0.6630, Test Loss: 0.6699\n",
      "Epoch: 1680, Train Acc: 0.6422, Test Acc: 0.5650, Train Loss: 0.6617, Test Loss: 0.6695\n",
      "Epoch: 1690, Train Acc: 0.6358, Test Acc: 0.5600, Train Loss: 0.6616, Test Loss: 0.6693\n",
      "Epoch: 1700, Train Acc: 0.6401, Test Acc: 0.5600, Train Loss: 0.6613, Test Loss: 0.6689\n",
      "Epoch: 1710, Train Acc: 0.6530, Test Acc: 0.5750, Train Loss: 0.6606, Test Loss: 0.6684\n",
      "Epoch: 1720, Train Acc: 0.6616, Test Acc: 0.5850, Train Loss: 0.6595, Test Loss: 0.6680\n",
      "Epoch: 1730, Train Acc: 0.6681, Test Acc: 0.5900, Train Loss: 0.6596, Test Loss: 0.6676\n",
      "Epoch: 1740, Train Acc: 0.6530, Test Acc: 0.5850, Train Loss: 0.6592, Test Loss: 0.6673\n",
      "Epoch: 1750, Train Acc: 0.6487, Test Acc: 0.5800, Train Loss: 0.6587, Test Loss: 0.6671\n",
      "Epoch: 1760, Train Acc: 0.6595, Test Acc: 0.5850, Train Loss: 0.6575, Test Loss: 0.6666\n",
      "Epoch: 1770, Train Acc: 0.6616, Test Acc: 0.5950, Train Loss: 0.6577, Test Loss: 0.6662\n",
      "Epoch: 1780, Train Acc: 0.6659, Test Acc: 0.5900, Train Loss: 0.6572, Test Loss: 0.6659\n",
      "Epoch: 1790, Train Acc: 0.6659, Test Acc: 0.5900, Train Loss: 0.6575, Test Loss: 0.6655\n",
      "Epoch: 1800, Train Acc: 0.6659, Test Acc: 0.6000, Train Loss: 0.6564, Test Loss: 0.6650\n",
      "Epoch: 1810, Train Acc: 0.6810, Test Acc: 0.6050, Train Loss: 0.6556, Test Loss: 0.6645\n",
      "Epoch: 1820, Train Acc: 0.6789, Test Acc: 0.6050, Train Loss: 0.6550, Test Loss: 0.6641\n",
      "Epoch: 1830, Train Acc: 0.6789, Test Acc: 0.6050, Train Loss: 0.6545, Test Loss: 0.6637\n",
      "Epoch: 1840, Train Acc: 0.6789, Test Acc: 0.6050, Train Loss: 0.6546, Test Loss: 0.6634\n",
      "Epoch: 1850, Train Acc: 0.6897, Test Acc: 0.6050, Train Loss: 0.6539, Test Loss: 0.6629\n",
      "Epoch: 1860, Train Acc: 0.6832, Test Acc: 0.6100, Train Loss: 0.6531, Test Loss: 0.6625\n",
      "Epoch: 1870, Train Acc: 0.6875, Test Acc: 0.6050, Train Loss: 0.6530, Test Loss: 0.6621\n",
      "Epoch: 1880, Train Acc: 0.6897, Test Acc: 0.6100, Train Loss: 0.6519, Test Loss: 0.6616\n",
      "Epoch: 1890, Train Acc: 0.6940, Test Acc: 0.6100, Train Loss: 0.6514, Test Loss: 0.6612\n",
      "Epoch: 1900, Train Acc: 0.6983, Test Acc: 0.6100, Train Loss: 0.6502, Test Loss: 0.6607\n",
      "Epoch: 1910, Train Acc: 0.6918, Test Acc: 0.6200, Train Loss: 0.6514, Test Loss: 0.6602\n",
      "Epoch: 1920, Train Acc: 0.6897, Test Acc: 0.6150, Train Loss: 0.6498, Test Loss: 0.6600\n",
      "Epoch: 1930, Train Acc: 0.6961, Test Acc: 0.6200, Train Loss: 0.6495, Test Loss: 0.6595\n",
      "Epoch: 1940, Train Acc: 0.6983, Test Acc: 0.6250, Train Loss: 0.6481, Test Loss: 0.6590\n",
      "Epoch: 1950, Train Acc: 0.6983, Test Acc: 0.6250, Train Loss: 0.6477, Test Loss: 0.6586\n",
      "Epoch: 1960, Train Acc: 0.7004, Test Acc: 0.6300, Train Loss: 0.6486, Test Loss: 0.6582\n",
      "Epoch: 1970, Train Acc: 0.6961, Test Acc: 0.6350, Train Loss: 0.6468, Test Loss: 0.6577\n",
      "Epoch: 1980, Train Acc: 0.7069, Test Acc: 0.6350, Train Loss: 0.6464, Test Loss: 0.6571\n",
      "Epoch: 1990, Train Acc: 0.7134, Test Acc: 0.6400, Train Loss: 0.6460, Test Loss: 0.6567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▃▂▂▃▃▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▇▇▇█</td></tr><tr><td>Test F1</td><td>▁███████████████████████████████████████</td></tr><tr><td>Test Loss</td><td>███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁███████████████████████████▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test Specificity</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄</td></tr><tr><td>Train Accuracy</td><td>▁▃▃▃▃▃▃▃▃▃▃▃▃▄▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇███</td></tr><tr><td>Train F1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████████████</td></tr><tr><td>Train Loss</td><td>█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁███████████████████████████▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Specificity</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.645</td></tr><tr><td>Test F1</td><td>0.71255</td></tr><tr><td>Test Loss</td><td>0.65627</td></tr><tr><td>Test Sensitivity</td><td>0.85437</td></tr><tr><td>Test Specificity</td><td>0.42268</td></tr><tr><td>Train Accuracy</td><td>0.71336</td></tr><tr><td>Train F1</td><td>0.76122</td></tr><tr><td>Train Loss</td><td>0.64519</td></tr><tr><td>Train Sensitivity</td><td>0.86179</td></tr><tr><td>Train Specificity</td><td>0.54587</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-sweep-19</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/cgfmm7c9' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/cgfmm7c9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_174959-cgfmm7c9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nyn0ht0j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010782497401718522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.833081660447347e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_175959-nyn0ht0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/nyn0ht0j' target=\"_blank\">desert-sweep-20</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/nyn0ht0j' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/nyn0ht0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6938\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6896, Test Loss: 0.6910\n",
      "Epoch: 030, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6900\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6861, Test Loss: 0.6901\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6890\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6823, Test Loss: 0.6874\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6799, Test Loss: 0.6855\n",
      "Epoch: 080, Train Acc: 0.5927, Test Acc: 0.5250, Train Loss: 0.6757, Test Loss: 0.6808\n",
      "Epoch: 090, Train Acc: 0.6401, Test Acc: 0.5900, Train Loss: 0.6700, Test Loss: 0.6755\n",
      "Epoch: 100, Train Acc: 0.6638, Test Acc: 0.6050, Train Loss: 0.6615, Test Loss: 0.6692\n",
      "Epoch: 110, Train Acc: 0.7004, Test Acc: 0.6600, Train Loss: 0.6516, Test Loss: 0.6607\n",
      "Epoch: 120, Train Acc: 0.6961, Test Acc: 0.6350, Train Loss: 0.6414, Test Loss: 0.6510\n",
      "Epoch: 130, Train Acc: 0.7392, Test Acc: 0.6650, Train Loss: 0.6237, Test Loss: 0.6385\n",
      "Epoch: 140, Train Acc: 0.7457, Test Acc: 0.6600, Train Loss: 0.6077, Test Loss: 0.6262\n",
      "Epoch: 150, Train Acc: 0.7047, Test Acc: 0.6500, Train Loss: 0.5962, Test Loss: 0.6183\n",
      "Epoch: 160, Train Acc: 0.7586, Test Acc: 0.6850, Train Loss: 0.5723, Test Loss: 0.6024\n",
      "Epoch: 170, Train Acc: 0.7435, Test Acc: 0.6950, Train Loss: 0.5608, Test Loss: 0.5941\n",
      "Epoch: 180, Train Acc: 0.7435, Test Acc: 0.6950, Train Loss: 0.5479, Test Loss: 0.5874\n",
      "Epoch: 190, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.5287, Test Loss: 0.5776\n",
      "Epoch: 200, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5186, Test Loss: 0.5723\n",
      "Epoch: 210, Train Acc: 0.7435, Test Acc: 0.6900, Train Loss: 0.5227, Test Loss: 0.5753\n",
      "Epoch: 220, Train Acc: 0.7996, Test Acc: 0.7100, Train Loss: 0.4946, Test Loss: 0.5641\n",
      "Epoch: 230, Train Acc: 0.7866, Test Acc: 0.7050, Train Loss: 0.4934, Test Loss: 0.5596\n",
      "Epoch: 240, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.4853, Test Loss: 0.5565\n",
      "Epoch: 250, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4780, Test Loss: 0.5529\n",
      "Epoch: 260, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4721, Test Loss: 0.5494\n",
      "Epoch: 270, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4662, Test Loss: 0.5464\n",
      "Epoch: 280, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4609, Test Loss: 0.5448\n",
      "Epoch: 290, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4519, Test Loss: 0.5418\n",
      "Epoch: 300, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4604, Test Loss: 0.5401\n",
      "Epoch: 310, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4426, Test Loss: 0.5394\n",
      "Epoch: 320, Train Acc: 0.7953, Test Acc: 0.7150, Train Loss: 0.4688, Test Loss: 0.5448\n",
      "Epoch: 330, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.4685, Test Loss: 0.5891\n",
      "Epoch: 340, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4313, Test Loss: 0.5320\n",
      "Epoch: 350, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4313, Test Loss: 0.5371\n",
      "Epoch: 360, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4285, Test Loss: 0.5398\n",
      "Epoch: 370, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4223, Test Loss: 0.5282\n",
      "Epoch: 380, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4453, Test Loss: 0.5344\n",
      "Epoch: 390, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4183, Test Loss: 0.5243\n",
      "Epoch: 400, Train Acc: 0.8211, Test Acc: 0.7600, Train Loss: 0.4178, Test Loss: 0.5304\n",
      "Epoch: 410, Train Acc: 0.8362, Test Acc: 0.7800, Train Loss: 0.4188, Test Loss: 0.5213\n",
      "Epoch: 420, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4089, Test Loss: 0.5253\n",
      "Epoch: 430, Train Acc: 0.8362, Test Acc: 0.7800, Train Loss: 0.4139, Test Loss: 0.5208\n",
      "Epoch: 440, Train Acc: 0.8341, Test Acc: 0.7900, Train Loss: 0.4038, Test Loss: 0.5198\n",
      "Epoch: 450, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4178, Test Loss: 0.5594\n",
      "Epoch: 460, Train Acc: 0.8362, Test Acc: 0.7800, Train Loss: 0.4006, Test Loss: 0.5199\n",
      "Epoch: 470, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.4254, Test Loss: 0.5252\n",
      "Epoch: 480, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.3958, Test Loss: 0.5219\n",
      "Epoch: 490, Train Acc: 0.8319, Test Acc: 0.7850, Train Loss: 0.3980, Test Loss: 0.5172\n",
      "Epoch: 500, Train Acc: 0.8190, Test Acc: 0.7650, Train Loss: 0.3961, Test Loss: 0.5352\n",
      "Epoch: 510, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.3947, Test Loss: 0.5441\n",
      "Epoch: 520, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.3960, Test Loss: 0.5210\n",
      "Epoch: 530, Train Acc: 0.8319, Test Acc: 0.7750, Train Loss: 0.3912, Test Loss: 0.5201\n",
      "Epoch: 540, Train Acc: 0.8254, Test Acc: 0.7700, Train Loss: 0.4107, Test Loss: 0.5287\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▃▄▅▄▄▅▅▅▆▅▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇█▇██████▇</td></tr><tr><td>Test F1</td><td>▅▅▅▅▅▅▅▄▅▂▁▂▄▄▄▅▆▆▆▇▅▇▇▇▄█▇▇▇▇▇▇▇▇█████▆</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▆▄▄▂▁▂▃▃▃▄▄▄▄▅▃▅▅▅▃▆▄▅▄▄▅▅▄▄▅▆▅▅▅▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▄▆▆▇██▇▇█▇▇▇▇▇█▇▇▇█▇████▇████▇████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▃▄▅▅▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█████▇</td></tr><tr><td>Train F1</td><td>▃▃▃▃▃▃▃▂▄▃▁▂▆▆▅▇▆▇▇▇▆▇▇▇▅▇▇▇▇▇▇█▇▇██▇██▇</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▅▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂</td></tr><tr><td>Train Sensitivity</td><td>██████▆▃▄▃▁▂▄▄▃▅▅▅▅▅▄▅▅▅▃▅▅▅▅▅▆▅▅▄▅▆▅▅▅▄</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▄▆▆▇██▇▇█▇▇▇▇▇█▇▇▇█▇████▇████▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.75</td></tr><tr><td>Test Loss</td><td>0.52869</td></tr><tr><td>Test Sensitivity</td><td>0.6699</td></tr><tr><td>Test Specificity</td><td>0.87629</td></tr><tr><td>Train Accuracy</td><td>0.82543</td></tr><tr><td>Train F1</td><td>0.81549</td></tr><tr><td>Train Loss</td><td>0.41071</td></tr><tr><td>Train Sensitivity</td><td>0.72764</td></tr><tr><td>Train Specificity</td><td>0.93578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">desert-sweep-20</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/nyn0ht0j' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/nyn0ht0j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_175959-nyn0ht0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: taim9ee3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003424846485210202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.336917813937063e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_180233-taim9ee3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/taim9ee3' target=\"_blank\">morning-sweep-21</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/taim9ee3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/taim9ee3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6939\n",
      "Epoch: 010, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6918\n",
      "Epoch: 020, Train Acc: 0.5345, Test Acc: 0.5650, Train Loss: 0.6872, Test Loss: 0.6863\n",
      "Epoch: 030, Train Acc: 0.5647, Test Acc: 0.5750, Train Loss: 0.6768, Test Loss: 0.6848\n",
      "Epoch: 040, Train Acc: 0.6487, Test Acc: 0.6600, Train Loss: 0.7392, Test Loss: 0.7702\n",
      "Epoch: 050, Train Acc: 0.6659, Test Acc: 0.6900, Train Loss: 0.6834, Test Loss: 0.6857\n",
      "Epoch: 060, Train Acc: 0.5797, Test Acc: 0.6200, Train Loss: 1.0721, Test Loss: 1.0352\n",
      "Epoch: 070, Train Acc: 0.8060, Test Acc: 0.7550, Train Loss: 0.4609, Test Loss: 0.5352\n",
      "Epoch: 080, Train Acc: 0.5582, Test Acc: 0.5900, Train Loss: 1.1392, Test Loss: 1.1121\n",
      "Epoch: 090, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.4528, Test Loss: 0.5715\n",
      "Epoch: 100, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4315, Test Loss: 0.5149\n",
      "Epoch: 110, Train Acc: 0.6767, Test Acc: 0.6900, Train Loss: 0.7531, Test Loss: 0.8022\n",
      "Epoch: 120, Train Acc: 0.6293, Test Acc: 0.6500, Train Loss: 0.8280, Test Loss: 0.8633\n",
      "Epoch: 130, Train Acc: 0.6638, Test Acc: 0.5750, Train Loss: 0.6166, Test Loss: 0.8138\n",
      "Epoch: 140, Train Acc: 0.6207, Test Acc: 0.5400, Train Loss: 0.7079, Test Loss: 0.9263\n",
      "Epoch: 150, Train Acc: 0.7543, Test Acc: 0.7300, Train Loss: 0.5543, Test Loss: 0.6479\n",
      "Epoch: 160, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4478, Test Loss: 0.5896\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▂▂▃▂▃▃▅▆▅▅▅▆▅▆▃▁█▇▆▇▆▇▇▄▃▃█▇▆▁▁▇▅▁▃▁</td></tr><tr><td>Test F1</td><td>▇▇▇▆▇▁▂▂▃▃▄▆▅▅▅▅▅▇▃▇█▇▆██▆▇▃▃▂█▇▆▇▇█▇▇▇▇</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▂▂▂▃▄▃▂▃▃▃▃▃▁▅▅▁▁▂▁▁▂▁▆▅█▁▂▂█▅▁▂▇▃▅</td></tr><tr><td>Test Sensitivity</td><td>███▅▇▁▂▂▂▂▃▄▃▃▃▃▃▇▂█▅▅▄▇▇▄▅▂▂▁▆▅▄██▇▇█▇█</td></tr><tr><td>Test Specificity</td><td>▁▁▁▄▂████████████▅█▁▇▇█▅▅█▇███▇▇█▁▁▆▄▁▃▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▁▂▂▂▂▃▅▄▃▄▄▄▇▂▁▇█▄▇▇▅▇▂▂▁█▇▅▁▂█▇▁▅▂</td></tr><tr><td>Train F1</td><td>▆▆▆▅▆▁▂▃▃▃▄▆▄▄▅▅▅█▂▆▇█▅██▆▇▂▂▁█▇▆▆▇██▆▇▇</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▃▃▃▄▄▂▃▄▃▃▃▁▆▅▂▁▃▁▁▂▂▆▆█▁▂▃▆▄▁▁▅▂▄</td></tr><tr><td>Train Sensitivity</td><td>███▅▇▁▂▂▂▂▃▄▃▃▃▃▃▇▂█▆▆▃▇▇▄▅▂▂▁▆▅▄██▇▇███</td></tr><tr><td>Train Specificity</td><td>▁▁▁▄▃████████████▆█▁▇▇█▆▆█████▇██▁▁▆▅▁▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.525</td></tr><tr><td>Test F1</td><td>0.68227</td></tr><tr><td>Test Loss</td><td>1.08606</td></tr><tr><td>Test Sensitivity</td><td>0.99029</td></tr><tr><td>Test Specificity</td><td>0.03093</td></tr><tr><td>Train Accuracy</td><td>0.57112</td></tr><tr><td>Train F1</td><td>0.71118</td></tr><tr><td>Train Loss</td><td>0.80757</td></tr><tr><td>Train Sensitivity</td><td>0.99593</td></tr><tr><td>Train Specificity</td><td>0.09174</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-21</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/taim9ee3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/taim9ee3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_180233-taim9ee3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87xzumaz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004231690461725518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.317351503253469e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_180329-87xzumaz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/87xzumaz' target=\"_blank\">misty-sweep-22</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/87xzumaz' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/87xzumaz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6936, Test Loss: 0.6978\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6995, Test Loss: 0.7049\n",
      "Epoch: 020, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6946, Test Loss: 0.6942\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6925\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6922\n",
      "Epoch: 050, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6907\n",
      "Epoch: 060, Train Acc: 0.5733, Test Acc: 0.5400, Train Loss: 0.6858, Test Loss: 0.6864\n",
      "Epoch: 070, Train Acc: 0.5797, Test Acc: 0.5750, Train Loss: 0.6394, Test Loss: 0.6478\n",
      "Epoch: 080, Train Acc: 0.6315, Test Acc: 0.6550, Train Loss: 0.6468, Test Loss: 0.6553\n",
      "Epoch: 090, Train Acc: 0.6336, Test Acc: 0.6500, Train Loss: 0.7815, Test Loss: 0.7647\n",
      "Epoch: 100, Train Acc: 0.6552, Test Acc: 0.6800, Train Loss: 0.7546, Test Loss: 0.7347\n",
      "Epoch: 110, Train Acc: 0.6142, Test Acc: 0.6600, Train Loss: 0.8804, Test Loss: 0.8385\n",
      "Epoch: 120, Train Acc: 0.7974, Test Acc: 0.7750, Train Loss: 0.4670, Test Loss: 0.5084\n",
      "Epoch: 130, Train Acc: 0.6789, Test Acc: 0.7050, Train Loss: 0.6918, Test Loss: 0.6867\n",
      "Epoch: 140, Train Acc: 0.7629, Test Acc: 0.7400, Train Loss: 0.5429, Test Loss: 0.5616\n",
      "Epoch: 150, Train Acc: 0.7909, Test Acc: 0.7550, Train Loss: 0.4937, Test Loss: 0.5330\n",
      "Epoch: 160, Train Acc: 0.8147, Test Acc: 0.7800, Train Loss: 0.4553, Test Loss: 0.5149\n",
      "Epoch: 170, Train Acc: 0.8082, Test Acc: 0.7750, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch: 180, Train Acc: 0.8233, Test Acc: 0.7750, Train Loss: 0.4303, Test Loss: 0.5149\n",
      "Epoch: 190, Train Acc: 0.7953, Test Acc: 0.7200, Train Loss: 0.4072, Test Loss: 0.5682\n",
      "Epoch: 200, Train Acc: 0.6401, Test Acc: 0.5600, Train Loss: 0.6650, Test Loss: 0.9225\n",
      "Epoch: 210, Train Acc: 0.7134, Test Acc: 0.7300, Train Loss: 0.7149, Test Loss: 0.7478\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▁▂▂▂▂▂▂▂▂▄▃▄▅▅▅▅▅▅▂▇▅▆▇█▇▇███▇█▆▃▂▇▆▄</td></tr><tr><td>Test F1</td><td>▁▁▇▁▇▇▇▇▇▇▇▇▆▅▅▆▅▆▆▅▆▂▇▅▇▇██▇███▇█▇▇▇█▆▄</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▂▆▁▃▂▁▁▁▂▁▁▁▂▁▂▃█▁▄▅</td></tr><tr><td>Test Sensitivity</td><td>▁▁█▁████████▄▃▃▄▃▄▄▃▄▂▅▃▄▅▆▅▅▆▆▇▅▆▇▇█▇▄▃</td></tr><tr><td>Test Specificity</td><td>██▁█▁▁▁▁▁▁▁▂▇▇████████▇██▇▇▇█▇▆▆█▇▅▃▁▆██</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▁▂▂▂▂▂▂▂▃▄▃▃▄▄▄▄▄▄▁▆▄▅▆▇▇▆▇██▆█▇▅▂█▅▃</td></tr><tr><td>Train F1</td><td>▁▁▇▁▇▇▇▇▇▇▇▇▅▅▄▅▅▅▅▅▅▁▇▄▆▇▇▇▇▇██▆██▇▇█▆▄</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▃█▂▄▃▂▂▂▂▂▁▁▂▁▂▂▇▁▄▆</td></tr><tr><td>Train Sensitivity</td><td>▁▁█▁███████▇▄▃▃▄▃▃▃▃▃▁▅▃▄▅▆▆▅▆▇▇▄▆▇██▇▄▂</td></tr><tr><td>Train Specificity</td><td>██▁█▁▁▁▁▁▁▁▂▇█████████████████▇▇██▅▃▁▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.605</td></tr><tr><td>Test F1</td><td>0.37795</td></tr><tr><td>Test Loss</td><td>1.18001</td></tr><tr><td>Test Sensitivity</td><td>0.23301</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.56681</td></tr><tr><td>Train F1</td><td>0.30928</td></tr><tr><td>Train Loss</td><td>1.22215</td></tr><tr><td>Train Sensitivity</td><td>0.18293</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-22</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/87xzumaz' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/87xzumaz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_180329-87xzumaz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ezcjtaak with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001413746716976139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.910978223868808e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_180451-ezcjtaak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/ezcjtaak' target=\"_blank\">astral-sweep-23</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/ezcjtaak' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/ezcjtaak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6940\n",
      "Epoch: 010, Train Acc: 0.4828, Test Acc: 0.5000, Train Loss: 0.6930, Test Loss: 0.6923\n",
      "Epoch: 020, Train Acc: 0.4741, Test Acc: 0.4950, Train Loss: 0.7317, Test Loss: 0.7244\n",
      "Epoch: 030, Train Acc: 0.5216, Test Acc: 0.5500, Train Loss: 0.8147, Test Loss: 0.8094\n",
      "Epoch: 040, Train Acc: 0.7284, Test Acc: 0.6700, Train Loss: 0.5441, Test Loss: 0.5961\n",
      "Epoch: 050, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.4873, Test Loss: 0.5613\n",
      "Epoch: 060, Train Acc: 0.5905, Test Acc: 0.6250, Train Loss: 0.8803, Test Loss: 0.8729\n",
      "Epoch: 070, Train Acc: 0.7953, Test Acc: 0.7400, Train Loss: 0.4693, Test Loss: 0.5390\n",
      "Epoch: 080, Train Acc: 0.6832, Test Acc: 0.5950, Train Loss: 0.5674, Test Loss: 0.7081\n",
      "Epoch: 090, Train Acc: 0.6034, Test Acc: 0.5550, Train Loss: 0.7019, Test Loss: 0.8675\n",
      "Epoch: 100, Train Acc: 0.7909, Test Acc: 0.7000, Train Loss: 0.4428, Test Loss: 0.5724\n",
      "Epoch: 110, Train Acc: 0.8190, Test Acc: 0.7650, Train Loss: 0.4337, Test Loss: 0.5232\n",
      "Epoch: 120, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4526, Test Loss: 0.5359\n",
      "Epoch: 130, Train Acc: 0.5431, Test Acc: 0.5850, Train Loss: 1.4296, Test Loss: 1.3967\n",
      "Epoch: 140, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.4224, Test Loss: 0.5748\n",
      "Epoch: 150, Train Acc: 0.8362, Test Acc: 0.7800, Train Loss: 0.3784, Test Loss: 0.5149\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▂▂▁▁▁▁▂▃▅▅▄▅▅▇▄▆▅▇▇▇▇▅▄▇▆▆▇▅▅██▃▆█▇▆▂▆█</td></tr><tr><td>Test F1</td><td>▇▇▇▁▁▁▂▂▃▆▆▅▆▆█▄▇▅█▇▇▇▇▇▇▇█▇▆▅██▄▆███▇██</td></tr><tr><td>Test Loss</td><td>▃▃▃▃▃▃▃▄▄▂▂▃▃▃▁▆▂▄▁▁▁▁▂▃▂▂▂▁▄▆▁▁█▄▁▁▂▆▂▁</td></tr><tr><td>Test Sensitivity</td><td>███▁▁▁▁▂▂▄▄▃▄▄▆▃▅▃▇▅▅▅▇▇▅▅▇▅▄▃▆▆▂▄▆▇▇█▇▇</td></tr><tr><td>Test Specificity</td><td>▁▁▁██████▇▇███▆█▇█▆▇▇▇▅▃██▅▇██▇▇██▇▆▅▁▅▆</td></tr><tr><td>Train Accuracy</td><td>▂▂▂▁▁▁▁▂▂▆▆▄▄▄▇▃▆▄▇▇▇▇▇▅▆▆▇█▄▃██▃▅██▇▃▇█</td></tr><tr><td>Train F1</td><td>▇▇▇▁▁▁▁▂▃▇▇▅▅▅█▄▇▅█████▇▆▆██▅▄██▃▆███▇██</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▄▄▄▄▄▂▂▄▃▄▂▆▂▅▁▂▂▂▂▂▃▃▂▁▄▆▁▁█▄▁▁▁▄▁▁</td></tr><tr><td>Train Sensitivity</td><td>███▁▁▁▁▁▂▅▅▃▄▃▆▂▅▃▇▆▆▆▇█▄▅▇▆▃▃▆▆▂▄▆▇▇█▇▇</td></tr><tr><td>Train Specificity</td><td>▁▁▁██████▇████▇███▇▇▇▇▆▄██▆▇██▇▇██▇▇▆▁▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.78</td></tr><tr><td>Test F1</td><td>0.79048</td></tr><tr><td>Test Loss</td><td>0.51808</td></tr><tr><td>Test Sensitivity</td><td>0.80583</td></tr><tr><td>Test Specificity</td><td>0.75258</td></tr><tr><td>Train Accuracy</td><td>0.83836</td></tr><tr><td>Train F1</td><td>0.84663</td></tr><tr><td>Train Loss</td><td>0.37723</td></tr><tr><td>Train Sensitivity</td><td>0.84146</td></tr><tr><td>Train Specificity</td><td>0.83486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-23</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/ezcjtaak' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/ezcjtaak</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_180451-ezcjtaak/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3qxkrqw3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00016208978980698224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00013185369963553963\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_180538-3qxkrqw3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/3qxkrqw3' target=\"_blank\">comic-sweep-24</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/3qxkrqw3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/3qxkrqw3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6938\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6924\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.4850, Train Loss: 0.6894, Test Loss: 0.6906\n",
      "Epoch: 030, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6875, Test Loss: 0.6899\n",
      "Epoch: 040, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6849, Test Loss: 0.6887\n",
      "Epoch: 050, Train Acc: 0.5668, Test Acc: 0.5150, Train Loss: 0.6811, Test Loss: 0.6852\n",
      "Epoch: 060, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6747, Test Loss: 0.6800\n",
      "Epoch: 070, Train Acc: 0.6487, Test Acc: 0.6550, Train Loss: 0.6667, Test Loss: 0.6707\n",
      "Epoch: 080, Train Acc: 0.6918, Test Acc: 0.6700, Train Loss: 0.6504, Test Loss: 0.6575\n",
      "Epoch: 090, Train Acc: 0.7004, Test Acc: 0.6800, Train Loss: 0.6307, Test Loss: 0.6411\n",
      "Epoch: 100, Train Acc: 0.6746, Test Acc: 0.6500, Train Loss: 0.6130, Test Loss: 0.6265\n",
      "Epoch: 110, Train Acc: 0.7241, Test Acc: 0.6700, Train Loss: 0.5833, Test Loss: 0.6066\n",
      "Epoch: 120, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5541, Test Loss: 0.5906\n",
      "Epoch: 130, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.5315, Test Loss: 0.5799\n",
      "Epoch: 140, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5171, Test Loss: 0.5738\n",
      "Epoch: 150, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5116, Test Loss: 0.5660\n",
      "Epoch: 160, Train Acc: 0.7974, Test Acc: 0.7200, Train Loss: 0.4951, Test Loss: 0.5658\n",
      "Epoch: 170, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.4902, Test Loss: 0.5572\n",
      "Epoch: 180, Train Acc: 0.7802, Test Acc: 0.7250, Train Loss: 0.4901, Test Loss: 0.5729\n",
      "Epoch: 190, Train Acc: 0.7974, Test Acc: 0.7100, Train Loss: 0.4726, Test Loss: 0.5477\n",
      "Epoch: 200, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4764, Test Loss: 0.5674\n",
      "Epoch: 210, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4603, Test Loss: 0.5395\n",
      "Epoch: 220, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4573, Test Loss: 0.5386\n",
      "Epoch: 230, Train Acc: 0.7931, Test Acc: 0.7400, Train Loss: 0.4544, Test Loss: 0.5528\n",
      "Epoch: 240, Train Acc: 0.8082, Test Acc: 0.7450, Train Loss: 0.4427, Test Loss: 0.5354\n",
      "Epoch: 250, Train Acc: 0.7996, Test Acc: 0.7500, Train Loss: 0.4433, Test Loss: 0.5366\n",
      "Epoch: 260, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4381, Test Loss: 0.5270\n",
      "Epoch: 270, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4364, Test Loss: 0.5298\n",
      "Epoch: 280, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4404, Test Loss: 0.5247\n",
      "Epoch: 290, Train Acc: 0.8082, Test Acc: 0.7550, Train Loss: 0.4293, Test Loss: 0.5360\n",
      "Epoch: 300, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4223, Test Loss: 0.5225\n",
      "Epoch: 310, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4174, Test Loss: 0.5208\n",
      "Epoch: 320, Train Acc: 0.8211, Test Acc: 0.7750, Train Loss: 0.4150, Test Loss: 0.5175\n",
      "Epoch: 330, Train Acc: 0.8297, Test Acc: 0.7700, Train Loss: 0.4176, Test Loss: 0.5161\n",
      "Epoch: 340, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4172, Test Loss: 0.5156\n",
      "Epoch: 350, Train Acc: 0.8233, Test Acc: 0.7800, Train Loss: 0.4018, Test Loss: 0.5158\n",
      "Epoch: 360, Train Acc: 0.8362, Test Acc: 0.7850, Train Loss: 0.4090, Test Loss: 0.5164\n",
      "Epoch: 370, Train Acc: 0.8233, Test Acc: 0.7700, Train Loss: 0.4007, Test Loss: 0.5198\n",
      "Epoch: 380, Train Acc: 0.8297, Test Acc: 0.7800, Train Loss: 0.3971, Test Loss: 0.5143\n",
      "Epoch: 390, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4136, Test Loss: 0.5168\n",
      "Epoch: 400, Train Acc: 0.8470, Test Acc: 0.7800, Train Loss: 0.3975, Test Loss: 0.5132\n",
      "Epoch: 410, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.4003, Test Loss: 0.5162\n",
      "Epoch: 420, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.3904, Test Loss: 0.5200\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▂▂▂▅▄▄▆▅▅▅▆▆▇▇▇▇▅▇▇▇▇▇▇▇█▇▇██▇█▇▇█▇█</td></tr><tr><td>Test F1</td><td>▅▅▄▅▅▅▅▄▁▁▄▄▄▄▅▆▇▆▆▇▃▆▆▇▆▇▇██▇█████▆██▆█</td></tr><tr><td>Test Loss</td><td>██████▇▇▆▅▅▄▄▃▃▃▃▂▂▂▃▂▂▂▁▃▁▂▁▁▁▁▁▂▁▁▂▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██▇██▇▇▄▁▁▃▃▃▃▃▄▅▄▄▄▂▄▅▅▄▆▅▆▅▄▆▅▅▆▅▄▆▅▄▆</td></tr><tr><td>Test Specificity</td><td>▁▁▂▁▂▂▂▆██▇▇▇▇▇▇▆▇▇▇█▇▇▇▇▆▇▆▇█▇▇▇▇▇█▆▇█▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▃▅▄▄▆▆▆▇▇▇▇▇▇▇▆▇█▇█▇█▇████████████</td></tr><tr><td>Train F1</td><td>▄▄▃▃▄▄▄▄▁▁▅▅▅▆▆▇▇▇▇▇▅▇▇▇▇▇█▇█▇█████▇██▇█</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▆▅▅▄▄▃▃▃▃▃▄▃▂▂▂▃▂▂▂▂▂▂▁▁▁▂▁▁▂▁</td></tr><tr><td>Train Sensitivity</td><td>██▆▇▇▇▇▄▁▁▃▃▃▄▄▅▅▅▅▅▃▅▅▅▅▆▅▅▅▅▅▅▅▆▅▄▆▅▅▅</td></tr><tr><td>Train Specificity</td><td>▁▁▂▂▂▃▃▆██▇▇█▇▇▇▇▇▇▇█▇▇▇▇▆▇▇▇█▇▇█▇██▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.78</td></tr><tr><td>Test F1</td><td>0.78846</td></tr><tr><td>Test Loss</td><td>0.5187</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.76289</td></tr><tr><td>Train Accuracy</td><td>0.82974</td></tr><tr><td>Train F1</td><td>0.83507</td></tr><tr><td>Train Loss</td><td>0.3852</td></tr><tr><td>Train Sensitivity</td><td>0.81301</td></tr><tr><td>Train Specificity</td><td>0.84862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-sweep-24</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/3qxkrqw3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/3qxkrqw3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_180538-3qxkrqw3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1i0akird with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.56015974288703e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.594503297417878e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_180730-1i0akird</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/1i0akird' target=\"_blank\">crisp-sweep-25</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/1i0akird' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/1i0akird</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6939, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5129, Test Acc: 0.5100, Train Loss: 0.6927, Test Loss: 0.6927\n",
      "Epoch: 020, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6913, Test Loss: 0.6917\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6918\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6918\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6918\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6917\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6916\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6916\n",
      "Epoch: 090, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6915\n",
      "Epoch: 100, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6915\n",
      "Epoch: 110, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6914\n",
      "Epoch: 120, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6914\n",
      "Epoch: 130, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6914\n",
      "Epoch: 140, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6914\n",
      "Epoch: 150, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6912\n",
      "Epoch: 160, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6912\n",
      "Epoch: 170, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6911\n",
      "Epoch: 180, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6911\n",
      "Epoch: 190, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6911\n",
      "Epoch: 200, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6911\n",
      "Epoch: 210, Train Acc: 0.5259, Test Acc: 0.5100, Train Loss: 0.6891, Test Loss: 0.6910\n",
      "Epoch: 220, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6910\n",
      "Epoch: 230, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6910\n",
      "Epoch: 240, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6909\n",
      "Epoch: 250, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6898, Test Loss: 0.6909\n",
      "Epoch: 260, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6894, Test Loss: 0.6908\n",
      "Epoch: 270, Train Acc: 0.5280, Test Acc: 0.5100, Train Loss: 0.6901, Test Loss: 0.6908\n",
      "Epoch: 280, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6897, Test Loss: 0.6908\n",
      "Epoch: 290, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6907\n",
      "Epoch: 300, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 310, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6897, Test Loss: 0.6907\n",
      "Epoch: 320, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6889, Test Loss: 0.6907\n",
      "Epoch: 330, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6887, Test Loss: 0.6906\n",
      "Epoch: 340, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6884, Test Loss: 0.6905\n",
      "Epoch: 350, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6896, Test Loss: 0.6905\n",
      "Epoch: 360, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6894, Test Loss: 0.6905\n",
      "Epoch: 370, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6890, Test Loss: 0.6904\n",
      "Epoch: 380, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6892, Test Loss: 0.6904\n",
      "Epoch: 390, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6903\n",
      "Epoch: 400, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6902\n",
      "Epoch: 410, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6903\n",
      "Epoch: 420, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6902\n",
      "Epoch: 430, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6902\n",
      "Epoch: 440, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6902\n",
      "Epoch: 450, Train Acc: 0.5366, Test Acc: 0.5100, Train Loss: 0.6882, Test Loss: 0.6902\n",
      "Epoch: 460, Train Acc: 0.5366, Test Acc: 0.5100, Train Loss: 0.6882, Test Loss: 0.6901\n",
      "Epoch: 470, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6901\n",
      "Epoch: 480, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6900\n",
      "Epoch: 490, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6900\n",
      "Epoch: 500, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6900\n",
      "Epoch: 510, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6899\n",
      "Epoch: 520, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6899\n",
      "Epoch: 530, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6899\n",
      "Epoch: 540, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6899\n",
      "Epoch: 550, Train Acc: 0.5366, Test Acc: 0.5100, Train Loss: 0.6880, Test Loss: 0.6899\n",
      "Epoch: 560, Train Acc: 0.5366, Test Acc: 0.5100, Train Loss: 0.6878, Test Loss: 0.6898\n",
      "Epoch: 570, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6897\n",
      "Epoch: 580, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6896\n",
      "Epoch: 590, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6896\n",
      "Epoch: 600, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6896\n",
      "Epoch: 610, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6895\n",
      "Epoch: 620, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6894\n",
      "Epoch: 630, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6894\n",
      "Epoch: 640, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6894\n",
      "Epoch: 650, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6894\n",
      "Epoch: 660, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6893\n",
      "Epoch: 670, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6893\n",
      "Epoch: 680, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6893\n",
      "Epoch: 690, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6893\n",
      "Epoch: 700, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6893\n",
      "Epoch: 710, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6892\n",
      "Epoch: 720, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6891\n",
      "Epoch: 730, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6891\n",
      "Epoch: 740, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6891\n",
      "Epoch: 750, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6890\n",
      "Epoch: 760, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6889\n",
      "Epoch: 770, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6889\n",
      "Epoch: 780, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6889\n",
      "Epoch: 790, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6867, Test Loss: 0.6889\n",
      "Epoch: 800, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6889\n",
      "Epoch: 810, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6888\n",
      "Epoch: 820, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6888\n",
      "Epoch: 830, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6864, Test Loss: 0.6887\n",
      "Epoch: 840, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6869, Test Loss: 0.6886\n",
      "Epoch: 850, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6886\n",
      "Epoch: 860, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6871, Test Loss: 0.6885\n",
      "Epoch: 870, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6865, Test Loss: 0.6885\n",
      "Epoch: 880, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6864, Test Loss: 0.6885\n",
      "Epoch: 890, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6865, Test Loss: 0.6885\n",
      "Epoch: 900, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6884\n",
      "Epoch: 910, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6865, Test Loss: 0.6884\n",
      "Epoch: 920, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6883\n",
      "Epoch: 930, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6860, Test Loss: 0.6883\n",
      "Epoch: 940, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6853, Test Loss: 0.6882\n",
      "Epoch: 950, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6860, Test Loss: 0.6882\n",
      "Epoch: 960, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6881\n",
      "Epoch: 970, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6861, Test Loss: 0.6881\n",
      "Epoch: 980, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6881\n",
      "Epoch: 990, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6862, Test Loss: 0.6881\n",
      "Epoch: 1000, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6880\n",
      "Epoch: 1010, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6850, Test Loss: 0.6879\n",
      "Epoch: 1020, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6858, Test Loss: 0.6879\n",
      "Epoch: 1030, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6856, Test Loss: 0.6879\n",
      "Epoch: 1040, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6859, Test Loss: 0.6879\n",
      "Epoch: 1050, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6852, Test Loss: 0.6878\n",
      "Epoch: 1060, Train Acc: 0.5496, Test Acc: 0.5200, Train Loss: 0.6848, Test Loss: 0.6878\n",
      "Epoch: 1070, Train Acc: 0.5517, Test Acc: 0.5200, Train Loss: 0.6850, Test Loss: 0.6877\n",
      "Epoch: 1080, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6853, Test Loss: 0.6876\n",
      "Epoch: 1090, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6850, Test Loss: 0.6876\n",
      "Epoch: 1100, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6854, Test Loss: 0.6875\n",
      "Epoch: 1110, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6845, Test Loss: 0.6875\n",
      "Epoch: 1120, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6850, Test Loss: 0.6874\n",
      "Epoch: 1130, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6845, Test Loss: 0.6875\n",
      "Epoch: 1140, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6847, Test Loss: 0.6874\n",
      "Epoch: 1150, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6854, Test Loss: 0.6873\n",
      "Epoch: 1160, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6873\n",
      "Epoch: 1170, Train Acc: 0.5496, Test Acc: 0.5250, Train Loss: 0.6839, Test Loss: 0.6873\n",
      "Epoch: 1180, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6872\n",
      "Epoch: 1190, Train Acc: 0.5560, Test Acc: 0.5250, Train Loss: 0.6844, Test Loss: 0.6871\n",
      "Epoch: 1200, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6871\n",
      "Epoch: 1210, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6846, Test Loss: 0.6871\n",
      "Epoch: 1220, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6847, Test Loss: 0.6870\n",
      "Epoch: 1230, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6843, Test Loss: 0.6870\n",
      "Epoch: 1240, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6837, Test Loss: 0.6869\n",
      "Epoch: 1250, Train Acc: 0.5517, Test Acc: 0.5250, Train Loss: 0.6834, Test Loss: 0.6869\n",
      "Epoch: 1260, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6843, Test Loss: 0.6868\n",
      "Epoch: 1270, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6835, Test Loss: 0.6868\n",
      "Epoch: 1280, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6838, Test Loss: 0.6868\n",
      "Epoch: 1290, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6842, Test Loss: 0.6867\n",
      "Epoch: 1300, Train Acc: 0.5539, Test Acc: 0.5250, Train Loss: 0.6839, Test Loss: 0.6866\n",
      "Epoch: 1310, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6831, Test Loss: 0.6866\n",
      "Epoch: 1320, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6837, Test Loss: 0.6865\n",
      "Epoch: 1330, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6836, Test Loss: 0.6865\n",
      "Epoch: 1340, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6837, Test Loss: 0.6865\n",
      "Epoch: 1350, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6837, Test Loss: 0.6864\n",
      "Epoch: 1360, Train Acc: 0.5603, Test Acc: 0.5200, Train Loss: 0.6839, Test Loss: 0.6863\n",
      "Epoch: 1370, Train Acc: 0.5603, Test Acc: 0.5200, Train Loss: 0.6833, Test Loss: 0.6863\n",
      "Epoch: 1380, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6831, Test Loss: 0.6862\n",
      "Epoch: 1390, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6842, Test Loss: 0.6861\n",
      "Epoch: 1400, Train Acc: 0.5690, Test Acc: 0.5300, Train Loss: 0.6833, Test Loss: 0.6860\n",
      "Epoch: 1410, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6828, Test Loss: 0.6860\n",
      "Epoch: 1420, Train Acc: 0.5647, Test Acc: 0.5250, Train Loss: 0.6832, Test Loss: 0.6860\n",
      "Epoch: 1430, Train Acc: 0.5647, Test Acc: 0.5250, Train Loss: 0.6830, Test Loss: 0.6859\n",
      "Epoch: 1440, Train Acc: 0.5690, Test Acc: 0.5250, Train Loss: 0.6830, Test Loss: 0.6858\n",
      "Epoch: 1450, Train Acc: 0.5690, Test Acc: 0.5250, Train Loss: 0.6826, Test Loss: 0.6858\n",
      "Epoch: 1460, Train Acc: 0.5733, Test Acc: 0.5300, Train Loss: 0.6828, Test Loss: 0.6857\n",
      "Epoch: 1470, Train Acc: 0.5625, Test Acc: 0.5150, Train Loss: 0.6826, Test Loss: 0.6857\n",
      "Epoch: 1480, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6836, Test Loss: 0.6857\n",
      "Epoch: 1490, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6832, Test Loss: 0.6856\n",
      "Epoch: 1500, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6832, Test Loss: 0.6855\n",
      "Epoch: 1510, Train Acc: 0.5647, Test Acc: 0.5150, Train Loss: 0.6830, Test Loss: 0.6855\n",
      "Epoch: 1520, Train Acc: 0.5647, Test Acc: 0.5150, Train Loss: 0.6829, Test Loss: 0.6854\n",
      "Epoch: 1530, Train Acc: 0.5711, Test Acc: 0.5200, Train Loss: 0.6823, Test Loss: 0.6853\n",
      "Epoch: 1540, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6821, Test Loss: 0.6852\n",
      "Epoch: 1550, Train Acc: 0.5733, Test Acc: 0.5200, Train Loss: 0.6818, Test Loss: 0.6852\n",
      "Epoch: 1560, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6814, Test Loss: 0.6851\n",
      "Epoch: 1570, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6824, Test Loss: 0.6851\n",
      "Epoch: 1580, Train Acc: 0.5668, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6850\n",
      "Epoch: 1590, Train Acc: 0.5690, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6850\n",
      "Epoch: 1600, Train Acc: 0.5711, Test Acc: 0.5200, Train Loss: 0.6823, Test Loss: 0.6849\n",
      "Epoch: 1610, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6812, Test Loss: 0.6848\n",
      "Epoch: 1620, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6847\n",
      "Epoch: 1630, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6819, Test Loss: 0.6847\n",
      "Epoch: 1640, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6807, Test Loss: 0.6846\n",
      "Epoch: 1650, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6812, Test Loss: 0.6845\n",
      "Epoch: 1660, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6816, Test Loss: 0.6845\n",
      "Epoch: 1670, Train Acc: 0.5905, Test Acc: 0.5200, Train Loss: 0.6812, Test Loss: 0.6844\n",
      "Epoch: 1680, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6809, Test Loss: 0.6844\n",
      "Epoch: 1690, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6809, Test Loss: 0.6843\n",
      "Epoch: 1700, Train Acc: 0.5905, Test Acc: 0.5200, Train Loss: 0.6809, Test Loss: 0.6842\n",
      "Epoch: 1710, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6803, Test Loss: 0.6842\n",
      "Epoch: 1720, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6807, Test Loss: 0.6841\n",
      "Epoch: 1730, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6808, Test Loss: 0.6840\n",
      "Epoch: 1740, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6810, Test Loss: 0.6840\n",
      "Epoch: 1750, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6807, Test Loss: 0.6839\n",
      "Epoch: 1760, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6804, Test Loss: 0.6838\n",
      "Epoch: 1770, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6808, Test Loss: 0.6837\n",
      "Epoch: 1780, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6805, Test Loss: 0.6837\n",
      "Epoch: 1790, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6792, Test Loss: 0.6836\n",
      "Epoch: 1800, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6800, Test Loss: 0.6835\n",
      "Epoch: 1810, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6799, Test Loss: 0.6835\n",
      "Epoch: 1820, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6797, Test Loss: 0.6834\n",
      "Epoch: 1830, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6796, Test Loss: 0.6833\n",
      "Epoch: 1840, Train Acc: 0.5970, Test Acc: 0.5400, Train Loss: 0.6798, Test Loss: 0.6832\n",
      "Epoch: 1850, Train Acc: 0.5927, Test Acc: 0.5250, Train Loss: 0.6797, Test Loss: 0.6832\n",
      "Epoch: 1860, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6801, Test Loss: 0.6831\n",
      "Epoch: 1870, Train Acc: 0.5948, Test Acc: 0.5250, Train Loss: 0.6792, Test Loss: 0.6830\n",
      "Epoch: 1880, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6795, Test Loss: 0.6829\n",
      "Epoch: 1890, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6789, Test Loss: 0.6828\n",
      "Epoch: 1900, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6794, Test Loss: 0.6828\n",
      "Epoch: 1910, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6792, Test Loss: 0.6827\n",
      "Epoch: 1920, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6782, Test Loss: 0.6826\n",
      "Epoch: 1930, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6787, Test Loss: 0.6825\n",
      "Epoch: 1940, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6774, Test Loss: 0.6825\n",
      "Epoch: 1950, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6791, Test Loss: 0.6824\n",
      "Epoch: 1960, Train Acc: 0.6013, Test Acc: 0.5300, Train Loss: 0.6780, Test Loss: 0.6823\n",
      "Epoch: 1970, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6787, Test Loss: 0.6822\n",
      "Epoch: 1980, Train Acc: 0.6056, Test Acc: 0.5300, Train Loss: 0.6787, Test Loss: 0.6821\n",
      "Epoch: 1990, Train Acc: 0.6078, Test Acc: 0.5350, Train Loss: 0.6787, Test Loss: 0.6820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▄▄▄▅▅▄▄▂▄▄▄▄█▇▇█</td></tr><tr><td>Test F1</td><td>▁▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇▇▇▆▇▇▇▆█▇▇▇</td></tr><tr><td>Test Loss</td><td>███▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▆▆▆▆▅</td></tr><tr><td>Test Specificity</td><td>█▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▄▂▃▂▃▃▃▄▆▅▅▇</td></tr><tr><td>Train Accuracy</td><td>▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▃▃▃▄▅▄▅▄▆▆▅▆▇▇▇█</td></tr><tr><td>Train F1</td><td>▁▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▅▆▆▆▇▇▇▇█</td></tr><tr><td>Train Loss</td><td>█▇▇▇▇▇▇▇▆▆▆▆▆▆▅▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Specificity</td><td>▆▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▃▃▄▅▅▅▅▅▆▆▅▆▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.535</td></tr><tr><td>Test F1</td><td>0.68041</td></tr><tr><td>Test Loss</td><td>0.68193</td></tr><tr><td>Test Sensitivity</td><td>0.96117</td></tr><tr><td>Test Specificity</td><td>0.08247</td></tr><tr><td>Train Accuracy</td><td>0.6056</td></tr><tr><td>Train F1</td><td>0.72315</td></tr><tr><td>Train Loss</td><td>0.67855</td></tr><tr><td>Train Sensitivity</td><td>0.97154</td></tr><tr><td>Train Specificity</td><td>0.19266</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-sweep-25</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/1i0akird' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/1i0akird</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_180730-1i0akird/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: px6jvbn8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.495069444419023e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.9238886278379537e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_181843-px6jvbn8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/px6jvbn8' target=\"_blank\">faithful-sweep-26</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/px6jvbn8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/px6jvbn8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6942\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6930\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6916\n",
      "Epoch: 030, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6912\n",
      "Epoch: 040, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6910\n",
      "Epoch: 050, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6878, Test Loss: 0.6905\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5250, Train Loss: 0.6869, Test Loss: 0.6901\n",
      "Epoch: 070, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6861, Test Loss: 0.6893\n",
      "Epoch: 080, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6852, Test Loss: 0.6880\n",
      "Epoch: 090, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6837, Test Loss: 0.6870\n",
      "Epoch: 100, Train Acc: 0.5754, Test Acc: 0.5250, Train Loss: 0.6817, Test Loss: 0.6850\n",
      "Epoch: 110, Train Acc: 0.5948, Test Acc: 0.5450, Train Loss: 0.6792, Test Loss: 0.6825\n",
      "Epoch: 120, Train Acc: 0.6034, Test Acc: 0.5400, Train Loss: 0.6753, Test Loss: 0.6795\n",
      "Epoch: 130, Train Acc: 0.6164, Test Acc: 0.5700, Train Loss: 0.6702, Test Loss: 0.6753\n",
      "Epoch: 140, Train Acc: 0.6616, Test Acc: 0.6100, Train Loss: 0.6644, Test Loss: 0.6704\n",
      "Epoch: 150, Train Acc: 0.6940, Test Acc: 0.6250, Train Loss: 0.6582, Test Loss: 0.6647\n",
      "Epoch: 160, Train Acc: 0.7069, Test Acc: 0.6450, Train Loss: 0.6497, Test Loss: 0.6580\n",
      "Epoch: 170, Train Acc: 0.7263, Test Acc: 0.6900, Train Loss: 0.6409, Test Loss: 0.6503\n",
      "Epoch: 180, Train Acc: 0.7284, Test Acc: 0.7000, Train Loss: 0.6313, Test Loss: 0.6422\n",
      "Epoch: 190, Train Acc: 0.7328, Test Acc: 0.7000, Train Loss: 0.6204, Test Loss: 0.6334\n",
      "Epoch: 200, Train Acc: 0.7306, Test Acc: 0.6900, Train Loss: 0.6084, Test Loss: 0.6248\n",
      "Epoch: 210, Train Acc: 0.7608, Test Acc: 0.6950, Train Loss: 0.5943, Test Loss: 0.6154\n",
      "Epoch: 220, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5828, Test Loss: 0.6076\n",
      "Epoch: 230, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5705, Test Loss: 0.5995\n",
      "Epoch: 240, Train Acc: 0.7845, Test Acc: 0.6900, Train Loss: 0.5573, Test Loss: 0.5931\n",
      "Epoch: 250, Train Acc: 0.7866, Test Acc: 0.7050, Train Loss: 0.5490, Test Loss: 0.5866\n",
      "Epoch: 260, Train Acc: 0.7716, Test Acc: 0.6800, Train Loss: 0.5399, Test Loss: 0.5808\n",
      "Epoch: 270, Train Acc: 0.7500, Test Acc: 0.6900, Train Loss: 0.5371, Test Loss: 0.5772\n",
      "Epoch: 280, Train Acc: 0.7909, Test Acc: 0.7000, Train Loss: 0.5214, Test Loss: 0.5728\n",
      "Epoch: 290, Train Acc: 0.7888, Test Acc: 0.6950, Train Loss: 0.5163, Test Loss: 0.5679\n",
      "Epoch: 300, Train Acc: 0.7888, Test Acc: 0.7050, Train Loss: 0.5074, Test Loss: 0.5650\n",
      "Epoch: 310, Train Acc: 0.7931, Test Acc: 0.7150, Train Loss: 0.5025, Test Loss: 0.5640\n",
      "Epoch: 320, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4951, Test Loss: 0.5611\n",
      "Epoch: 330, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4912, Test Loss: 0.5606\n",
      "Epoch: 340, Train Acc: 0.7931, Test Acc: 0.7100, Train Loss: 0.4880, Test Loss: 0.5543\n",
      "Epoch: 350, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4783, Test Loss: 0.5534\n",
      "Epoch: 360, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4823, Test Loss: 0.5495\n",
      "Epoch: 370, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4748, Test Loss: 0.5518\n",
      "Epoch: 380, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4709, Test Loss: 0.5497\n",
      "Epoch: 390, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4686, Test Loss: 0.5433\n",
      "Epoch: 400, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4648, Test Loss: 0.5441\n",
      "Epoch: 410, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4604, Test Loss: 0.5434\n",
      "Epoch: 420, Train Acc: 0.8039, Test Acc: 0.7350, Train Loss: 0.4633, Test Loss: 0.5384\n",
      "Epoch: 430, Train Acc: 0.8017, Test Acc: 0.7450, Train Loss: 0.4540, Test Loss: 0.5414\n",
      "Epoch: 440, Train Acc: 0.8017, Test Acc: 0.7450, Train Loss: 0.4491, Test Loss: 0.5398\n",
      "Epoch: 450, Train Acc: 0.8017, Test Acc: 0.7450, Train Loss: 0.4509, Test Loss: 0.5433\n",
      "Epoch: 460, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4442, Test Loss: 0.5367\n",
      "Epoch: 470, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4568, Test Loss: 0.5322\n",
      "Epoch: 480, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4381, Test Loss: 0.5366\n",
      "Epoch: 490, Train Acc: 0.8017, Test Acc: 0.7500, Train Loss: 0.4406, Test Loss: 0.5390\n",
      "Epoch: 500, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4348, Test Loss: 0.5285\n",
      "Epoch: 510, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4312, Test Loss: 0.5307\n",
      "Epoch: 520, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4283, Test Loss: 0.5314\n",
      "Epoch: 530, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4303, Test Loss: 0.5294\n",
      "Epoch: 540, Train Acc: 0.8039, Test Acc: 0.7200, Train Loss: 0.4375, Test Loss: 0.5513\n",
      "Epoch: 550, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4268, Test Loss: 0.5231\n",
      "Epoch: 560, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4256, Test Loss: 0.5325\n",
      "Epoch: 570, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.4266, Test Loss: 0.5208\n",
      "Epoch: 580, Train Acc: 0.8168, Test Acc: 0.7750, Train Loss: 0.4212, Test Loss: 0.5205\n",
      "Epoch: 590, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4191, Test Loss: 0.5214\n",
      "Epoch: 600, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.4213, Test Loss: 0.5211\n",
      "Epoch: 610, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4235, Test Loss: 0.5178\n",
      "Epoch: 620, Train Acc: 0.8125, Test Acc: 0.7700, Train Loss: 0.4133, Test Loss: 0.5203\n",
      "Epoch: 630, Train Acc: 0.8147, Test Acc: 0.7650, Train Loss: 0.4124, Test Loss: 0.5217\n",
      "Epoch: 640, Train Acc: 0.8190, Test Acc: 0.7700, Train Loss: 0.4102, Test Loss: 0.5170\n",
      "Epoch: 650, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4031, Test Loss: 0.5220\n",
      "Epoch: 660, Train Acc: 0.8168, Test Acc: 0.7650, Train Loss: 0.4056, Test Loss: 0.5206\n",
      "Epoch: 670, Train Acc: 0.8190, Test Acc: 0.7700, Train Loss: 0.4059, Test Loss: 0.5213\n",
      "Epoch: 680, Train Acc: 0.8297, Test Acc: 0.7750, Train Loss: 0.4102, Test Loss: 0.5145\n",
      "Epoch: 690, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.3987, Test Loss: 0.5203\n",
      "Epoch: 700, Train Acc: 0.8233, Test Acc: 0.7650, Train Loss: 0.4062, Test Loss: 0.5335\n",
      "Epoch: 710, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.4000, Test Loss: 0.5240\n",
      "Epoch: 720, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4215, Test Loss: 0.5565\n",
      "Epoch: 730, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4030, Test Loss: 0.5377\n",
      "Epoch: 740, Train Acc: 0.8341, Test Acc: 0.7800, Train Loss: 0.4001, Test Loss: 0.5137\n",
      "Epoch: 750, Train Acc: 0.8233, Test Acc: 0.7700, Train Loss: 0.3909, Test Loss: 0.5219\n",
      "Epoch: 760, Train Acc: 0.8297, Test Acc: 0.7800, Train Loss: 0.3949, Test Loss: 0.5160\n",
      "Epoch: 770, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.3917, Test Loss: 0.5180\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▂▄▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇</td></tr><tr><td>Test F1</td><td>▄▄▄▄▄▄▄▄▅▄▁▄▄▃▅▄▅▆▅▅▅▆▅▇▆▇▇▆▇▇▇██▇███▇█▇</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▇▆▅▄▁▃▃▃▄▃▄▄▃▃▄▄▃▅▄▅▅▄▅▅▅▅▅▆▅▅▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▂▄▅▆█▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇▇▇▇▇▇██▇█▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▄▅▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇██████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▂▂▃▄▄▁▅▆▅▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>███████▇▇▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>████▇▇▆▅▅▄▁▃▄▃▄▄▄▅▄▄▄▄▄▅▄▄▅▄▅▅▄▅▄▅▄▄▄▅▄▅</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▃▅▆▇█▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█▇█▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.76</td></tr><tr><td>Test F1</td><td>0.77358</td></tr><tr><td>Test Loss</td><td>0.52456</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.72165</td></tr><tr><td>Train Accuracy</td><td>0.82112</td></tr><tr><td>Train F1</td><td>0.82816</td></tr><tr><td>Train Loss</td><td>0.38826</td></tr><tr><td>Train Sensitivity</td><td>0.81301</td></tr><tr><td>Train Specificity</td><td>0.83028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-26</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/px6jvbn8' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/px6jvbn8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_181843-px6jvbn8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7rtsv86w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001717851870655918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.90074249079059e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_182158-7rtsv86w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/7rtsv86w' target=\"_blank\">hardy-sweep-27</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7rtsv86w' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7rtsv86w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6923, Test Loss: 0.6927\n",
      "Epoch: 010, Train Acc: 0.5194, Test Acc: 0.4950, Train Loss: 0.6911, Test Loss: 0.6914\n",
      "Epoch: 020, Train Acc: 0.5474, Test Acc: 0.5400, Train Loss: 0.6873, Test Loss: 0.6876\n",
      "Epoch: 030, Train Acc: 0.5797, Test Acc: 0.5600, Train Loss: 0.6779, Test Loss: 0.6795\n",
      "Epoch: 040, Train Acc: 0.6681, Test Acc: 0.6350, Train Loss: 0.6614, Test Loss: 0.6663\n",
      "Epoch: 050, Train Acc: 0.7263, Test Acc: 0.6800, Train Loss: 0.6339, Test Loss: 0.6434\n",
      "Epoch: 060, Train Acc: 0.6250, Test Acc: 0.6250, Train Loss: 0.6223, Test Loss: 0.6316\n",
      "Epoch: 070, Train Acc: 0.7586, Test Acc: 0.7050, Train Loss: 0.5587, Test Loss: 0.5903\n",
      "Epoch: 080, Train Acc: 0.7823, Test Acc: 0.7050, Train Loss: 0.5294, Test Loss: 0.5736\n",
      "Epoch: 090, Train Acc: 0.7047, Test Acc: 0.6700, Train Loss: 0.5539, Test Loss: 0.5945\n",
      "Epoch: 100, Train Acc: 0.7155, Test Acc: 0.6750, Train Loss: 0.5512, Test Loss: 0.5955\n",
      "Epoch: 110, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.4850, Test Loss: 0.5491\n",
      "Epoch: 120, Train Acc: 0.7241, Test Acc: 0.6950, Train Loss: 0.5492, Test Loss: 0.6036\n",
      "Epoch: 130, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.4856, Test Loss: 0.5524\n",
      "Epoch: 140, Train Acc: 0.7371, Test Acc: 0.7050, Train Loss: 0.5377, Test Loss: 0.6009\n",
      "Epoch: 150, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4638, Test Loss: 0.5409\n",
      "Epoch: 160, Train Acc: 0.7608, Test Acc: 0.7150, Train Loss: 0.5104, Test Loss: 0.5758\n",
      "Epoch: 170, Train Acc: 0.7931, Test Acc: 0.7200, Train Loss: 0.4655, Test Loss: 0.5451\n",
      "Epoch: 180, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4440, Test Loss: 0.5283\n",
      "Epoch: 190, Train Acc: 0.8190, Test Acc: 0.7700, Train Loss: 0.4148, Test Loss: 0.5230\n",
      "Epoch: 200, Train Acc: 0.8254, Test Acc: 0.7400, Train Loss: 0.4251, Test Loss: 0.5235\n",
      "Epoch: 210, Train Acc: 0.7069, Test Acc: 0.7050, Train Loss: 0.6098, Test Loss: 0.6703\n",
      "Epoch: 220, Train Acc: 0.8470, Test Acc: 0.7600, Train Loss: 0.4057, Test Loss: 0.5192\n",
      "Epoch: 230, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.3910, Test Loss: 0.5152\n",
      "Epoch: 240, Train Acc: 0.8448, Test Acc: 0.7700, Train Loss: 0.3908, Test Loss: 0.5212\n",
      "Epoch: 250, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.3826, Test Loss: 0.5314\n",
      "Epoch: 260, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3774, Test Loss: 0.5267\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▁▅▄▅▄▅▆▇▅▅▅▆▆▆▆▅▇▆▆▇▇▇▆▇▇██▇▇▇█▇▆▇▇</td></tr><tr><td>Test F1</td><td>▁▆▅▆▇▇▆▅▅▅▆▇█▆▆▆▇▆▆▆▆▇▇▇▇▇▇▆▇▇██▇▇▇█▇▇▇▇</td></tr><tr><td>Test Loss</td><td>█████▇▇▆▆▆▄▄▄▃▄▃▂▃▄▅▇▂▃▃▂▂▂▇▃▅▁▁▂▁▂▁▂▆▁▃</td></tr><tr><td>Test Sensitivity</td><td>▁▅▃▅▇█▄▄▃▃▄▆▇▄▄▄▅▅▄▄▄▅▅▅▅▅▅▄▅▅▆▇▅▅▅▆▅▄▅▅</td></tr><tr><td>Test Specificity</td><td>█▄▆▄▂▁▇▇██▇▇▅▇▇▇▇▇▇██▇▇▇▇▇▇█▇█▆▆▇▇▇▇▇█▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▃▃▄▅▄▄▅▇▇▆▆▆▇▆▆▆▅▇▆▇▇▇▇▅▇▆██▇█▇██▆█▇</td></tr><tr><td>Train F1</td><td>▁▆▅▆▇▇▆▆▅▅▆▇█▇▇▇▇▇▇▆▆▇▇▇█▇█▆▇▇██▇████▇█▇</td></tr><tr><td>Train Loss</td><td>█████▇▇▇▇▆▅▄▄▄▄▄▃▄▄▅▆▃▄▃▂▃▂▆▃▅▁▁▂▂▂▁▂▅▁▃</td></tr><tr><td>Train Sensitivity</td><td>▁▅▄▅▇█▄▄▄▃▅▆▇▅▅▅▆▅▅▅▄▆▅▅▆▆▆▄▅▅▇▇▆▆▆▇▆▅▆▆</td></tr><tr><td>Train Specificity</td><td>█▄▆▄▃▁▇▇██▇▇▆▇▇▇▇▇███▇██▇█████▇▇███▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.78</td></tr><tr><td>Test F1</td><td>0.77083</td></tr><tr><td>Test Loss</td><td>0.51639</td></tr><tr><td>Test Sensitivity</td><td>0.71845</td></tr><tr><td>Test Specificity</td><td>0.84536</td></tr><tr><td>Train Accuracy</td><td>0.85345</td></tr><tr><td>Train F1</td><td>0.85088</td></tr><tr><td>Train Loss</td><td>0.38363</td></tr><tr><td>Train Sensitivity</td><td>0.78862</td></tr><tr><td>Train Specificity</td><td>0.92661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-27</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7rtsv86w' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7rtsv86w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_182158-7rtsv86w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w8k641gk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.94425525691874e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.151639553218368e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_182345-w8k641gk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/w8k641gk' target=\"_blank\">misunderstood-sweep-28</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/w8k641gk' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/w8k641gk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6939, Test Loss: 0.6935\n",
      "Epoch: 010, Train Acc: 0.5086, Test Acc: 0.5000, Train Loss: 0.6928, Test Loss: 0.6927\n",
      "Epoch: 020, Train Acc: 0.5345, Test Acc: 0.5100, Train Loss: 0.6914, Test Loss: 0.6917\n",
      "Epoch: 030, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6917\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6917\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6917\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6917\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6917\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▅▇█▆▃▂▇▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test F1</td><td>▁▁▁▂▅▇▇▇▇███████████████████████████████</td></tr><tr><td>Test Loss</td><td>███▇▆▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▃▅▆▆▇███████████████████████████████</td></tr><tr><td>Test Specificity</td><td>████▆▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▆▆▅▅▇███▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train F1</td><td>▁▁▁▁▅▇▇▇████████████████████████████████</td></tr><tr><td>Train Loss</td><td>███▇▇▆▆▅▅▄▄▄▃▂▂▂▂▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▂▁▂▂▂▁▃▂</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▃▅▆▆▇███████████████████████████████</td></tr><tr><td>Train Specificity</td><td>████▆▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69172</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.52802</td></tr><tr><td>Train F1</td><td>0.69111</td></tr><tr><td>Train Loss</td><td>0.69032</td></tr><tr><td>Train Sensitivity</td><td>0.99593</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-28</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/w8k641gk' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/w8k641gk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_182345-w8k641gk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iuk8wy0e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.183818552887422e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00016643427565978672\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_182421-iuk8wy0e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/iuk8wy0e' target=\"_blank\">fresh-sweep-29</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/iuk8wy0e' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/iuk8wy0e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6935\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6929\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6924\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6914\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6917\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6887, Test Loss: 0.6908\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6910\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6902\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6900\n",
      "Epoch: 090, Train Acc: 0.5409, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6892\n",
      "Epoch: 100, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6857, Test Loss: 0.6888\n",
      "Epoch: 110, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6850, Test Loss: 0.6881\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6850, Test Loss: 0.6879\n",
      "Epoch: 130, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6835, Test Loss: 0.6869\n",
      "Epoch: 140, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6859\n",
      "Epoch: 150, Train Acc: 0.5474, Test Acc: 0.5100, Train Loss: 0.6807, Test Loss: 0.6854\n",
      "Epoch: 160, Train Acc: 0.5733, Test Acc: 0.5150, Train Loss: 0.6791, Test Loss: 0.6841\n",
      "Epoch: 170, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6775, Test Loss: 0.6828\n",
      "Epoch: 180, Train Acc: 0.5690, Test Acc: 0.5100, Train Loss: 0.6760, Test Loss: 0.6818\n",
      "Epoch: 190, Train Acc: 0.5948, Test Acc: 0.5250, Train Loss: 0.6744, Test Loss: 0.6800\n",
      "Epoch: 200, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6724, Test Loss: 0.6781\n",
      "Epoch: 210, Train Acc: 0.6078, Test Acc: 0.5450, Train Loss: 0.6696, Test Loss: 0.6761\n",
      "Epoch: 220, Train Acc: 0.6444, Test Acc: 0.5900, Train Loss: 0.6661, Test Loss: 0.6733\n",
      "Epoch: 230, Train Acc: 0.6573, Test Acc: 0.5750, Train Loss: 0.6635, Test Loss: 0.6708\n",
      "Epoch: 240, Train Acc: 0.6746, Test Acc: 0.6150, Train Loss: 0.6590, Test Loss: 0.6675\n",
      "Epoch: 250, Train Acc: 0.6875, Test Acc: 0.6050, Train Loss: 0.6539, Test Loss: 0.6642\n",
      "Epoch: 260, Train Acc: 0.7069, Test Acc: 0.6450, Train Loss: 0.6490, Test Loss: 0.6602\n",
      "Epoch: 270, Train Acc: 0.7220, Test Acc: 0.6650, Train Loss: 0.6449, Test Loss: 0.6560\n",
      "Epoch: 280, Train Acc: 0.7349, Test Acc: 0.6700, Train Loss: 0.6388, Test Loss: 0.6515\n",
      "Epoch: 290, Train Acc: 0.7328, Test Acc: 0.6850, Train Loss: 0.6324, Test Loss: 0.6468\n",
      "Epoch: 300, Train Acc: 0.7478, Test Acc: 0.6950, Train Loss: 0.6267, Test Loss: 0.6420\n",
      "Epoch: 310, Train Acc: 0.7478, Test Acc: 0.7000, Train Loss: 0.6187, Test Loss: 0.6369\n",
      "Epoch: 320, Train Acc: 0.7457, Test Acc: 0.6950, Train Loss: 0.6126, Test Loss: 0.6318\n",
      "Epoch: 330, Train Acc: 0.7392, Test Acc: 0.6750, Train Loss: 0.6055, Test Loss: 0.6266\n",
      "Epoch: 340, Train Acc: 0.7435, Test Acc: 0.6600, Train Loss: 0.5992, Test Loss: 0.6220\n",
      "Epoch: 350, Train Acc: 0.7565, Test Acc: 0.6800, Train Loss: 0.5905, Test Loss: 0.6169\n",
      "Epoch: 360, Train Acc: 0.7522, Test Acc: 0.6850, Train Loss: 0.5851, Test Loss: 0.6122\n",
      "Epoch: 370, Train Acc: 0.7543, Test Acc: 0.6750, Train Loss: 0.5781, Test Loss: 0.6080\n",
      "Epoch: 380, Train Acc: 0.7694, Test Acc: 0.6650, Train Loss: 0.5692, Test Loss: 0.6035\n",
      "Epoch: 390, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5622, Test Loss: 0.5996\n",
      "Epoch: 400, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5576, Test Loss: 0.5963\n",
      "Epoch: 410, Train Acc: 0.7737, Test Acc: 0.6700, Train Loss: 0.5527, Test Loss: 0.5925\n",
      "Epoch: 420, Train Acc: 0.7780, Test Acc: 0.6850, Train Loss: 0.5456, Test Loss: 0.5895\n",
      "Epoch: 430, Train Acc: 0.7780, Test Acc: 0.6800, Train Loss: 0.5413, Test Loss: 0.5864\n",
      "Epoch: 440, Train Acc: 0.7780, Test Acc: 0.6800, Train Loss: 0.5343, Test Loss: 0.5836\n",
      "Epoch: 450, Train Acc: 0.7780, Test Acc: 0.6700, Train Loss: 0.5328, Test Loss: 0.5812\n",
      "Epoch: 460, Train Acc: 0.7823, Test Acc: 0.6800, Train Loss: 0.5253, Test Loss: 0.5787\n",
      "Epoch: 470, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.5230, Test Loss: 0.5769\n",
      "Epoch: 480, Train Acc: 0.7888, Test Acc: 0.6850, Train Loss: 0.5181, Test Loss: 0.5747\n",
      "Epoch: 490, Train Acc: 0.7866, Test Acc: 0.6900, Train Loss: 0.5134, Test Loss: 0.5728\n",
      "Epoch: 500, Train Acc: 0.7931, Test Acc: 0.6900, Train Loss: 0.5123, Test Loss: 0.5716\n",
      "Epoch: 510, Train Acc: 0.7866, Test Acc: 0.6900, Train Loss: 0.5056, Test Loss: 0.5694\n",
      "Epoch: 520, Train Acc: 0.7931, Test Acc: 0.6950, Train Loss: 0.4993, Test Loss: 0.5683\n",
      "Epoch: 530, Train Acc: 0.7888, Test Acc: 0.6950, Train Loss: 0.4964, Test Loss: 0.5667\n",
      "Epoch: 540, Train Acc: 0.7996, Test Acc: 0.6950, Train Loss: 0.4960, Test Loss: 0.5656\n",
      "Epoch: 550, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.4952, Test Loss: 0.5640\n",
      "Epoch: 560, Train Acc: 0.7931, Test Acc: 0.7050, Train Loss: 0.4951, Test Loss: 0.5627\n",
      "Epoch: 570, Train Acc: 0.7953, Test Acc: 0.7050, Train Loss: 0.4907, Test Loss: 0.5613\n",
      "Epoch: 580, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.4904, Test Loss: 0.5604\n",
      "Epoch: 590, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.4853, Test Loss: 0.5595\n",
      "Epoch: 600, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4807, Test Loss: 0.5585\n",
      "Epoch: 610, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4774, Test Loss: 0.5587\n",
      "Epoch: 620, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4775, Test Loss: 0.5577\n",
      "Epoch: 630, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4761, Test Loss: 0.5567\n",
      "Epoch: 640, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4732, Test Loss: 0.5545\n",
      "Epoch: 650, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4708, Test Loss: 0.5535\n",
      "Epoch: 660, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4680, Test Loss: 0.5543\n",
      "Epoch: 670, Train Acc: 0.8103, Test Acc: 0.7100, Train Loss: 0.4677, Test Loss: 0.5535\n",
      "Epoch: 680, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4649, Test Loss: 0.5515\n",
      "Epoch: 690, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4670, Test Loss: 0.5507\n",
      "Epoch: 700, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4621, Test Loss: 0.5535\n",
      "Epoch: 710, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4602, Test Loss: 0.5526\n",
      "Epoch: 720, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4617, Test Loss: 0.5492\n",
      "Epoch: 730, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4555, Test Loss: 0.5497\n",
      "Epoch: 740, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4561, Test Loss: 0.5494\n",
      "Epoch: 750, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4519, Test Loss: 0.5476\n",
      "Epoch: 760, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4577, Test Loss: 0.5488\n",
      "Epoch: 770, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4549, Test Loss: 0.5446\n",
      "Epoch: 780, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4496, Test Loss: 0.5467\n",
      "Epoch: 790, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4482, Test Loss: 0.5481\n",
      "Epoch: 800, Train Acc: 0.8082, Test Acc: 0.7250, Train Loss: 0.4505, Test Loss: 0.5490\n",
      "Epoch: 810, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4463, Test Loss: 0.5442\n",
      "Epoch: 820, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4468, Test Loss: 0.5416\n",
      "Epoch: 830, Train Acc: 0.8082, Test Acc: 0.7450, Train Loss: 0.4448, Test Loss: 0.5486\n",
      "Epoch: 840, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4425, Test Loss: 0.5426\n",
      "Epoch: 850, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4426, Test Loss: 0.5436\n",
      "Epoch: 860, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4415, Test Loss: 0.5392\n",
      "Epoch: 870, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4382, Test Loss: 0.5426\n",
      "Epoch: 880, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4379, Test Loss: 0.5403\n",
      "Epoch: 890, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4386, Test Loss: 0.5382\n",
      "Epoch: 900, Train Acc: 0.8168, Test Acc: 0.7350, Train Loss: 0.4355, Test Loss: 0.5395\n",
      "Epoch: 910, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4350, Test Loss: 0.5403\n",
      "Epoch: 920, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4324, Test Loss: 0.5422\n",
      "Epoch: 930, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4300, Test Loss: 0.5407\n",
      "Epoch: 940, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4335, Test Loss: 0.5429\n",
      "Epoch: 950, Train Acc: 0.8125, Test Acc: 0.7600, Train Loss: 0.4318, Test Loss: 0.5399\n",
      "Epoch: 960, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4291, Test Loss: 0.5349\n",
      "Epoch: 970, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.4300, Test Loss: 0.5361\n",
      "Epoch: 980, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4274, Test Loss: 0.5334\n",
      "Epoch: 990, Train Acc: 0.8254, Test Acc: 0.7400, Train Loss: 0.4248, Test Loss: 0.5322\n",
      "Epoch: 1000, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4240, Test Loss: 0.5322\n",
      "Epoch: 1010, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4292, Test Loss: 0.5338\n",
      "Epoch: 1020, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4234, Test Loss: 0.5331\n",
      "Epoch: 1030, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4220, Test Loss: 0.5321\n",
      "Epoch: 1040, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4210, Test Loss: 0.5322\n",
      "Epoch: 1050, Train Acc: 0.8233, Test Acc: 0.7450, Train Loss: 0.4182, Test Loss: 0.5321\n",
      "Epoch: 1060, Train Acc: 0.8211, Test Acc: 0.7600, Train Loss: 0.4212, Test Loss: 0.5336\n",
      "Epoch: 1070, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4227, Test Loss: 0.5292\n",
      "Epoch: 1080, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4214, Test Loss: 0.5294\n",
      "Epoch: 1090, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4174, Test Loss: 0.5292\n",
      "Epoch: 1100, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4200, Test Loss: 0.5286\n",
      "Epoch: 1110, Train Acc: 0.8233, Test Acc: 0.7650, Train Loss: 0.4188, Test Loss: 0.5349\n",
      "Epoch: 1120, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4178, Test Loss: 0.5276\n",
      "Epoch: 1130, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4160, Test Loss: 0.5272\n",
      "Epoch: 1140, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4145, Test Loss: 0.5276\n",
      "Epoch: 1150, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4152, Test Loss: 0.5263\n",
      "Epoch: 1160, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4156, Test Loss: 0.5265\n",
      "Epoch: 1170, Train Acc: 0.8319, Test Acc: 0.7500, Train Loss: 0.4136, Test Loss: 0.5279\n",
      "Epoch: 1180, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4080, Test Loss: 0.5299\n",
      "Epoch: 1190, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4068, Test Loss: 0.5288\n",
      "Epoch: 1200, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4110, Test Loss: 0.5276\n",
      "Epoch: 1210, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4123, Test Loss: 0.5261\n",
      "Epoch: 1220, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4015, Test Loss: 0.5272\n",
      "Epoch: 1230, Train Acc: 0.8362, Test Acc: 0.7550, Train Loss: 0.4084, Test Loss: 0.5269\n",
      "Epoch: 1240, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4034, Test Loss: 0.5335\n",
      "Epoch: 1250, Train Acc: 0.8427, Test Acc: 0.7550, Train Loss: 0.4108, Test Loss: 0.5263\n",
      "Epoch: 1260, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4017, Test Loss: 0.5289\n",
      "Epoch: 1270, Train Acc: 0.8384, Test Acc: 0.7550, Train Loss: 0.4016, Test Loss: 0.5268\n",
      "Epoch: 1280, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4034, Test Loss: 0.5248\n",
      "Epoch: 1290, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.3989, Test Loss: 0.5290\n",
      "Epoch: 1300, Train Acc: 0.8384, Test Acc: 0.7650, Train Loss: 0.4030, Test Loss: 0.5249\n",
      "Epoch: 1310, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.3989, Test Loss: 0.5274\n",
      "Epoch: 1320, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.3953, Test Loss: 0.5277\n",
      "Epoch: 1330, Train Acc: 0.8384, Test Acc: 0.7650, Train Loss: 0.3953, Test Loss: 0.5268\n",
      "Epoch: 1340, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.3972, Test Loss: 0.5302\n",
      "Epoch: 1350, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.3985, Test Loss: 0.5274\n",
      "Epoch: 1360, Train Acc: 0.8362, Test Acc: 0.7700, Train Loss: 0.3974, Test Loss: 0.5274\n",
      "Epoch: 1370, Train Acc: 0.8427, Test Acc: 0.7700, Train Loss: 0.3966, Test Loss: 0.5275\n",
      "Epoch: 1380, Train Acc: 0.8427, Test Acc: 0.7750, Train Loss: 0.3966, Test Loss: 0.5245\n",
      "Epoch: 1390, Train Acc: 0.8448, Test Acc: 0.7650, Train Loss: 0.3960, Test Loss: 0.5247\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▃▅▅▆▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇████▇█████</td></tr><tr><td>Test F1</td><td>▃▃▃▂▂▂▂▄▃▂▁▂▁▃▃▃▅▄▄▅▅▆▅▆▆▆▇▇▇▇▇▆██▆▇▇▇█▇</td></tr><tr><td>Test Loss</td><td>█████▇▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>█████▇▅▄▃▂▁▁▁▂▂▂▃▃▃▃▃▃▂▃▄▄▄▄▄▄▃▂▅▅▄▄▄▄▄▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▂▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▂▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>Train F1</td><td>▁▁▁▂▂▂▃▃▄▃▄▄▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▆▇▇█▇▇███</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>█████▇▅▃▃▁▁▂▂▃▂▂▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▂▄▄▃▄▃▄▄▄</td></tr><tr><td>Train Specificity</td><td>▁▁▁▂▁▂▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇███▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.78302</td></tr><tr><td>Test Loss</td><td>0.53099</td></tr><tr><td>Test Sensitivity</td><td>0.80583</td></tr><tr><td>Test Specificity</td><td>0.73196</td></tr><tr><td>Train Accuracy</td><td>0.8319</td></tr><tr><td>Train F1</td><td>0.83884</td></tr><tr><td>Train Loss</td><td>0.39266</td></tr><tr><td>Train Sensitivity</td><td>0.8252</td></tr><tr><td>Train Specificity</td><td>0.83945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-29</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/iuk8wy0e' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/iuk8wy0e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_182421-iuk8wy0e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6mg1pi68 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0016515759807859522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.5977400814417186e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_183051-6mg1pi68</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/6mg1pi68' target=\"_blank\">celestial-sweep-30</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/6mg1pi68' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/6mg1pi68</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6921, Test Loss: 0.6954\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6917\n",
      "Epoch: 020, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6876\n",
      "Epoch: 030, Train Acc: 0.5409, Test Acc: 0.5700, Train Loss: 0.6771, Test Loss: 0.6745\n",
      "Epoch: 040, Train Acc: 0.5668, Test Acc: 0.5850, Train Loss: 0.6707, Test Loss: 0.6825\n",
      "Epoch: 050, Train Acc: 0.5496, Test Acc: 0.5800, Train Loss: 1.0913, Test Loss: 1.0890\n",
      "Epoch: 060, Train Acc: 0.7004, Test Acc: 0.6950, Train Loss: 0.5851, Test Loss: 0.6374\n",
      "Epoch: 070, Train Acc: 0.6250, Test Acc: 0.6550, Train Loss: 0.7741, Test Loss: 0.7854\n",
      "Epoch: 080, Train Acc: 0.6681, Test Acc: 0.6950, Train Loss: 0.6946, Test Loss: 0.7266\n",
      "Epoch: 090, Train Acc: 0.6659, Test Acc: 0.6850, Train Loss: 0.7126, Test Loss: 0.7410\n",
      "Epoch: 100, Train Acc: 0.6659, Test Acc: 0.6900, Train Loss: 0.7292, Test Loss: 0.7515\n",
      "Epoch: 110, Train Acc: 0.8103, Test Acc: 0.7600, Train Loss: 0.4758, Test Loss: 0.5464\n",
      "Epoch: 120, Train Acc: 0.5711, Test Acc: 0.6000, Train Loss: 1.1488, Test Loss: 1.1257\n",
      "Epoch: 130, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.4328, Test Loss: 0.5387\n",
      "Epoch: 140, Train Acc: 0.6379, Test Acc: 0.6700, Train Loss: 0.8683, Test Loss: 0.8819\n",
      "Epoch: 150, Train Acc: 0.6207, Test Acc: 0.6500, Train Loss: 0.9398, Test Loss: 0.9810\n",
      "Epoch: 160, Train Acc: 0.6681, Test Acc: 0.7100, Train Loss: 0.7841, Test Loss: 0.8265\n",
      "Epoch: 170, Train Acc: 0.7500, Test Acc: 0.7250, Train Loss: 0.5481, Test Loss: 0.6693\n",
      "Epoch: 180, Train Acc: 0.6142, Test Acc: 0.6400, Train Loss: 1.0714, Test Loss: 1.1054\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▃▂▃▃▄▃▄▆▃▇▅▇▆▇▅▇▇▆▄▄▆▅▃▃▇▆▅▇▇█▇▅▆▇▇</td></tr><tr><td>Test F1</td><td>▁▇▃▃▇▃▂▄▄▅▄▅▆▄█▅▇▆▆▆▇█▆▄▄▆▅▄▇▇▆▅▇██▇▅▆█▇</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▂▂▂▂▂▃▃▂▅▁▃▂▂▂▃▁▁▃▅▅▃▃█▃▁▃▅▂▁▁▃▄▄▁▂</td></tr><tr><td>Test Sensitivity</td><td>▁█▂▂▆▂▁▂▂▃▂▃▄▂▇▃▄▄▄▃▅▇▄▃▃▄▃▂█▅▄▃▄▇▇▄▃▄▇▅</td></tr><tr><td>Test Specificity</td><td>█▁██▃████▇████▅█████▇▅██████▂▇███▅▆███▅█</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▂▂▂▃▃▄▃▃▄▃▇▄▅▅▅▄▇▇▄▃▃▅▄▂▄▇▄▃▅▇█▅▄▅█▆</td></tr><tr><td>Train F1</td><td>▁▇▂▃▆▃▂▃▄▅▄▄▅▃█▅▆▆▆▅▇█▅▃▃▆▅▃▇▇▅▄▆██▆▅▅█▆</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▃▃▂▂▄▄▃▅▂▃▃▃▃▃▂▁▃▆▆▃▄█▃▂▃▅▃▁▁▃▄▄▁▂</td></tr><tr><td>Train Sensitivity</td><td>▁█▂▂▆▂▁▂▂▃▂▃▄▂▇▃▄▄▄▃▅▇▃▂▂▄▃▂█▅▃▂▄▇▇▄▃▃▇▄</td></tr><tr><td>Train Specificity</td><td>█▁██▃█████████▆██████▆██████▃████▆▇███▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.765</td></tr><tr><td>Test F1</td><td>0.74595</td></tr><tr><td>Test Loss</td><td>0.5643</td></tr><tr><td>Test Sensitivity</td><td>0.6699</td></tr><tr><td>Test Specificity</td><td>0.86598</td></tr><tr><td>Train Accuracy</td><td>0.86422</td></tr><tr><td>Train F1</td><td>0.85969</td></tr><tr><td>Train Loss</td><td>0.37077</td></tr><tr><td>Train Sensitivity</td><td>0.78455</td></tr><tr><td>Train Specificity</td><td>0.95413</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-30</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/6mg1pi68' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/6mg1pi68</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_183051-6mg1pi68/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 60gd35op with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.220906215768976e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.869582996558572e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_183148-60gd35op</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/60gd35op' target=\"_blank\">rosy-sweep-31</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/60gd35op' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/60gd35op</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5129, Test Acc: 0.4850, Train Loss: 0.6930, Test Loss: 0.6930\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6919\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6903\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6890\n",
      "Epoch: 040, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6832, Test Loss: 0.6864\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6803, Test Loss: 0.6847\n",
      "Epoch: 060, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6772, Test Loss: 0.6814\n",
      "Epoch: 070, Train Acc: 0.5970, Test Acc: 0.5400, Train Loss: 0.6698, Test Loss: 0.6749\n",
      "Epoch: 080, Train Acc: 0.6616, Test Acc: 0.6150, Train Loss: 0.6627, Test Loss: 0.6673\n",
      "Epoch: 090, Train Acc: 0.6961, Test Acc: 0.6350, Train Loss: 0.6512, Test Loss: 0.6585\n",
      "Epoch: 100, Train Acc: 0.7155, Test Acc: 0.6800, Train Loss: 0.6381, Test Loss: 0.6470\n",
      "Epoch: 110, Train Acc: 0.7629, Test Acc: 0.7050, Train Loss: 0.6202, Test Loss: 0.6341\n",
      "Epoch: 120, Train Acc: 0.7198, Test Acc: 0.6650, Train Loss: 0.6060, Test Loss: 0.6214\n",
      "Epoch: 130, Train Acc: 0.7220, Test Acc: 0.6700, Train Loss: 0.5896, Test Loss: 0.6086\n",
      "Epoch: 140, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5656, Test Loss: 0.5955\n",
      "Epoch: 150, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5499, Test Loss: 0.5881\n",
      "Epoch: 160, Train Acc: 0.7241, Test Acc: 0.6550, Train Loss: 0.5526, Test Loss: 0.5860\n",
      "Epoch: 170, Train Acc: 0.7198, Test Acc: 0.6550, Train Loss: 0.5448, Test Loss: 0.5829\n",
      "Epoch: 180, Train Acc: 0.7845, Test Acc: 0.7250, Train Loss: 0.5109, Test Loss: 0.5674\n",
      "Epoch: 190, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.5073, Test Loss: 0.5653\n",
      "Epoch: 200, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.4998, Test Loss: 0.5597\n",
      "Epoch: 210, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.5044, Test Loss: 0.5622\n",
      "Epoch: 220, Train Acc: 0.8017, Test Acc: 0.7400, Train Loss: 0.4853, Test Loss: 0.5559\n",
      "Epoch: 230, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.4797, Test Loss: 0.5516\n",
      "Epoch: 240, Train Acc: 0.7522, Test Acc: 0.6800, Train Loss: 0.5055, Test Loss: 0.5669\n",
      "Epoch: 250, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4683, Test Loss: 0.5469\n",
      "Epoch: 260, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4617, Test Loss: 0.5447\n",
      "Epoch: 270, Train Acc: 0.8039, Test Acc: 0.7200, Train Loss: 0.4644, Test Loss: 0.5424\n",
      "Epoch: 280, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.4676, Test Loss: 0.5457\n",
      "Epoch: 290, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4557, Test Loss: 0.5400\n",
      "Epoch: 300, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4542, Test Loss: 0.5382\n",
      "Epoch: 310, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4469, Test Loss: 0.5363\n",
      "Epoch: 320, Train Acc: 0.8168, Test Acc: 0.7300, Train Loss: 0.4430, Test Loss: 0.5351\n",
      "Epoch: 330, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4452, Test Loss: 0.5333\n",
      "Epoch: 340, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4392, Test Loss: 0.5313\n",
      "Epoch: 350, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4590, Test Loss: 0.5389\n",
      "Epoch: 360, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4290, Test Loss: 0.5317\n",
      "Epoch: 370, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4584, Test Loss: 0.5410\n",
      "Epoch: 380, Train Acc: 0.8254, Test Acc: 0.7350, Train Loss: 0.4241, Test Loss: 0.5258\n",
      "Epoch: 390, Train Acc: 0.8125, Test Acc: 0.7650, Train Loss: 0.4230, Test Loss: 0.5351\n",
      "Epoch: 400, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4289, Test Loss: 0.5282\n",
      "Epoch: 410, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4715, Test Loss: 0.5539\n",
      "Epoch: 420, Train Acc: 0.8233, Test Acc: 0.7700, Train Loss: 0.4117, Test Loss: 0.5282\n",
      "Epoch: 430, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4130, Test Loss: 0.5228\n",
      "Epoch: 440, Train Acc: 0.8319, Test Acc: 0.7500, Train Loss: 0.4245, Test Loss: 0.5245\n",
      "Epoch: 450, Train Acc: 0.8362, Test Acc: 0.7600, Train Loss: 0.4119, Test Loss: 0.5202\n",
      "Epoch: 460, Train Acc: 0.8362, Test Acc: 0.7650, Train Loss: 0.4076, Test Loss: 0.5192\n",
      "Epoch: 470, Train Acc: 0.8384, Test Acc: 0.7600, Train Loss: 0.4110, Test Loss: 0.5222\n",
      "Epoch: 480, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4084, Test Loss: 0.5206\n",
      "Epoch: 490, Train Acc: 0.8384, Test Acc: 0.7750, Train Loss: 0.4043, Test Loss: 0.5179\n",
      "Epoch: 500, Train Acc: 0.8297, Test Acc: 0.7750, Train Loss: 0.3923, Test Loss: 0.5253\n",
      "Epoch: 510, Train Acc: 0.8147, Test Acc: 0.7250, Train Loss: 0.4076, Test Loss: 0.5552\n",
      "Epoch: 520, Train Acc: 0.8427, Test Acc: 0.7650, Train Loss: 0.3973, Test Loss: 0.5191\n",
      "Epoch: 530, Train Acc: 0.8405, Test Acc: 0.7650, Train Loss: 0.3877, Test Loss: 0.5180\n",
      "Epoch: 540, Train Acc: 0.8297, Test Acc: 0.7800, Train Loss: 0.3848, Test Loss: 0.5287\n",
      "Epoch: 550, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4215, Test Loss: 0.5298\n",
      "Epoch: 560, Train Acc: 0.8190, Test Acc: 0.7150, Train Loss: 0.3975, Test Loss: 0.5622\n",
      "Epoch: 570, Train Acc: 0.8491, Test Acc: 0.7800, Train Loss: 0.3886, Test Loss: 0.5160\n",
      "Epoch: 580, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4036, Test Loss: 0.5261\n",
      "Epoch: 590, Train Acc: 0.8319, Test Acc: 0.7700, Train Loss: 0.3750, Test Loss: 0.5355\n",
      "Epoch: 600, Train Acc: 0.8448, Test Acc: 0.7650, Train Loss: 0.3894, Test Loss: 0.5201\n",
      "Epoch: 610, Train Acc: 0.8470, Test Acc: 0.7900, Train Loss: 0.3764, Test Loss: 0.5174\n",
      "Epoch: 620, Train Acc: 0.8448, Test Acc: 0.7900, Train Loss: 0.3657, Test Loss: 0.5261\n",
      "Epoch: 630, Train Acc: 0.8491, Test Acc: 0.7850, Train Loss: 0.3624, Test Loss: 0.5231\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▂▅▅▅▆▆▆▅▆▆▇▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Test F1</td><td>▄▁▄▃▃▃▃▁▃▅▆▂▃▄▅▃▄▂▅▃▅▅▆▅▇▇▄▅▆▆▇▆▆▇▅██▇▇█</td></tr><tr><td>Test Loss</td><td>████▇▇▆▅▄▄▃▃▃▂▂▂▂▃▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>█▅█▇▇▃▃▁▂▄▅▁▂▃▄▂▃▂▄▂▃▃▄▃▅▅▃▃▄▄▅▄▃▄▃▅▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>▁▂▁▂▃▆▇██▆▆██▇▇█▇█▇███▇█▇▇███▇▇████▇▇██▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▃▄▅▅▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇███████▇█████</td></tr><tr><td>Train F1</td><td>▂▁▂▃▃▃▃▁▄▆▆▃▅▆▆▅▆▄▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆█████</td></tr><tr><td>Train Loss</td><td>█████▇▇▆▆▅▅▄▄▄▃▃▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>█▅█▇▆▃▃▁▃▅▅▂▃▄▄▃▄▂▅▃▄▄▅▄▅▅▄▄▅▅▅▅▄▄▄▅▅▅▅▅</td></tr><tr><td>Train Specificity</td><td>▁▃▁▃▃▆▇▇▇▇▇█▇▇▇█▇█▇█▇█▇█▇▇███▇█████▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.75532</td></tr><tr><td>Test Loss</td><td>0.52138</td></tr><tr><td>Test Sensitivity</td><td>0.68932</td></tr><tr><td>Test Specificity</td><td>0.85567</td></tr><tr><td>Train Accuracy</td><td>0.84914</td></tr><tr><td>Train F1</td><td>0.84444</td></tr><tr><td>Train Loss</td><td>0.38076</td></tr><tr><td>Train Sensitivity</td><td>0.77236</td></tr><tr><td>Train Specificity</td><td>0.93578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-31</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/60gd35op' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/60gd35op</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_183148-60gd35op/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 75guh4fw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002334568728189586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001064107755697636\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_183554-75guh4fw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/75guh4fw' target=\"_blank\">solar-sweep-32</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/75guh4fw' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/75guh4fw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6940\n",
      "Epoch: 010, Train Acc: 0.4784, Test Acc: 0.5000, Train Loss: 0.6936, Test Loss: 0.6927\n",
      "Epoch: 020, Train Acc: 0.4806, Test Acc: 0.5000, Train Loss: 0.7014, Test Loss: 0.6971\n",
      "Epoch: 030, Train Acc: 0.5431, Test Acc: 0.5650, Train Loss: 0.8870, Test Loss: 0.8851\n",
      "Epoch: 040, Train Acc: 0.6164, Test Acc: 0.6200, Train Loss: 0.8328, Test Loss: 0.8517\n",
      "Epoch: 050, Train Acc: 0.5927, Test Acc: 0.6250, Train Loss: 0.9291, Test Loss: 0.9132\n",
      "Epoch: 060, Train Acc: 0.6789, Test Acc: 0.6950, Train Loss: 0.6636, Test Loss: 0.6880\n",
      "Epoch: 070, Train Acc: 0.7780, Test Acc: 0.7350, Train Loss: 0.4950, Test Loss: 0.5564\n",
      "Epoch: 080, Train Acc: 0.5431, Test Acc: 0.5850, Train Loss: 1.2864, Test Loss: 1.2353\n",
      "Epoch: 090, Train Acc: 0.8211, Test Acc: 0.7750, Train Loss: 0.4354, Test Loss: 0.5108\n",
      "Epoch: 100, Train Acc: 0.7888, Test Acc: 0.7300, Train Loss: 0.5005, Test Loss: 0.5651\n",
      "Epoch: 110, Train Acc: 0.8254, Test Acc: 0.7800, Train Loss: 0.4263, Test Loss: 0.5251\n",
      "Epoch: 120, Train Acc: 0.8470, Test Acc: 0.8050, Train Loss: 0.3999, Test Loss: 0.5106\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▁▁▁▁▂▃▃▄▄▄▅▆▄▆▆▆▇▆▆█▅█▃▅▇▆▇▅▇▇▇█▆▇▆▇</td></tr><tr><td>Test F1</td><td>▇▇▇▂▆▂▁▁▂▄▄▅▄▅▆▇▄▇▇▇▇▇▇█▅█▄▆▇▆▇▆▇▇▇█▇▇█▇</td></tr><tr><td>Test Loss</td><td>▃▃▃▃▃▃▃▃▃▃▄▃▆▄▄▂▅▂▂▂▂▂▂▁▄▁█▃▂▃▂▄▂▁▂▁▂▂▁▂</td></tr><tr><td>Test Sensitivity</td><td>███▂▆▁▁▁▁▂▂▃▃▃▃▄▃▄▅▄▅▄▅▆▃▆▂▄▅▄▅▄▅▅▅▆▅▅▇▅</td></tr><tr><td>Test Specificity</td><td>▁▁▁█▃██████████▇██▇█▇██▇█▇██▇█▇█▇▇█▇▇▇▅▇</td></tr><tr><td>Train Accuracy</td><td>▂▂▂▁▂▁▁▁▂▃▃▄▃▄▄▆▃▆▇▆▆▆▆█▄█▂▅▇▅▇▅▇█▆█▆▆█▇</td></tr><tr><td>Train F1</td><td>▇▇▇▂▆▂▁▁▂▄▃▅▄▅▅▇▄▇▇▆▇▇▇█▅█▃▆▇▅▇▆▇█▇█▇▇█▇</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▃▃▄▃▅▄▆▄▄▂▆▂▂▂▂▂▂▁▅▁█▄▂▄▂▄▂▂▂▁▂▂▁▂</td></tr><tr><td>Train Sensitivity</td><td>███▁▆▁▁▁▁▂▂▃▂▃▃▅▂▅▅▄▅▅▅▇▃▆▂▄▅▃▅▄▅▆▄▆▄▅▇▅</td></tr><tr><td>Train Specificity</td><td>▁▁▁█▃██████████████████▇█▇████████████▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.73</td></tr><tr><td>Test F1</td><td>0.68966</td></tr><tr><td>Test Loss</td><td>0.573</td></tr><tr><td>Test Sensitivity</td><td>0.58252</td></tr><tr><td>Test Specificity</td><td>0.8866</td></tr><tr><td>Train Accuracy</td><td>0.7931</td></tr><tr><td>Train F1</td><td>0.76471</td></tr><tr><td>Train Loss</td><td>0.49148</td></tr><tr><td>Train Sensitivity</td><td>0.63415</td></tr><tr><td>Train Specificity</td><td>0.97248</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-32</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/75guh4fw' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/75guh4fw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_183554-75guh4fw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lwtoqrfx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.214901148097237e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002061918657135869\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_183630-lwtoqrfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/lwtoqrfx' target=\"_blank\">ethereal-sweep-33</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/lwtoqrfx' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/lwtoqrfx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6945\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6942\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6941\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6943\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6943\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6942\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>█▄▂▁▁▂▃▄▄▄▄▃▃▂▂▂▃▃▄▅▅▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▂</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▃▁▅▄▅█▄█▃▄▄█▃▂▃▆▃▄▂▅▂▆▆▆▅▆▂▆▅▃▃▂▂▄▂▅▂▅▃▄</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.6941</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69116</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-33</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/lwtoqrfx' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/lwtoqrfx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_183630-lwtoqrfx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2tyediyg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.4822393723835496e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 9.095632491247144e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_183655-2tyediyg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/2tyediyg' target=\"_blank\">scarlet-sweep-34</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2tyediyg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2tyediyg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6941, Test Loss: 0.6935\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6920, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6927\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6924\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6922\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6921\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6920\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6917\n",
      "Epoch: 090, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6916\n",
      "Epoch: 100, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6916\n",
      "Epoch: 110, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6914\n",
      "Epoch: 120, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6913\n",
      "Epoch: 130, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6912\n",
      "Epoch: 140, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6910\n",
      "Epoch: 150, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6909\n",
      "Epoch: 160, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 170, Train Acc: 0.5237, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 180, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6906\n",
      "Epoch: 190, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6905\n",
      "Epoch: 200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6905\n",
      "Epoch: 210, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6903\n",
      "Epoch: 220, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6901\n",
      "Epoch: 230, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6900\n",
      "Epoch: 240, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6899\n",
      "Epoch: 250, Train Acc: 0.5302, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6897\n",
      "Epoch: 260, Train Acc: 0.5302, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6896\n",
      "Epoch: 270, Train Acc: 0.5302, Test Acc: 0.5200, Train Loss: 0.6876, Test Loss: 0.6896\n",
      "Epoch: 280, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6896\n",
      "Epoch: 290, Train Acc: 0.5280, Test Acc: 0.5200, Train Loss: 0.6879, Test Loss: 0.6893\n",
      "Epoch: 300, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6870, Test Loss: 0.6891\n",
      "Epoch: 310, Train Acc: 0.5345, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6890\n",
      "Epoch: 320, Train Acc: 0.5345, Test Acc: 0.5250, Train Loss: 0.6868, Test Loss: 0.6889\n",
      "Epoch: 330, Train Acc: 0.5496, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6888\n",
      "Epoch: 340, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6862, Test Loss: 0.6887\n",
      "Epoch: 350, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6886\n",
      "Epoch: 360, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6864, Test Loss: 0.6885\n",
      "Epoch: 370, Train Acc: 0.5496, Test Acc: 0.5150, Train Loss: 0.6862, Test Loss: 0.6883\n",
      "Epoch: 380, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6883\n",
      "Epoch: 390, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6881\n",
      "Epoch: 400, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6857, Test Loss: 0.6880\n",
      "Epoch: 410, Train Acc: 0.5496, Test Acc: 0.5100, Train Loss: 0.6856, Test Loss: 0.6878\n",
      "Epoch: 420, Train Acc: 0.5474, Test Acc: 0.5100, Train Loss: 0.6850, Test Loss: 0.6877\n",
      "Epoch: 430, Train Acc: 0.5496, Test Acc: 0.5100, Train Loss: 0.6850, Test Loss: 0.6875\n",
      "Epoch: 440, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6845, Test Loss: 0.6875\n",
      "Epoch: 450, Train Acc: 0.5517, Test Acc: 0.5100, Train Loss: 0.6854, Test Loss: 0.6873\n",
      "Epoch: 460, Train Acc: 0.5647, Test Acc: 0.5200, Train Loss: 0.6858, Test Loss: 0.6870\n",
      "Epoch: 470, Train Acc: 0.5647, Test Acc: 0.5250, Train Loss: 0.6840, Test Loss: 0.6869\n",
      "Epoch: 480, Train Acc: 0.5603, Test Acc: 0.5100, Train Loss: 0.6836, Test Loss: 0.6868\n",
      "Epoch: 490, Train Acc: 0.5582, Test Acc: 0.5100, Train Loss: 0.6844, Test Loss: 0.6866\n",
      "Epoch: 500, Train Acc: 0.5668, Test Acc: 0.5250, Train Loss: 0.6837, Test Loss: 0.6864\n",
      "Epoch: 510, Train Acc: 0.5647, Test Acc: 0.5100, Train Loss: 0.6837, Test Loss: 0.6863\n",
      "Epoch: 520, Train Acc: 0.5711, Test Acc: 0.5250, Train Loss: 0.6835, Test Loss: 0.6861\n",
      "Epoch: 530, Train Acc: 0.5625, Test Acc: 0.5100, Train Loss: 0.6830, Test Loss: 0.6860\n",
      "Epoch: 540, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6833, Test Loss: 0.6858\n",
      "Epoch: 550, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6818, Test Loss: 0.6855\n",
      "Epoch: 560, Train Acc: 0.5797, Test Acc: 0.5250, Train Loss: 0.6827, Test Loss: 0.6854\n",
      "Epoch: 570, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6821, Test Loss: 0.6851\n",
      "Epoch: 580, Train Acc: 0.5754, Test Acc: 0.5150, Train Loss: 0.6816, Test Loss: 0.6850\n",
      "Epoch: 590, Train Acc: 0.5776, Test Acc: 0.5150, Train Loss: 0.6820, Test Loss: 0.6848\n",
      "Epoch: 600, Train Acc: 0.5776, Test Acc: 0.5100, Train Loss: 0.6818, Test Loss: 0.6846\n",
      "Epoch: 610, Train Acc: 0.5776, Test Acc: 0.5100, Train Loss: 0.6808, Test Loss: 0.6844\n",
      "Epoch: 620, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6812, Test Loss: 0.6843\n",
      "Epoch: 630, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6810, Test Loss: 0.6841\n",
      "Epoch: 640, Train Acc: 0.5711, Test Acc: 0.5100, Train Loss: 0.6800, Test Loss: 0.6838\n",
      "Epoch: 650, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6806, Test Loss: 0.6835\n",
      "Epoch: 660, Train Acc: 0.5776, Test Acc: 0.5150, Train Loss: 0.6801, Test Loss: 0.6832\n",
      "Epoch: 670, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6791, Test Loss: 0.6830\n",
      "Epoch: 680, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6793, Test Loss: 0.6827\n",
      "Epoch: 690, Train Acc: 0.5797, Test Acc: 0.5150, Train Loss: 0.6790, Test Loss: 0.6825\n",
      "Epoch: 700, Train Acc: 0.5754, Test Acc: 0.5150, Train Loss: 0.6791, Test Loss: 0.6823\n",
      "Epoch: 710, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6788, Test Loss: 0.6820\n",
      "Epoch: 720, Train Acc: 0.5733, Test Acc: 0.5200, Train Loss: 0.6778, Test Loss: 0.6817\n",
      "Epoch: 730, Train Acc: 0.5819, Test Acc: 0.5150, Train Loss: 0.6777, Test Loss: 0.6814\n",
      "Epoch: 740, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6772, Test Loss: 0.6811\n",
      "Epoch: 750, Train Acc: 0.5862, Test Acc: 0.5150, Train Loss: 0.6776, Test Loss: 0.6808\n",
      "Epoch: 760, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6767, Test Loss: 0.6805\n",
      "Epoch: 770, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6761, Test Loss: 0.6802\n",
      "Epoch: 780, Train Acc: 0.5884, Test Acc: 0.5200, Train Loss: 0.6766, Test Loss: 0.6799\n",
      "Epoch: 790, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6760, Test Loss: 0.6796\n",
      "Epoch: 800, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6747, Test Loss: 0.6791\n",
      "Epoch: 810, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6743, Test Loss: 0.6788\n",
      "Epoch: 820, Train Acc: 0.5884, Test Acc: 0.5300, Train Loss: 0.6749, Test Loss: 0.6785\n",
      "Epoch: 830, Train Acc: 0.5905, Test Acc: 0.5300, Train Loss: 0.6743, Test Loss: 0.6782\n",
      "Epoch: 840, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6734, Test Loss: 0.6777\n",
      "Epoch: 850, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6737, Test Loss: 0.6773\n",
      "Epoch: 860, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6730, Test Loss: 0.6768\n",
      "Epoch: 870, Train Acc: 0.5991, Test Acc: 0.5400, Train Loss: 0.6719, Test Loss: 0.6765\n",
      "Epoch: 880, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6713, Test Loss: 0.6762\n",
      "Epoch: 890, Train Acc: 0.5991, Test Acc: 0.5350, Train Loss: 0.6712, Test Loss: 0.6757\n",
      "Epoch: 900, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6704, Test Loss: 0.6753\n",
      "Epoch: 910, Train Acc: 0.6056, Test Acc: 0.5400, Train Loss: 0.6700, Test Loss: 0.6749\n",
      "Epoch: 920, Train Acc: 0.6056, Test Acc: 0.5350, Train Loss: 0.6703, Test Loss: 0.6745\n",
      "Epoch: 930, Train Acc: 0.6078, Test Acc: 0.5300, Train Loss: 0.6687, Test Loss: 0.6741\n",
      "Epoch: 940, Train Acc: 0.6056, Test Acc: 0.5550, Train Loss: 0.6690, Test Loss: 0.6734\n",
      "Epoch: 950, Train Acc: 0.6056, Test Acc: 0.5550, Train Loss: 0.6675, Test Loss: 0.6730\n",
      "Epoch: 960, Train Acc: 0.6121, Test Acc: 0.5350, Train Loss: 0.6677, Test Loss: 0.6726\n",
      "Epoch: 970, Train Acc: 0.6121, Test Acc: 0.5500, Train Loss: 0.6671, Test Loss: 0.6721\n",
      "Epoch: 980, Train Acc: 0.6099, Test Acc: 0.5650, Train Loss: 0.6666, Test Loss: 0.6716\n",
      "Epoch: 990, Train Acc: 0.6207, Test Acc: 0.5600, Train Loss: 0.6666, Test Loss: 0.6711\n",
      "Epoch: 1000, Train Acc: 0.6121, Test Acc: 0.5550, Train Loss: 0.6650, Test Loss: 0.6707\n",
      "Epoch: 1010, Train Acc: 0.6228, Test Acc: 0.5600, Train Loss: 0.6641, Test Loss: 0.6701\n",
      "Epoch: 1020, Train Acc: 0.6293, Test Acc: 0.5600, Train Loss: 0.6637, Test Loss: 0.6694\n",
      "Epoch: 1030, Train Acc: 0.6293, Test Acc: 0.5600, Train Loss: 0.6626, Test Loss: 0.6689\n",
      "Epoch: 1040, Train Acc: 0.6293, Test Acc: 0.5600, Train Loss: 0.6624, Test Loss: 0.6684\n",
      "Epoch: 1050, Train Acc: 0.6315, Test Acc: 0.5600, Train Loss: 0.6619, Test Loss: 0.6678\n",
      "Epoch: 1060, Train Acc: 0.6401, Test Acc: 0.5650, Train Loss: 0.6608, Test Loss: 0.6672\n",
      "Epoch: 1070, Train Acc: 0.6379, Test Acc: 0.5800, Train Loss: 0.6604, Test Loss: 0.6666\n",
      "Epoch: 1080, Train Acc: 0.6401, Test Acc: 0.5800, Train Loss: 0.6590, Test Loss: 0.6659\n",
      "Epoch: 1090, Train Acc: 0.6401, Test Acc: 0.5850, Train Loss: 0.6593, Test Loss: 0.6654\n",
      "Epoch: 1100, Train Acc: 0.6379, Test Acc: 0.5900, Train Loss: 0.6586, Test Loss: 0.6648\n",
      "Epoch: 1110, Train Acc: 0.6466, Test Acc: 0.5800, Train Loss: 0.6581, Test Loss: 0.6643\n",
      "Epoch: 1120, Train Acc: 0.6659, Test Acc: 0.6000, Train Loss: 0.6557, Test Loss: 0.6635\n",
      "Epoch: 1130, Train Acc: 0.6659, Test Acc: 0.6000, Train Loss: 0.6556, Test Loss: 0.6629\n",
      "Epoch: 1140, Train Acc: 0.6703, Test Acc: 0.5950, Train Loss: 0.6550, Test Loss: 0.6623\n",
      "Epoch: 1150, Train Acc: 0.6789, Test Acc: 0.5950, Train Loss: 0.6548, Test Loss: 0.6617\n",
      "Epoch: 1160, Train Acc: 0.6789, Test Acc: 0.6000, Train Loss: 0.6534, Test Loss: 0.6610\n",
      "Epoch: 1170, Train Acc: 0.6853, Test Acc: 0.5950, Train Loss: 0.6524, Test Loss: 0.6603\n",
      "Epoch: 1180, Train Acc: 0.6853, Test Acc: 0.6000, Train Loss: 0.6524, Test Loss: 0.6596\n",
      "Epoch: 1190, Train Acc: 0.6875, Test Acc: 0.6200, Train Loss: 0.6517, Test Loss: 0.6588\n",
      "Epoch: 1200, Train Acc: 0.6897, Test Acc: 0.6300, Train Loss: 0.6497, Test Loss: 0.6581\n",
      "Epoch: 1210, Train Acc: 0.6853, Test Acc: 0.6300, Train Loss: 0.6498, Test Loss: 0.6574\n",
      "Epoch: 1220, Train Acc: 0.6940, Test Acc: 0.6300, Train Loss: 0.6488, Test Loss: 0.6568\n",
      "Epoch: 1230, Train Acc: 0.6961, Test Acc: 0.6350, Train Loss: 0.6475, Test Loss: 0.6558\n",
      "Epoch: 1240, Train Acc: 0.6897, Test Acc: 0.6400, Train Loss: 0.6459, Test Loss: 0.6553\n",
      "Epoch: 1250, Train Acc: 0.7004, Test Acc: 0.6400, Train Loss: 0.6460, Test Loss: 0.6544\n",
      "Epoch: 1260, Train Acc: 0.6940, Test Acc: 0.6450, Train Loss: 0.6437, Test Loss: 0.6539\n",
      "Epoch: 1270, Train Acc: 0.7004, Test Acc: 0.6350, Train Loss: 0.6441, Test Loss: 0.6530\n",
      "Epoch: 1280, Train Acc: 0.7091, Test Acc: 0.6350, Train Loss: 0.6430, Test Loss: 0.6522\n",
      "Epoch: 1290, Train Acc: 0.7112, Test Acc: 0.6400, Train Loss: 0.6426, Test Loss: 0.6515\n",
      "Epoch: 1300, Train Acc: 0.7241, Test Acc: 0.6450, Train Loss: 0.6415, Test Loss: 0.6506\n",
      "Epoch: 1310, Train Acc: 0.7241, Test Acc: 0.6400, Train Loss: 0.6392, Test Loss: 0.6499\n",
      "Epoch: 1320, Train Acc: 0.7263, Test Acc: 0.6600, Train Loss: 0.6394, Test Loss: 0.6491\n",
      "Epoch: 1330, Train Acc: 0.7220, Test Acc: 0.6750, Train Loss: 0.6387, Test Loss: 0.6483\n",
      "Epoch: 1340, Train Acc: 0.7263, Test Acc: 0.6750, Train Loss: 0.6373, Test Loss: 0.6475\n",
      "Epoch: 1350, Train Acc: 0.7306, Test Acc: 0.6900, Train Loss: 0.6350, Test Loss: 0.6468\n",
      "Epoch: 1360, Train Acc: 0.7241, Test Acc: 0.6700, Train Loss: 0.6344, Test Loss: 0.6458\n",
      "Epoch: 1370, Train Acc: 0.7263, Test Acc: 0.6800, Train Loss: 0.6344, Test Loss: 0.6450\n",
      "Epoch: 1380, Train Acc: 0.7371, Test Acc: 0.6800, Train Loss: 0.6335, Test Loss: 0.6443\n",
      "Epoch: 1390, Train Acc: 0.7263, Test Acc: 0.6850, Train Loss: 0.6323, Test Loss: 0.6434\n",
      "Epoch: 1400, Train Acc: 0.7284, Test Acc: 0.6900, Train Loss: 0.6305, Test Loss: 0.6425\n",
      "Epoch: 1410, Train Acc: 0.7328, Test Acc: 0.6950, Train Loss: 0.6293, Test Loss: 0.6418\n",
      "Epoch: 1420, Train Acc: 0.7371, Test Acc: 0.6900, Train Loss: 0.6291, Test Loss: 0.6408\n",
      "Epoch: 1430, Train Acc: 0.7392, Test Acc: 0.6900, Train Loss: 0.6282, Test Loss: 0.6400\n",
      "Epoch: 1440, Train Acc: 0.7392, Test Acc: 0.6850, Train Loss: 0.6266, Test Loss: 0.6391\n",
      "Epoch: 1450, Train Acc: 0.7457, Test Acc: 0.6900, Train Loss: 0.6255, Test Loss: 0.6384\n",
      "Epoch: 1460, Train Acc: 0.7435, Test Acc: 0.6950, Train Loss: 0.6241, Test Loss: 0.6375\n",
      "Epoch: 1470, Train Acc: 0.7457, Test Acc: 0.6900, Train Loss: 0.6237, Test Loss: 0.6367\n",
      "Epoch: 1480, Train Acc: 0.7457, Test Acc: 0.6950, Train Loss: 0.6221, Test Loss: 0.6357\n",
      "Epoch: 1490, Train Acc: 0.7478, Test Acc: 0.6950, Train Loss: 0.6207, Test Loss: 0.6349\n",
      "Epoch: 1500, Train Acc: 0.7435, Test Acc: 0.6950, Train Loss: 0.6193, Test Loss: 0.6339\n",
      "Epoch: 1510, Train Acc: 0.7457, Test Acc: 0.7000, Train Loss: 0.6180, Test Loss: 0.6331\n",
      "Epoch: 1520, Train Acc: 0.7500, Test Acc: 0.7000, Train Loss: 0.6166, Test Loss: 0.6323\n",
      "Epoch: 1530, Train Acc: 0.7522, Test Acc: 0.6950, Train Loss: 0.6169, Test Loss: 0.6313\n",
      "Epoch: 1540, Train Acc: 0.7478, Test Acc: 0.7000, Train Loss: 0.6146, Test Loss: 0.6305\n",
      "Epoch: 1550, Train Acc: 0.7565, Test Acc: 0.7000, Train Loss: 0.6141, Test Loss: 0.6297\n",
      "Epoch: 1560, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.6129, Test Loss: 0.6288\n",
      "Epoch: 1570, Train Acc: 0.7586, Test Acc: 0.6850, Train Loss: 0.6117, Test Loss: 0.6278\n",
      "Epoch: 1580, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.6110, Test Loss: 0.6272\n",
      "Epoch: 1590, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.6101, Test Loss: 0.6264\n",
      "Epoch: 1600, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.6077, Test Loss: 0.6254\n",
      "Epoch: 1610, Train Acc: 0.7608, Test Acc: 0.7000, Train Loss: 0.6080, Test Loss: 0.6246\n",
      "Epoch: 1620, Train Acc: 0.7608, Test Acc: 0.6950, Train Loss: 0.6064, Test Loss: 0.6238\n",
      "Epoch: 1630, Train Acc: 0.7586, Test Acc: 0.7000, Train Loss: 0.6053, Test Loss: 0.6229\n",
      "Epoch: 1640, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.6030, Test Loss: 0.6223\n",
      "Epoch: 1650, Train Acc: 0.7565, Test Acc: 0.7050, Train Loss: 0.6026, Test Loss: 0.6212\n",
      "Epoch: 1660, Train Acc: 0.7522, Test Acc: 0.7050, Train Loss: 0.6024, Test Loss: 0.6203\n",
      "Epoch: 1670, Train Acc: 0.7608, Test Acc: 0.7000, Train Loss: 0.6004, Test Loss: 0.6198\n",
      "Epoch: 1680, Train Acc: 0.7565, Test Acc: 0.7000, Train Loss: 0.5987, Test Loss: 0.6187\n",
      "Epoch: 1690, Train Acc: 0.7565, Test Acc: 0.7050, Train Loss: 0.5993, Test Loss: 0.6180\n",
      "Epoch: 1700, Train Acc: 0.7586, Test Acc: 0.7000, Train Loss: 0.5983, Test Loss: 0.6172\n",
      "Epoch: 1710, Train Acc: 0.7608, Test Acc: 0.7050, Train Loss: 0.5950, Test Loss: 0.6167\n",
      "Epoch: 1720, Train Acc: 0.7522, Test Acc: 0.7000, Train Loss: 0.5947, Test Loss: 0.6155\n",
      "Epoch: 1730, Train Acc: 0.7565, Test Acc: 0.6950, Train Loss: 0.5938, Test Loss: 0.6147\n",
      "Epoch: 1740, Train Acc: 0.7586, Test Acc: 0.7000, Train Loss: 0.5938, Test Loss: 0.6141\n",
      "Epoch: 1750, Train Acc: 0.7565, Test Acc: 0.6950, Train Loss: 0.5925, Test Loss: 0.6133\n",
      "Epoch: 1760, Train Acc: 0.7565, Test Acc: 0.6950, Train Loss: 0.5894, Test Loss: 0.6125\n",
      "Epoch: 1770, Train Acc: 0.7543, Test Acc: 0.6900, Train Loss: 0.5888, Test Loss: 0.6116\n",
      "Epoch: 1780, Train Acc: 0.7586, Test Acc: 0.6900, Train Loss: 0.5890, Test Loss: 0.6108\n",
      "Epoch: 1790, Train Acc: 0.7586, Test Acc: 0.6900, Train Loss: 0.5864, Test Loss: 0.6100\n",
      "Epoch: 1800, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.5856, Test Loss: 0.6095\n",
      "Epoch: 1810, Train Acc: 0.7565, Test Acc: 0.6850, Train Loss: 0.5845, Test Loss: 0.6084\n",
      "Epoch: 1820, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5848, Test Loss: 0.6081\n",
      "Epoch: 1830, Train Acc: 0.7586, Test Acc: 0.6850, Train Loss: 0.5824, Test Loss: 0.6071\n",
      "Epoch: 1840, Train Acc: 0.7608, Test Acc: 0.6900, Train Loss: 0.5828, Test Loss: 0.6064\n",
      "Epoch: 1850, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5817, Test Loss: 0.6057\n",
      "Epoch: 1860, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5784, Test Loss: 0.6048\n",
      "Epoch: 1870, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5800, Test Loss: 0.6044\n",
      "Epoch: 1880, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5768, Test Loss: 0.6035\n",
      "Epoch: 1890, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5764, Test Loss: 0.6028\n",
      "Epoch: 1900, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5754, Test Loss: 0.6020\n",
      "Epoch: 1910, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5749, Test Loss: 0.6013\n",
      "Epoch: 1920, Train Acc: 0.7672, Test Acc: 0.6950, Train Loss: 0.5731, Test Loss: 0.6007\n",
      "Epoch: 1930, Train Acc: 0.7672, Test Acc: 0.6950, Train Loss: 0.5716, Test Loss: 0.5997\n",
      "Epoch: 1940, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5706, Test Loss: 0.5996\n",
      "Epoch: 1950, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5719, Test Loss: 0.5986\n",
      "Epoch: 1960, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5673, Test Loss: 0.5979\n",
      "Epoch: 1970, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5679, Test Loss: 0.5975\n",
      "Epoch: 1980, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5671, Test Loss: 0.5966\n",
      "Epoch: 1990, Train Acc: 0.7737, Test Acc: 0.6850, Train Loss: 0.5667, Test Loss: 0.5961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▅▅▅▅▇▇▇▇████▇▇▇▇█▇</td></tr><tr><td>Test F1</td><td>▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▂▂▃▄▄▄▄▆▇▆▇█▇▆▇▅▅▅▅▆▅</td></tr><tr><td>Test Loss</td><td>███████████▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>█████████▇█▇▇▇▇▆▆▆▇▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▂▁▂▁▂▁▂▂▂▂▃▃▄▅▅▆▆▆▇▇▇▇▇████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▂▂▂▃▃▃▃▃▄▄▅▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▂▂▂▂▃▃▃▃▃▄▅▅▅▆▇▇▇▇▇██▇▇▇███▇</td></tr><tr><td>Train Loss</td><td>████████████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>█████▇▇██▇█▇▇▇▇▇▇▆▆▆▅▅▅▄▃▃▃▃▃▃▃▂▂▂▂▁▂▂▂▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▃▃▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.69</td></tr><tr><td>Test F1</td><td>0.70192</td></tr><tr><td>Test Loss</td><td>0.59535</td></tr><tr><td>Test Sensitivity</td><td>0.70874</td></tr><tr><td>Test Specificity</td><td>0.6701</td></tr><tr><td>Train Accuracy</td><td>0.77155</td></tr><tr><td>Train F1</td><td>0.78189</td></tr><tr><td>Train Loss</td><td>0.56511</td></tr><tr><td>Train Sensitivity</td><td>0.77236</td></tr><tr><td>Train Specificity</td><td>0.77064</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-34</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2tyediyg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2tyediyg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_183655-2tyediyg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a2wbl3rv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010048867990229724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0015707114619439978\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_184908-a2wbl3rv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/a2wbl3rv' target=\"_blank\">serene-sweep-35</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/a2wbl3rv' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/a2wbl3rv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6926, Test Loss: 0.6928\n",
      "Epoch: 010, Train Acc: 0.5194, Test Acc: 0.5200, Train Loss: 0.6916, Test Loss: 0.6918\n",
      "Epoch: 020, Train Acc: 0.5366, Test Acc: 0.4900, Train Loss: 0.6879, Test Loss: 0.6888\n",
      "Epoch: 030, Train Acc: 0.5754, Test Acc: 0.5250, Train Loss: 0.6826, Test Loss: 0.6852\n",
      "Epoch: 040, Train Acc: 0.5862, Test Acc: 0.5450, Train Loss: 0.6767, Test Loss: 0.6802\n",
      "Epoch: 050, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6684, Test Loss: 0.6752\n",
      "Epoch: 060, Train Acc: 0.6681, Test Acc: 0.6650, Train Loss: 0.6574, Test Loss: 0.6613\n",
      "Epoch: 070, Train Acc: 0.7414, Test Acc: 0.6900, Train Loss: 0.6329, Test Loss: 0.6435\n",
      "Epoch: 080, Train Acc: 0.7457, Test Acc: 0.6900, Train Loss: 0.6082, Test Loss: 0.6236\n",
      "Epoch: 090, Train Acc: 0.7155, Test Acc: 0.6600, Train Loss: 0.5884, Test Loss: 0.6079\n",
      "Epoch: 100, Train Acc: 0.6703, Test Acc: 0.6450, Train Loss: 0.5908, Test Loss: 0.6105\n",
      "Epoch: 110, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5409, Test Loss: 0.5777\n",
      "Epoch: 120, Train Acc: 0.7371, Test Acc: 0.6750, Train Loss: 0.5302, Test Loss: 0.5756\n",
      "Epoch: 130, Train Acc: 0.7414, Test Acc: 0.6850, Train Loss: 0.5157, Test Loss: 0.5657\n",
      "Epoch: 140, Train Acc: 0.7543, Test Acc: 0.6800, Train Loss: 0.5000, Test Loss: 0.5609\n",
      "Epoch: 150, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4815, Test Loss: 0.5500\n",
      "Epoch: 160, Train Acc: 0.7759, Test Acc: 0.6950, Train Loss: 0.4837, Test Loss: 0.5504\n",
      "Epoch: 170, Train Acc: 0.7780, Test Acc: 0.6900, Train Loss: 0.4840, Test Loss: 0.5508\n",
      "Epoch: 180, Train Acc: 0.7565, Test Acc: 0.7050, Train Loss: 0.4956, Test Loss: 0.5634\n",
      "Epoch: 190, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4517, Test Loss: 0.5380\n",
      "Epoch: 200, Train Acc: 0.8168, Test Acc: 0.7300, Train Loss: 0.4433, Test Loss: 0.5315\n",
      "Epoch: 210, Train Acc: 0.7586, Test Acc: 0.7100, Train Loss: 0.4964, Test Loss: 0.5657\n",
      "Epoch: 220, Train Acc: 0.8254, Test Acc: 0.7400, Train Loss: 0.4392, Test Loss: 0.5280\n",
      "Epoch: 230, Train Acc: 0.8233, Test Acc: 0.7450, Train Loss: 0.4330, Test Loss: 0.5253\n",
      "Epoch: 240, Train Acc: 0.7931, Test Acc: 0.7350, Train Loss: 0.4556, Test Loss: 0.5391\n",
      "Epoch: 250, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4611, Test Loss: 0.5419\n",
      "Epoch: 260, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4410, Test Loss: 0.5318\n",
      "Epoch: 270, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4111, Test Loss: 0.5213\n",
      "Epoch: 280, Train Acc: 0.8082, Test Acc: 0.7650, Train Loss: 0.4083, Test Loss: 0.5330\n",
      "Epoch: 290, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4068, Test Loss: 0.5160\n",
      "Epoch: 300, Train Acc: 0.8384, Test Acc: 0.7700, Train Loss: 0.4116, Test Loss: 0.5205\n",
      "Epoch: 310, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4291, Test Loss: 0.5331\n",
      "Epoch: 320, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4053, Test Loss: 0.5170\n",
      "Epoch: 330, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4406, Test Loss: 0.5431\n",
      "Epoch: 340, Train Acc: 0.7651, Test Acc: 0.7200, Train Loss: 0.5214, Test Loss: 0.6043\n",
      "Epoch: 350, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4131, Test Loss: 0.5279\n",
      "Epoch: 360, Train Acc: 0.8448, Test Acc: 0.7900, Train Loss: 0.3797, Test Loss: 0.5151\n",
      "Epoch: 370, Train Acc: 0.8470, Test Acc: 0.7800, Train Loss: 0.3737, Test Loss: 0.5202\n",
      "Epoch: 380, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.3741, Test Loss: 0.5371\n",
      "Epoch: 390, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.3802, Test Loss: 0.5544\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▁▁▅▆▅▅▆▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇█▇▇</td></tr><tr><td>Test F1</td><td>▁▆▆▇▇▇▇▇▆▆▇▆▆▆▇▆▆▇▇▇▇▇▇█▇▇▇█▇█▇▇█▇██▇█▇█</td></tr><tr><td>Test Loss</td><td>█████▇▇▆▅▅▄▄▄▃▂▃▃▂▂▂▂▂▂▁▂▁▁▁▂▁▁▂▂▃▂▂▂▂▂▂</td></tr><tr><td>Test Sensitivity</td><td>▁▅▆▇██▇▅▄▄▅▄▄▄▅▅▄▅▅▅▅▅▅▆▅▅▅▆▅▆▅▅▇▅▇▇▅▇▅▇</td></tr><tr><td>Test Specificity</td><td>█▃▃▂▁▁▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▇▆▆▇▆▇▆</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▂▃▅▆▅▅▇▆▆▆▇▇▆▇▇▇▇▇▇█▇███▇██▇█▇████▇█</td></tr><tr><td>Train F1</td><td>▁▆▆▇▇▇▇▇▆▆▇▇▆▇▇▇▇▇█▇█▇██▇███▇██▇█▇████▇█</td></tr><tr><td>Train Loss</td><td>█████▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▃▂▂▃▂▂▃▁▃▁▁▂▁▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁▅▆▇██▇▅▄▅▆▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▆▇▅▆▆▅▇▅▇▇▆▇▆▇</td></tr><tr><td>Train Specificity</td><td>█▄▃▃▁▁▅▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇███▇████▇█▇▆█▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.74</td></tr><tr><td>Test F1</td><td>0.70455</td></tr><tr><td>Test Loss</td><td>0.54753</td></tr><tr><td>Test Sensitivity</td><td>0.60194</td></tr><tr><td>Test Specificity</td><td>0.8866</td></tr><tr><td>Train Accuracy</td><td>0.81466</td></tr><tr><td>Train F1</td><td>0.79717</td></tr><tr><td>Train Loss</td><td>0.42622</td></tr><tr><td>Train Sensitivity</td><td>0.68699</td></tr><tr><td>Train Specificity</td><td>0.95872</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-sweep-35</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/a2wbl3rv' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/a2wbl3rv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_184908-a2wbl3rv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q0zja0oo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.490334785239361e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.627973787980456e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_185142-q0zja0oo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/q0zja0oo' target=\"_blank\">hopeful-sweep-36</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/q0zja0oo' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/q0zja0oo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6945\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6941\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6937\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6936\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6935\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6933\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6931\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6930\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6929\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6928\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6927\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6927\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6926\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6926\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6925\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6925\n",
      "Epoch: 160, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6926\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6926\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6925\n",
      "Epoch: 190, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6924\n",
      "Epoch: 200, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6924\n",
      "Epoch: 210, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6923\n",
      "Epoch: 220, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6923\n",
      "Epoch: 230, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6923\n",
      "Epoch: 240, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6923\n",
      "Epoch: 250, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6923\n",
      "Epoch: 260, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6923\n",
      "Epoch: 270, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6923\n",
      "Epoch: 280, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6922\n",
      "Epoch: 290, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6922\n",
      "Epoch: 300, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6922\n",
      "Epoch: 310, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6922\n",
      "Epoch: 320, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6922\n",
      "Epoch: 330, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6922\n",
      "Epoch: 340, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6922\n",
      "Epoch: 350, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6921\n",
      "Epoch: 360, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6921\n",
      "Epoch: 370, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6921\n",
      "Epoch: 380, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6921\n",
      "Epoch: 390, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6921\n",
      "Epoch: 400, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6921\n",
      "Epoch: 410, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6921\n",
      "Epoch: 420, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6921\n",
      "Epoch: 430, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6921\n",
      "Epoch: 440, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6920\n",
      "Epoch: 450, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6920\n",
      "Epoch: 460, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6920\n",
      "Epoch: 470, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6920\n",
      "Epoch: 480, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6920\n",
      "Epoch: 490, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6919\n",
      "Epoch: 500, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6920\n",
      "Epoch: 510, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 520, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 530, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 540, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6919\n",
      "Epoch: 550, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6919\n",
      "Epoch: 560, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6919\n",
      "Epoch: 570, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6918\n",
      "Epoch: 580, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6918\n",
      "Epoch: 590, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6918\n",
      "Epoch: 600, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6918\n",
      "Epoch: 610, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6918\n",
      "Epoch: 620, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6918\n",
      "Epoch: 630, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6918\n",
      "Epoch: 640, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6918\n",
      "Epoch: 650, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6918\n",
      "Epoch: 660, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6892, Test Loss: 0.6917\n",
      "Epoch: 670, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6918\n",
      "Epoch: 680, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6917\n",
      "Epoch: 690, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6917\n",
      "Epoch: 700, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6917\n",
      "Epoch: 710, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6917\n",
      "Epoch: 720, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6917\n",
      "Epoch: 730, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6916\n",
      "Epoch: 740, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6916\n",
      "Epoch: 750, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6916\n",
      "Epoch: 760, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6915\n",
      "Epoch: 770, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6915\n",
      "Epoch: 780, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6916\n",
      "Epoch: 790, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6915\n",
      "Epoch: 800, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6915\n",
      "Epoch: 810, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6915\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>█▇▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>█████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▄▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄</td></tr><tr><td>Train F1</td><td>█████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃</td></tr><tr><td>Train Loss</td><td>█▆▄▄▅▅▄▄▂▅▆▅▄▄▅▃▅▃▃▃▃▄▂▃▂▃▄▂▃▃▂▃▁▄▂▄▂▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>█████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69153</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.52802</td></tr><tr><td>Train F1</td><td>0.69024</td></tr><tr><td>Train Loss</td><td>0.68976</td></tr><tr><td>Train Sensitivity</td><td>0.99187</td></tr><tr><td>Train Specificity</td><td>0.00459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-36</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/q0zja0oo' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/q0zja0oo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_185142-q0zja0oo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7s3cwowd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006608663532616705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.5207483188558175e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_185458-7s3cwowd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/7s3cwowd' target=\"_blank\">breezy-sweep-37</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7s3cwowd' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7s3cwowd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7111, Test Loss: 0.7192\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7011, Test Loss: 0.7084\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6920, Test Loss: 0.6926\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6924\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6930\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6919\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6905\n",
      "Epoch: 070, Train Acc: 0.6961, Test Acc: 0.6150, Train Loss: 0.6637, Test Loss: 0.6663\n",
      "Epoch: 080, Train Acc: 0.6595, Test Acc: 0.6600, Train Loss: 0.6364, Test Loss: 0.6305\n",
      "Epoch: 090, Train Acc: 0.7306, Test Acc: 0.7250, Train Loss: 0.5858, Test Loss: 0.5922\n",
      "Epoch: 100, Train Acc: 0.7716, Test Acc: 0.7450, Train Loss: 0.5015, Test Loss: 0.5237\n",
      "Epoch: 110, Train Acc: 0.7802, Test Acc: 0.7550, Train Loss: 0.5119, Test Loss: 0.5300\n",
      "Epoch: 120, Train Acc: 0.7220, Test Acc: 0.7450, Train Loss: 0.6072, Test Loss: 0.6046\n",
      "Epoch: 130, Train Acc: 0.6897, Test Acc: 0.7300, Train Loss: 0.6510, Test Loss: 0.6515\n",
      "Epoch: 140, Train Acc: 0.7909, Test Acc: 0.7600, Train Loss: 0.4919, Test Loss: 0.5342\n",
      "Epoch: 150, Train Acc: 0.8405, Test Acc: 0.7700, Train Loss: 0.4208, Test Loss: 0.5277\n",
      "Epoch: 160, Train Acc: 0.6789, Test Acc: 0.6100, Train Loss: 0.5996, Test Loss: 0.8369\n",
      "Epoch: 170, Train Acc: 0.4741, Test Acc: 0.4900, Train Loss: 5.0053, Test Loss: 4.6364\n",
      "Epoch: 180, Train Acc: 0.7845, Test Acc: 0.6700, Train Loss: 0.4207, Test Loss: 0.6548\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▇▅▅▆▆▆█▇███▇▇▇█▇█▄▂▇▇▁▇▃▇</td></tr><tr><td>Test F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▇▇▇█▆▆▇▇▆▇▇████▇▇█▇█▇▇▇█▁▇▇█</td></tr><tr><td>Test Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁█▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁██▁██████████▇▄▄▄▄▄▅▅▆▆▇▇▅▅▆▅▆▇█▅▇▁▅█▆</td></tr><tr><td>Test Specificity</td><td>██▁▁█▁▁▁▁▁▁▁▁▁▁▆▇▇███▇█▇▇▆▅██▇▇▇▃▁▇▅██▂▆</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▆▅▆▆▅▄▇▇█▇█▇▅▆█▇█▅▃▇█▁▆▅█</td></tr><tr><td>Train F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▅▇▇████▆▇█▇█▇▇▇█▁▇▇█</td></tr><tr><td>Train Loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▁██▁██████████▆▄▄▄▄▃▅▅▆▆▇▇▄▅▆▆▆██▅▇▁▅█▇</td></tr><tr><td>Train Specificity</td><td>██▁▁█▁▁▁▁▁▁▁▁▁▁▆████████▇▇▆█████▃▂█▆██▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.5</td></tr><tr><td>Test F1</td><td>0.0566</td></tr><tr><td>Test Loss</td><td>4.28033</td></tr><tr><td>Test Sensitivity</td><td>0.02913</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.47845</td></tr><tr><td>Train F1</td><td>0.032</td></tr><tr><td>Train Loss</td><td>4.41746</td></tr><tr><td>Train Sensitivity</td><td>0.01626</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-37</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/7s3cwowd' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/7s3cwowd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_185458-7s3cwowd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqx7aosa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0023704949692664005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.4261587260088538e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_185555-eqx7aosa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/eqx7aosa' target=\"_blank\">confused-sweep-38</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/eqx7aosa' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/eqx7aosa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6939\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6950\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6919\n",
      "Epoch: 030, Train Acc: 0.5496, Test Acc: 0.5500, Train Loss: 0.6857, Test Loss: 0.6860\n",
      "Epoch: 040, Train Acc: 0.6444, Test Acc: 0.6200, Train Loss: 0.6498, Test Loss: 0.6539\n",
      "Epoch: 050, Train Acc: 0.5690, Test Acc: 0.5750, Train Loss: 0.7180, Test Loss: 0.7320\n",
      "Epoch: 060, Train Acc: 0.5884, Test Acc: 0.6000, Train Loss: 0.8771, Test Loss: 0.8780\n",
      "Epoch: 070, Train Acc: 0.5884, Test Acc: 0.6250, Train Loss: 0.9209, Test Loss: 0.9132\n",
      "Epoch: 080, Train Acc: 0.6444, Test Acc: 0.6700, Train Loss: 0.7593, Test Loss: 0.7703\n",
      "Epoch: 090, Train Acc: 0.6703, Test Acc: 0.7000, Train Loss: 0.6737, Test Loss: 0.6946\n",
      "Epoch: 100, Train Acc: 0.6638, Test Acc: 0.6950, Train Loss: 0.7073, Test Loss: 0.7234\n",
      "Epoch: 110, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4422, Test Loss: 0.5531\n",
      "Epoch: 120, Train Acc: 0.6573, Test Acc: 0.6850, Train Loss: 0.8097, Test Loss: 0.8294\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 1.0213, Test Loss: 1.2349\n",
      "Epoch: 140, Train Acc: 0.6703, Test Acc: 0.7000, Train Loss: 0.7726, Test Loss: 0.8035\n",
      "Epoch: 150, Train Acc: 0.5927, Test Acc: 0.6300, Train Loss: 1.0741, Test Loss: 1.0620\n",
      "Epoch: 160, Train Acc: 0.6013, Test Acc: 0.6250, Train Loss: 1.0468, Test Loss: 1.0449\n",
      "Epoch: 170, Train Acc: 0.8384, Test Acc: 0.7300, Train Loss: 0.3656, Test Loss: 0.5560\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 2.5357, Test Loss: 2.9446\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▂▂▅▆▅▄▅▅▃▆▄▇▅▇▆▇▇▇▅▄▇▇▇▆▆▇▇▇▄▇▆▇██▇</td></tr><tr><td>Test F1</td><td>▁▇▇▃▇▇▇▇▇▆▅▆▅▄▆▅▇▆▇▆▇█▇▅▄▇▇▇██▇▇▇▄▇█████</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▃▆▂▅▂▃▂▃▂▁▂▅▇▂▂▂▂▁▂▂▂█▄▂▂▁▂▂</td></tr><tr><td>Test Sensitivity</td><td>▁██▂██▆▅▆▄▃▃▃▂▄▃▄▃▄▄▄▇▄▃▂▅▄▅▇▇▅▅▄▃▄▇▇▅▅▇</td></tr><tr><td>Test Specificity</td><td>█▁▁█▁▁▃▅▅▇▇█▇███████▇▆███▇█▇▄▅▇████▅▅▇▇▅</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▁▂▃▃▄▆▅▄▄▄▃▅▃▅▄▅▄▆█▅▃▃▇▆▇▆▇▇▆▆▃▅▇████</td></tr><tr><td>Train F1</td><td>▁▇▇▂▇▇▆▆▇▆▅▅▅▃▆▄▆▅▆▅▇█▆▄▃▇▆▇██▇▆▆▃▆███▇█</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▃▃▃▃▃▃▃▆▃▅▃▄▃▄▂▁▃▅▇▂▃▂▂▂▂▃▃█▄▁▁▁▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁██▁██▆▅▆▄▃▃▃▂▄▂▄▃▄▃▅▇▄▃▂▅▄▅▇▇▅▄▄▂▄▇▇▆▅▇</td></tr><tr><td>Train Specificity</td><td>█▁▁█▁▂▄▆▆████████████▆██████▅▆█████▅▆██▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.805</td></tr><tr><td>Test F1</td><td>0.80402</td></tr><tr><td>Test Loss</td><td>0.53923</td></tr><tr><td>Test Sensitivity</td><td>0.7767</td></tr><tr><td>Test Specificity</td><td>0.83505</td></tr><tr><td>Train Accuracy</td><td>0.87284</td></tr><tr><td>Train F1</td><td>0.87257</td></tr><tr><td>Train Loss</td><td>0.33282</td></tr><tr><td>Train Sensitivity</td><td>0.82114</td></tr><tr><td>Train Specificity</td><td>0.93119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-38</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/eqx7aosa' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/eqx7aosa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_185555-eqx7aosa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lctokdu2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0306432217187472e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.4645786705141315e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_185652-lctokdu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/lctokdu2' target=\"_blank\">fine-sweep-39</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/lctokdu2' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/lctokdu2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6964, Test Loss: 0.6952\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6994, Test Loss: 0.6970\n",
      "Epoch: 020, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.7001, Test Loss: 0.6978\n",
      "Epoch: 030, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6994, Test Loss: 0.6975\n",
      "Epoch: 040, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6983, Test Loss: 0.6966\n",
      "Epoch: 050, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6966, Test Loss: 0.6956\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>▁▁▁▂▃▄▄▅▆▆▆▇▇▇█████████▇▇▇▇▆▆▅▅▅▄▄▄▄▃▃▂▂</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▁▁▁▃▃▄▃▄▆▆▇▇▇▇████▇█▆▇▇▇▆▆▇▅▆▅▄▅▄▃▃▄▂▃▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.485</td></tr><tr><td>Test F1</td><td>0.0</td></tr><tr><td>Test Loss</td><td>0.69559</td></tr><tr><td>Test Sensitivity</td><td>0.0</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.46983</td></tr><tr><td>Train F1</td><td>0.0</td></tr><tr><td>Train Loss</td><td>0.69658</td></tr><tr><td>Train Sensitivity</td><td>0.0</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-39</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/lctokdu2' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/lctokdu2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_185652-lctokdu2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xfcwzcx3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3162591652877977e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.154309761671225e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_185716-xfcwzcx3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/xfcwzcx3' target=\"_blank\">morning-sweep-40</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/xfcwzcx3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/xfcwzcx3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6961, Test Loss: 0.6951\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6936, Test Loss: 0.6934\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6912, Test Loss: 0.6928\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6927\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6924\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6923\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6921\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6918\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6915\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6913\n",
      "Epoch: 100, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6912\n",
      "Epoch: 110, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6911\n",
      "Epoch: 120, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6909\n",
      "Epoch: 130, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6910\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6906\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6903\n",
      "Epoch: 160, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6902\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6903\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6871, Test Loss: 0.6901\n",
      "Epoch: 190, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6900\n",
      "Epoch: 200, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6868, Test Loss: 0.6896\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6896\n",
      "Epoch: 220, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6894\n",
      "Epoch: 230, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6865, Test Loss: 0.6891\n",
      "Epoch: 240, Train Acc: 0.5388, Test Acc: 0.5200, Train Loss: 0.6862, Test Loss: 0.6889\n",
      "Epoch: 250, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6887\n",
      "Epoch: 260, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6855, Test Loss: 0.6886\n",
      "Epoch: 270, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6882\n",
      "Epoch: 280, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6850, Test Loss: 0.6879\n",
      "Epoch: 290, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6850, Test Loss: 0.6877\n",
      "Epoch: 300, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6845, Test Loss: 0.6877\n",
      "Epoch: 310, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6844, Test Loss: 0.6873\n",
      "Epoch: 320, Train Acc: 0.5517, Test Acc: 0.5150, Train Loss: 0.6838, Test Loss: 0.6870\n",
      "Epoch: 330, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6840, Test Loss: 0.6866\n",
      "Epoch: 340, Train Acc: 0.5625, Test Acc: 0.5150, Train Loss: 0.6830, Test Loss: 0.6863\n",
      "Epoch: 350, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6829, Test Loss: 0.6862\n",
      "Epoch: 360, Train Acc: 0.5905, Test Acc: 0.5400, Train Loss: 0.6821, Test Loss: 0.6854\n",
      "Epoch: 370, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6815, Test Loss: 0.6854\n",
      "Epoch: 380, Train Acc: 0.5754, Test Acc: 0.5200, Train Loss: 0.6808, Test Loss: 0.6849\n",
      "Epoch: 390, Train Acc: 0.5690, Test Acc: 0.5150, Train Loss: 0.6807, Test Loss: 0.6845\n",
      "Epoch: 400, Train Acc: 0.5690, Test Acc: 0.5150, Train Loss: 0.6804, Test Loss: 0.6841\n",
      "Epoch: 410, Train Acc: 0.5927, Test Acc: 0.5350, Train Loss: 0.6801, Test Loss: 0.6834\n",
      "Epoch: 420, Train Acc: 0.5690, Test Acc: 0.5200, Train Loss: 0.6791, Test Loss: 0.6833\n",
      "Epoch: 430, Train Acc: 0.5948, Test Acc: 0.5350, Train Loss: 0.6783, Test Loss: 0.6825\n",
      "Epoch: 440, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6782, Test Loss: 0.6822\n",
      "Epoch: 450, Train Acc: 0.5733, Test Acc: 0.5150, Train Loss: 0.6768, Test Loss: 0.6817\n",
      "Epoch: 460, Train Acc: 0.5905, Test Acc: 0.5350, Train Loss: 0.6763, Test Loss: 0.6810\n",
      "Epoch: 470, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6759, Test Loss: 0.6803\n",
      "Epoch: 480, Train Acc: 0.5905, Test Acc: 0.5350, Train Loss: 0.6749, Test Loss: 0.6798\n",
      "Epoch: 490, Train Acc: 0.6078, Test Acc: 0.5450, Train Loss: 0.6738, Test Loss: 0.6788\n",
      "Epoch: 500, Train Acc: 0.6078, Test Acc: 0.5450, Train Loss: 0.6732, Test Loss: 0.6782\n",
      "Epoch: 510, Train Acc: 0.5797, Test Acc: 0.5300, Train Loss: 0.6719, Test Loss: 0.6779\n",
      "Epoch: 520, Train Acc: 0.6078, Test Acc: 0.5500, Train Loss: 0.6714, Test Loss: 0.6767\n",
      "Epoch: 530, Train Acc: 0.6121, Test Acc: 0.5450, Train Loss: 0.6692, Test Loss: 0.6758\n",
      "Epoch: 540, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6695, Test Loss: 0.6754\n",
      "Epoch: 550, Train Acc: 0.6185, Test Acc: 0.5600, Train Loss: 0.6679, Test Loss: 0.6741\n",
      "Epoch: 560, Train Acc: 0.6164, Test Acc: 0.5600, Train Loss: 0.6661, Test Loss: 0.6733\n",
      "Epoch: 570, Train Acc: 0.6358, Test Acc: 0.5750, Train Loss: 0.6658, Test Loss: 0.6720\n",
      "Epoch: 580, Train Acc: 0.6315, Test Acc: 0.5700, Train Loss: 0.6645, Test Loss: 0.6712\n",
      "Epoch: 590, Train Acc: 0.6401, Test Acc: 0.5800, Train Loss: 0.6620, Test Loss: 0.6700\n",
      "Epoch: 600, Train Acc: 0.6552, Test Acc: 0.5750, Train Loss: 0.6618, Test Loss: 0.6688\n",
      "Epoch: 610, Train Acc: 0.6379, Test Acc: 0.5650, Train Loss: 0.6605, Test Loss: 0.6680\n",
      "Epoch: 620, Train Acc: 0.6595, Test Acc: 0.5900, Train Loss: 0.6584, Test Loss: 0.6665\n",
      "Epoch: 630, Train Acc: 0.6681, Test Acc: 0.6050, Train Loss: 0.6563, Test Loss: 0.6652\n",
      "Epoch: 640, Train Acc: 0.6724, Test Acc: 0.6150, Train Loss: 0.6560, Test Loss: 0.6641\n",
      "Epoch: 650, Train Acc: 0.6810, Test Acc: 0.6200, Train Loss: 0.6540, Test Loss: 0.6627\n",
      "Epoch: 660, Train Acc: 0.6875, Test Acc: 0.6150, Train Loss: 0.6520, Test Loss: 0.6612\n",
      "Epoch: 670, Train Acc: 0.6897, Test Acc: 0.6200, Train Loss: 0.6502, Test Loss: 0.6599\n",
      "Epoch: 680, Train Acc: 0.7112, Test Acc: 0.6450, Train Loss: 0.6484, Test Loss: 0.6582\n",
      "Epoch: 690, Train Acc: 0.7047, Test Acc: 0.6350, Train Loss: 0.6468, Test Loss: 0.6569\n",
      "Epoch: 700, Train Acc: 0.7112, Test Acc: 0.6500, Train Loss: 0.6438, Test Loss: 0.6552\n",
      "Epoch: 710, Train Acc: 0.7112, Test Acc: 0.6500, Train Loss: 0.6421, Test Loss: 0.6538\n",
      "Epoch: 720, Train Acc: 0.7134, Test Acc: 0.6500, Train Loss: 0.6402, Test Loss: 0.6522\n",
      "Epoch: 730, Train Acc: 0.7220, Test Acc: 0.6750, Train Loss: 0.6379, Test Loss: 0.6504\n",
      "Epoch: 740, Train Acc: 0.7284, Test Acc: 0.6750, Train Loss: 0.6363, Test Loss: 0.6486\n",
      "Epoch: 750, Train Acc: 0.7284, Test Acc: 0.6800, Train Loss: 0.6352, Test Loss: 0.6472\n",
      "Epoch: 760, Train Acc: 0.7328, Test Acc: 0.6700, Train Loss: 0.6320, Test Loss: 0.6453\n",
      "Epoch: 770, Train Acc: 0.7435, Test Acc: 0.6650, Train Loss: 0.6299, Test Loss: 0.6436\n",
      "Epoch: 780, Train Acc: 0.7522, Test Acc: 0.6800, Train Loss: 0.6268, Test Loss: 0.6423\n",
      "Epoch: 790, Train Acc: 0.7500, Test Acc: 0.6750, Train Loss: 0.6249, Test Loss: 0.6402\n",
      "Epoch: 800, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6218, Test Loss: 0.6384\n",
      "Epoch: 810, Train Acc: 0.7586, Test Acc: 0.6750, Train Loss: 0.6202, Test Loss: 0.6368\n",
      "Epoch: 820, Train Acc: 0.7543, Test Acc: 0.6750, Train Loss: 0.6172, Test Loss: 0.6347\n",
      "Epoch: 830, Train Acc: 0.7543, Test Acc: 0.6700, Train Loss: 0.6161, Test Loss: 0.6332\n",
      "Epoch: 840, Train Acc: 0.7565, Test Acc: 0.6700, Train Loss: 0.6137, Test Loss: 0.6315\n",
      "Epoch: 850, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.6109, Test Loss: 0.6296\n",
      "Epoch: 860, Train Acc: 0.7629, Test Acc: 0.6750, Train Loss: 0.6090, Test Loss: 0.6281\n",
      "Epoch: 870, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.6064, Test Loss: 0.6263\n",
      "Epoch: 880, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.6055, Test Loss: 0.6245\n",
      "Epoch: 890, Train Acc: 0.7672, Test Acc: 0.6850, Train Loss: 0.6008, Test Loss: 0.6228\n",
      "Epoch: 900, Train Acc: 0.7694, Test Acc: 0.6800, Train Loss: 0.5993, Test Loss: 0.6209\n",
      "Epoch: 910, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5969, Test Loss: 0.6191\n",
      "Epoch: 920, Train Acc: 0.7586, Test Acc: 0.6750, Train Loss: 0.5932, Test Loss: 0.6172\n",
      "Epoch: 930, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.5930, Test Loss: 0.6157\n",
      "Epoch: 940, Train Acc: 0.7716, Test Acc: 0.6900, Train Loss: 0.5911, Test Loss: 0.6145\n",
      "Epoch: 950, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.5858, Test Loss: 0.6124\n",
      "Epoch: 960, Train Acc: 0.7716, Test Acc: 0.6900, Train Loss: 0.5842, Test Loss: 0.6114\n",
      "Epoch: 970, Train Acc: 0.7629, Test Acc: 0.6950, Train Loss: 0.5826, Test Loss: 0.6091\n",
      "Epoch: 980, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5783, Test Loss: 0.6087\n",
      "Epoch: 990, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5773, Test Loss: 0.6061\n",
      "Epoch: 1000, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5766, Test Loss: 0.6047\n",
      "Epoch: 1010, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5733, Test Loss: 0.6037\n",
      "Epoch: 1020, Train Acc: 0.7716, Test Acc: 0.7050, Train Loss: 0.5709, Test Loss: 0.6017\n",
      "Epoch: 1030, Train Acc: 0.7759, Test Acc: 0.7050, Train Loss: 0.5690, Test Loss: 0.6004\n",
      "Epoch: 1040, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5672, Test Loss: 0.5987\n",
      "Epoch: 1050, Train Acc: 0.7780, Test Acc: 0.7150, Train Loss: 0.5635, Test Loss: 0.5979\n",
      "Epoch: 1060, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5600, Test Loss: 0.5962\n",
      "Epoch: 1070, Train Acc: 0.7780, Test Acc: 0.7150, Train Loss: 0.5584, Test Loss: 0.5951\n",
      "Epoch: 1080, Train Acc: 0.7716, Test Acc: 0.6850, Train Loss: 0.5570, Test Loss: 0.5935\n",
      "Epoch: 1090, Train Acc: 0.7716, Test Acc: 0.6850, Train Loss: 0.5556, Test Loss: 0.5923\n",
      "Epoch: 1100, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5517, Test Loss: 0.5912\n",
      "Epoch: 1110, Train Acc: 0.7716, Test Acc: 0.6850, Train Loss: 0.5502, Test Loss: 0.5899\n",
      "Epoch: 1120, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5509, Test Loss: 0.5893\n",
      "Epoch: 1130, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5477, Test Loss: 0.5879\n",
      "Epoch: 1140, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5471, Test Loss: 0.5869\n",
      "Epoch: 1150, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5437, Test Loss: 0.5852\n",
      "Epoch: 1160, Train Acc: 0.7780, Test Acc: 0.7100, Train Loss: 0.5409, Test Loss: 0.5856\n",
      "Epoch: 1170, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5396, Test Loss: 0.5831\n",
      "Epoch: 1180, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5386, Test Loss: 0.5826\n",
      "Epoch: 1190, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5379, Test Loss: 0.5814\n",
      "Epoch: 1200, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5357, Test Loss: 0.5805\n",
      "Epoch: 1210, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5351, Test Loss: 0.5796\n",
      "Epoch: 1220, Train Acc: 0.7716, Test Acc: 0.6900, Train Loss: 0.5332, Test Loss: 0.5783\n",
      "Epoch: 1230, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5270, Test Loss: 0.5788\n",
      "Epoch: 1240, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5283, Test Loss: 0.5769\n",
      "Epoch: 1250, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5286, Test Loss: 0.5764\n",
      "Epoch: 1260, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5229, Test Loss: 0.5754\n",
      "Epoch: 1270, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5250, Test Loss: 0.5747\n",
      "Epoch: 1280, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.5224, Test Loss: 0.5736\n",
      "Epoch: 1290, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5212, Test Loss: 0.5728\n",
      "Epoch: 1300, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5194, Test Loss: 0.5725\n",
      "Epoch: 1310, Train Acc: 0.7823, Test Acc: 0.7000, Train Loss: 0.5159, Test Loss: 0.5714\n",
      "Epoch: 1320, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5178, Test Loss: 0.5709\n",
      "Epoch: 1330, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5147, Test Loss: 0.5699\n",
      "Epoch: 1340, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5122, Test Loss: 0.5699\n",
      "Epoch: 1350, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5102, Test Loss: 0.5690\n",
      "Epoch: 1360, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.5097, Test Loss: 0.5677\n",
      "Epoch: 1370, Train Acc: 0.7866, Test Acc: 0.7150, Train Loss: 0.5087, Test Loss: 0.5678\n",
      "Epoch: 1380, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5052, Test Loss: 0.5671\n",
      "Epoch: 1390, Train Acc: 0.7866, Test Acc: 0.6900, Train Loss: 0.5067, Test Loss: 0.5654\n",
      "Epoch: 1400, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5030, Test Loss: 0.5657\n",
      "Epoch: 1410, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.5060, Test Loss: 0.5649\n",
      "Epoch: 1420, Train Acc: 0.7823, Test Acc: 0.7100, Train Loss: 0.5030, Test Loss: 0.5643\n",
      "Epoch: 1430, Train Acc: 0.7845, Test Acc: 0.7050, Train Loss: 0.5038, Test Loss: 0.5635\n",
      "Epoch: 1440, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5011, Test Loss: 0.5632\n",
      "Epoch: 1450, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.5004, Test Loss: 0.5629\n",
      "Epoch: 1460, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4984, Test Loss: 0.5623\n",
      "Epoch: 1470, Train Acc: 0.7931, Test Acc: 0.6900, Train Loss: 0.4979, Test Loss: 0.5605\n",
      "Epoch: 1480, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4969, Test Loss: 0.5609\n",
      "Epoch: 1490, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4947, Test Loss: 0.5604\n",
      "Epoch: 1500, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4884, Test Loss: 0.5600\n",
      "Epoch: 1510, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4944, Test Loss: 0.5596\n",
      "Epoch: 1520, Train Acc: 0.7845, Test Acc: 0.7150, Train Loss: 0.4959, Test Loss: 0.5582\n",
      "Epoch: 1530, Train Acc: 0.7866, Test Acc: 0.7150, Train Loss: 0.4956, Test Loss: 0.5578\n",
      "Epoch: 1540, Train Acc: 0.7866, Test Acc: 0.7250, Train Loss: 0.4855, Test Loss: 0.5578\n",
      "Epoch: 1550, Train Acc: 0.7888, Test Acc: 0.7200, Train Loss: 0.4876, Test Loss: 0.5584\n",
      "Epoch: 1560, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4900, Test Loss: 0.5576\n",
      "Epoch: 1570, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4895, Test Loss: 0.5569\n",
      "Epoch: 1580, Train Acc: 0.7931, Test Acc: 0.7150, Train Loss: 0.4873, Test Loss: 0.5552\n",
      "Epoch: 1590, Train Acc: 0.7888, Test Acc: 0.7200, Train Loss: 0.4828, Test Loss: 0.5551\n",
      "Epoch: 1600, Train Acc: 0.7974, Test Acc: 0.7200, Train Loss: 0.4900, Test Loss: 0.5543\n",
      "Epoch: 1610, Train Acc: 0.7866, Test Acc: 0.7250, Train Loss: 0.4822, Test Loss: 0.5546\n",
      "Epoch: 1620, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4820, Test Loss: 0.5538\n",
      "Epoch: 1630, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4815, Test Loss: 0.5537\n",
      "Epoch: 1640, Train Acc: 0.7931, Test Acc: 0.7200, Train Loss: 0.4819, Test Loss: 0.5528\n",
      "Epoch: 1650, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4791, Test Loss: 0.5528\n",
      "Epoch: 1660, Train Acc: 0.7931, Test Acc: 0.7300, Train Loss: 0.4803, Test Loss: 0.5532\n",
      "Epoch: 1670, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.4802, Test Loss: 0.5515\n",
      "Epoch: 1680, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4756, Test Loss: 0.5517\n",
      "Epoch: 1690, Train Acc: 0.8017, Test Acc: 0.7350, Train Loss: 0.4772, Test Loss: 0.5511\n",
      "Epoch: 1700, Train Acc: 0.7953, Test Acc: 0.7300, Train Loss: 0.4786, Test Loss: 0.5521\n",
      "Epoch: 1710, Train Acc: 0.7953, Test Acc: 0.7350, Train Loss: 0.4757, Test Loss: 0.5499\n",
      "Epoch: 1720, Train Acc: 0.8060, Test Acc: 0.7300, Train Loss: 0.4727, Test Loss: 0.5500\n",
      "Epoch: 1730, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4709, Test Loss: 0.5489\n",
      "Epoch: 1740, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4708, Test Loss: 0.5500\n",
      "Epoch: 1750, Train Acc: 0.7953, Test Acc: 0.7300, Train Loss: 0.4747, Test Loss: 0.5478\n",
      "Epoch: 1760, Train Acc: 0.8017, Test Acc: 0.7400, Train Loss: 0.4701, Test Loss: 0.5489\n",
      "Epoch: 1770, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4715, Test Loss: 0.5481\n",
      "Epoch: 1780, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4688, Test Loss: 0.5480\n",
      "Epoch: 1790, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4726, Test Loss: 0.5466\n",
      "Epoch: 1800, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4652, Test Loss: 0.5471\n",
      "Epoch: 1810, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4652, Test Loss: 0.5470\n",
      "Epoch: 1820, Train Acc: 0.8060, Test Acc: 0.7300, Train Loss: 0.4668, Test Loss: 0.5455\n",
      "Epoch: 1830, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4652, Test Loss: 0.5452\n",
      "Epoch: 1840, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4684, Test Loss: 0.5463\n",
      "Epoch: 1850, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4662, Test Loss: 0.5441\n",
      "Epoch: 1860, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4615, Test Loss: 0.5437\n",
      "Epoch: 1870, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4655, Test Loss: 0.5439\n",
      "Epoch: 1880, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4626, Test Loss: 0.5440\n",
      "Epoch: 1890, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4614, Test Loss: 0.5435\n",
      "Epoch: 1900, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4626, Test Loss: 0.5431\n",
      "Epoch: 1910, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4637, Test Loss: 0.5418\n",
      "Epoch: 1920, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4593, Test Loss: 0.5427\n",
      "Epoch: 1930, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4594, Test Loss: 0.5425\n",
      "Epoch: 1940, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4592, Test Loss: 0.5410\n",
      "Epoch: 1950, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4558, Test Loss: 0.5420\n",
      "Epoch: 1960, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4585, Test Loss: 0.5406\n",
      "Epoch: 1970, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4579, Test Loss: 0.5400\n",
      "Epoch: 1980, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4581, Test Loss: 0.5421\n",
      "Epoch: 1990, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4534, Test Loss: 0.5397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▄▄▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇███████</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅▅▄▄▄▄▄▅▃▃▃▁▃▃▄▆▅▆▆▆▇▆██▇█</td></tr><tr><td>Test Loss</td><td>█████████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>████████▇▇▇▇▆▅▅▅▄▃▃▃▂▃▂▂▂▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▄▄▅▆▆▇▇▇████████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▂▂▂▃▂▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▂▂▃▂▃▃▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>██████████▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>███████▇▇▇▇▆▅▄▄▃▃▂▂▂▁▂▁▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▂▂▃▂▃▄▅▆▆▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.75</td></tr><tr><td>Test F1</td><td>0.7549</td></tr><tr><td>Test Loss</td><td>0.53927</td></tr><tr><td>Test Sensitivity</td><td>0.74757</td></tr><tr><td>Test Specificity</td><td>0.75258</td></tr><tr><td>Train Accuracy</td><td>0.81681</td></tr><tr><td>Train F1</td><td>0.82402</td></tr><tr><td>Train Loss</td><td>0.45581</td></tr><tr><td>Train Sensitivity</td><td>0.80894</td></tr><tr><td>Train Specificity</td><td>0.82569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-40</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/xfcwzcx3' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/xfcwzcx3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_185716-xfcwzcx3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gjwttk22 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.4062694807747572e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.006348508709866373\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_190823-gjwttk22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/gjwttk22' target=\"_blank\">light-sweep-41</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/gjwttk22' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/gjwttk22</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6931\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6919\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6919\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6913\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6913\n",
      "Epoch: 070, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6908\n",
      "Epoch: 080, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6881, Test Loss: 0.6906\n",
      "Epoch: 090, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6901\n",
      "Epoch: 100, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6898\n",
      "Epoch: 110, Train Acc: 0.5388, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6895\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6894\n",
      "Epoch: 130, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6887\n",
      "Epoch: 140, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6851, Test Loss: 0.6882\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6844, Test Loss: 0.6882\n",
      "Epoch: 160, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6834, Test Loss: 0.6873\n",
      "Epoch: 170, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6826, Test Loss: 0.6868\n",
      "Epoch: 180, Train Acc: 0.5517, Test Acc: 0.5100, Train Loss: 0.6822, Test Loss: 0.6863\n",
      "Epoch: 190, Train Acc: 0.5560, Test Acc: 0.5100, Train Loss: 0.6818, Test Loss: 0.6856\n",
      "Epoch: 200, Train Acc: 0.5668, Test Acc: 0.5100, Train Loss: 0.6811, Test Loss: 0.6849\n",
      "Epoch: 210, Train Acc: 0.5690, Test Acc: 0.5150, Train Loss: 0.6798, Test Loss: 0.6841\n",
      "Epoch: 220, Train Acc: 0.5862, Test Acc: 0.5350, Train Loss: 0.6781, Test Loss: 0.6828\n",
      "Epoch: 230, Train Acc: 0.5668, Test Acc: 0.5100, Train Loss: 0.6778, Test Loss: 0.6823\n",
      "Epoch: 240, Train Acc: 0.5970, Test Acc: 0.5250, Train Loss: 0.6758, Test Loss: 0.6809\n",
      "Epoch: 250, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6734, Test Loss: 0.6798\n",
      "Epoch: 260, Train Acc: 0.5927, Test Acc: 0.5350, Train Loss: 0.6717, Test Loss: 0.6783\n",
      "Epoch: 270, Train Acc: 0.6056, Test Acc: 0.5450, Train Loss: 0.6708, Test Loss: 0.6766\n",
      "Epoch: 280, Train Acc: 0.6272, Test Acc: 0.5600, Train Loss: 0.6680, Test Loss: 0.6748\n",
      "Epoch: 290, Train Acc: 0.6422, Test Acc: 0.5550, Train Loss: 0.6652, Test Loss: 0.6728\n",
      "Epoch: 300, Train Acc: 0.6638, Test Acc: 0.5900, Train Loss: 0.6630, Test Loss: 0.6706\n",
      "Epoch: 310, Train Acc: 0.6724, Test Acc: 0.5700, Train Loss: 0.6600, Test Loss: 0.6684\n",
      "Epoch: 320, Train Acc: 0.6810, Test Acc: 0.6300, Train Loss: 0.6566, Test Loss: 0.6656\n",
      "Epoch: 330, Train Acc: 0.7004, Test Acc: 0.6450, Train Loss: 0.6531, Test Loss: 0.6629\n",
      "Epoch: 340, Train Acc: 0.7069, Test Acc: 0.6650, Train Loss: 0.6494, Test Loss: 0.6600\n",
      "Epoch: 350, Train Acc: 0.6961, Test Acc: 0.6300, Train Loss: 0.6445, Test Loss: 0.6574\n",
      "Epoch: 360, Train Acc: 0.7284, Test Acc: 0.6750, Train Loss: 0.6417, Test Loss: 0.6537\n",
      "Epoch: 370, Train Acc: 0.7306, Test Acc: 0.6800, Train Loss: 0.6369, Test Loss: 0.6503\n",
      "Epoch: 380, Train Acc: 0.7414, Test Acc: 0.6750, Train Loss: 0.6311, Test Loss: 0.6468\n",
      "Epoch: 390, Train Acc: 0.7371, Test Acc: 0.6800, Train Loss: 0.6267, Test Loss: 0.6431\n",
      "Epoch: 400, Train Acc: 0.7543, Test Acc: 0.6750, Train Loss: 0.6225, Test Loss: 0.6396\n",
      "Epoch: 410, Train Acc: 0.7457, Test Acc: 0.7050, Train Loss: 0.6180, Test Loss: 0.6358\n",
      "Epoch: 420, Train Acc: 0.7457, Test Acc: 0.6950, Train Loss: 0.6127, Test Loss: 0.6320\n",
      "Epoch: 430, Train Acc: 0.7500, Test Acc: 0.6800, Train Loss: 0.6067, Test Loss: 0.6284\n",
      "Epoch: 440, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.6006, Test Loss: 0.6244\n",
      "Epoch: 450, Train Acc: 0.7543, Test Acc: 0.6900, Train Loss: 0.5974, Test Loss: 0.6208\n",
      "Epoch: 460, Train Acc: 0.7608, Test Acc: 0.6850, Train Loss: 0.5909, Test Loss: 0.6172\n",
      "Epoch: 470, Train Acc: 0.7629, Test Acc: 0.6850, Train Loss: 0.5866, Test Loss: 0.6137\n",
      "Epoch: 480, Train Acc: 0.7629, Test Acc: 0.6700, Train Loss: 0.5812, Test Loss: 0.6103\n",
      "Epoch: 490, Train Acc: 0.7651, Test Acc: 0.6700, Train Loss: 0.5751, Test Loss: 0.6071\n",
      "Epoch: 500, Train Acc: 0.7672, Test Acc: 0.6950, Train Loss: 0.5723, Test Loss: 0.6043\n",
      "Epoch: 510, Train Acc: 0.7716, Test Acc: 0.6750, Train Loss: 0.5651, Test Loss: 0.6012\n",
      "Epoch: 520, Train Acc: 0.7716, Test Acc: 0.6800, Train Loss: 0.5586, Test Loss: 0.5983\n",
      "Epoch: 530, Train Acc: 0.7737, Test Acc: 0.6800, Train Loss: 0.5545, Test Loss: 0.5956\n",
      "Epoch: 540, Train Acc: 0.7716, Test Acc: 0.6750, Train Loss: 0.5523, Test Loss: 0.5929\n",
      "Epoch: 550, Train Acc: 0.7759, Test Acc: 0.6850, Train Loss: 0.5493, Test Loss: 0.5909\n",
      "Epoch: 560, Train Acc: 0.7780, Test Acc: 0.6850, Train Loss: 0.5462, Test Loss: 0.5886\n",
      "Epoch: 570, Train Acc: 0.7780, Test Acc: 0.6800, Train Loss: 0.5415, Test Loss: 0.5862\n",
      "Epoch: 580, Train Acc: 0.7823, Test Acc: 0.6800, Train Loss: 0.5391, Test Loss: 0.5841\n",
      "Epoch: 590, Train Acc: 0.7823, Test Acc: 0.6850, Train Loss: 0.5339, Test Loss: 0.5823\n",
      "Epoch: 600, Train Acc: 0.7823, Test Acc: 0.6850, Train Loss: 0.5289, Test Loss: 0.5805\n",
      "Epoch: 610, Train Acc: 0.7866, Test Acc: 0.6900, Train Loss: 0.5248, Test Loss: 0.5792\n",
      "Epoch: 620, Train Acc: 0.7866, Test Acc: 0.7000, Train Loss: 0.5230, Test Loss: 0.5782\n",
      "Epoch: 630, Train Acc: 0.7866, Test Acc: 0.6900, Train Loss: 0.5199, Test Loss: 0.5765\n",
      "Epoch: 640, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5163, Test Loss: 0.5747\n",
      "Epoch: 650, Train Acc: 0.7909, Test Acc: 0.6850, Train Loss: 0.5133, Test Loss: 0.5729\n",
      "Epoch: 660, Train Acc: 0.7931, Test Acc: 0.6950, Train Loss: 0.5100, Test Loss: 0.5717\n",
      "Epoch: 670, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5085, Test Loss: 0.5707\n",
      "Epoch: 680, Train Acc: 0.7953, Test Acc: 0.6900, Train Loss: 0.5047, Test Loss: 0.5697\n",
      "Epoch: 690, Train Acc: 0.7931, Test Acc: 0.6900, Train Loss: 0.5059, Test Loss: 0.5684\n",
      "Epoch: 700, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.5007, Test Loss: 0.5679\n",
      "Epoch: 710, Train Acc: 0.7953, Test Acc: 0.7050, Train Loss: 0.4977, Test Loss: 0.5681\n",
      "Epoch: 720, Train Acc: 0.7996, Test Acc: 0.6950, Train Loss: 0.4985, Test Loss: 0.5659\n",
      "Epoch: 730, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4928, Test Loss: 0.5657\n",
      "Epoch: 740, Train Acc: 0.7996, Test Acc: 0.7100, Train Loss: 0.4920, Test Loss: 0.5650\n",
      "Epoch: 750, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4878, Test Loss: 0.5638\n",
      "Epoch: 760, Train Acc: 0.7974, Test Acc: 0.7100, Train Loss: 0.4925, Test Loss: 0.5640\n",
      "Epoch: 770, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.4881, Test Loss: 0.5613\n",
      "Epoch: 780, Train Acc: 0.8017, Test Acc: 0.7150, Train Loss: 0.4838, Test Loss: 0.5618\n",
      "Epoch: 790, Train Acc: 0.7974, Test Acc: 0.7200, Train Loss: 0.4824, Test Loss: 0.5627\n",
      "Epoch: 800, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4828, Test Loss: 0.5615\n",
      "Epoch: 810, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4800, Test Loss: 0.5589\n",
      "Epoch: 820, Train Acc: 0.8060, Test Acc: 0.7050, Train Loss: 0.4797, Test Loss: 0.5575\n",
      "Epoch: 830, Train Acc: 0.7996, Test Acc: 0.7100, Train Loss: 0.4767, Test Loss: 0.5597\n",
      "Epoch: 840, Train Acc: 0.8060, Test Acc: 0.7100, Train Loss: 0.4754, Test Loss: 0.5566\n",
      "Epoch: 850, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4749, Test Loss: 0.5567\n",
      "Epoch: 860, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4730, Test Loss: 0.5546\n",
      "Epoch: 870, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4702, Test Loss: 0.5553\n",
      "Epoch: 880, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4694, Test Loss: 0.5541\n",
      "Epoch: 890, Train Acc: 0.8060, Test Acc: 0.7250, Train Loss: 0.4696, Test Loss: 0.5531\n",
      "Epoch: 900, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4669, Test Loss: 0.5542\n",
      "Epoch: 910, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4653, Test Loss: 0.5533\n",
      "Epoch: 920, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4626, Test Loss: 0.5531\n",
      "Epoch: 930, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4603, Test Loss: 0.5530\n",
      "Epoch: 940, Train Acc: 0.8060, Test Acc: 0.7300, Train Loss: 0.4630, Test Loss: 0.5529\n",
      "Epoch: 950, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4618, Test Loss: 0.5513\n",
      "Epoch: 960, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4589, Test Loss: 0.5490\n",
      "Epoch: 970, Train Acc: 0.8147, Test Acc: 0.7300, Train Loss: 0.4597, Test Loss: 0.5495\n",
      "Epoch: 980, Train Acc: 0.8147, Test Acc: 0.7300, Train Loss: 0.4568, Test Loss: 0.5478\n",
      "Epoch: 990, Train Acc: 0.8039, Test Acc: 0.7400, Train Loss: 0.4538, Test Loss: 0.5465\n",
      "Epoch: 1000, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4537, Test Loss: 0.5461\n",
      "Epoch: 1010, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4586, Test Loss: 0.5465\n",
      "Epoch: 1020, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4529, Test Loss: 0.5463\n",
      "Epoch: 1030, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4510, Test Loss: 0.5454\n",
      "Epoch: 1040, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4498, Test Loss: 0.5454\n",
      "Epoch: 1050, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4473, Test Loss: 0.5447\n",
      "Epoch: 1060, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4499, Test Loss: 0.5459\n",
      "Epoch: 1070, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4508, Test Loss: 0.5430\n",
      "Epoch: 1080, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4488, Test Loss: 0.5428\n",
      "Epoch: 1090, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4450, Test Loss: 0.5430\n",
      "Epoch: 1100, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4460, Test Loss: 0.5440\n",
      "Epoch: 1110, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4503, Test Loss: 0.5528\n",
      "Epoch: 1120, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4453, Test Loss: 0.5413\n",
      "Epoch: 1130, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4417, Test Loss: 0.5403\n",
      "Epoch: 1140, Train Acc: 0.8190, Test Acc: 0.7350, Train Loss: 0.4425, Test Loss: 0.5404\n",
      "Epoch: 1150, Train Acc: 0.8190, Test Acc: 0.7400, Train Loss: 0.4414, Test Loss: 0.5394\n",
      "Epoch: 1160, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4424, Test Loss: 0.5399\n",
      "Epoch: 1170, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4410, Test Loss: 0.5407\n",
      "Epoch: 1180, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4370, Test Loss: 0.5411\n",
      "Epoch: 1190, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4353, Test Loss: 0.5405\n",
      "Epoch: 1200, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4390, Test Loss: 0.5390\n",
      "Epoch: 1210, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4390, Test Loss: 0.5378\n",
      "Epoch: 1220, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4301, Test Loss: 0.5388\n",
      "Epoch: 1230, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4360, Test Loss: 0.5392\n",
      "Epoch: 1240, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4327, Test Loss: 0.5426\n",
      "Epoch: 1250, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4394, Test Loss: 0.5368\n",
      "Epoch: 1260, Train Acc: 0.8190, Test Acc: 0.7400, Train Loss: 0.4312, Test Loss: 0.5367\n",
      "Epoch: 1270, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4305, Test Loss: 0.5359\n",
      "Epoch: 1280, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4315, Test Loss: 0.5348\n",
      "Epoch: 1290, Train Acc: 0.8190, Test Acc: 0.7350, Train Loss: 0.4279, Test Loss: 0.5362\n",
      "Epoch: 1300, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4312, Test Loss: 0.5342\n",
      "Epoch: 1310, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4279, Test Loss: 0.5354\n",
      "Epoch: 1320, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4240, Test Loss: 0.5353\n",
      "Epoch: 1330, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.4246, Test Loss: 0.5343\n",
      "Epoch: 1340, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4262, Test Loss: 0.5347\n",
      "Epoch: 1350, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4276, Test Loss: 0.5333\n",
      "Epoch: 1360, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.4265, Test Loss: 0.5335\n",
      "Epoch: 1370, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4247, Test Loss: 0.5355\n",
      "Epoch: 1380, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4241, Test Loss: 0.5340\n",
      "Epoch: 1390, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4239, Test Loss: 0.5333\n",
      "Epoch: 1400, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4189, Test Loss: 0.5329\n",
      "Epoch: 1410, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4211, Test Loss: 0.5344\n",
      "Epoch: 1420, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4185, Test Loss: 0.5329\n",
      "Epoch: 1430, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4197, Test Loss: 0.5308\n",
      "Epoch: 1440, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4207, Test Loss: 0.5333\n",
      "Epoch: 1450, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4162, Test Loss: 0.5310\n",
      "Epoch: 1460, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4173, Test Loss: 0.5326\n",
      "Epoch: 1470, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4150, Test Loss: 0.5317\n",
      "Epoch: 1480, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4168, Test Loss: 0.5350\n",
      "Epoch: 1490, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4144, Test Loss: 0.5313\n",
      "Epoch: 1500, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4139, Test Loss: 0.5283\n",
      "Epoch: 1510, Train Acc: 0.8319, Test Acc: 0.7450, Train Loss: 0.4113, Test Loss: 0.5293\n",
      "Epoch: 1520, Train Acc: 0.8319, Test Acc: 0.7450, Train Loss: 0.4166, Test Loss: 0.5293\n",
      "Epoch: 1530, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4124, Test Loss: 0.5310\n",
      "Epoch: 1540, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4101, Test Loss: 0.5341\n",
      "Epoch: 1550, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4130, Test Loss: 0.5315\n",
      "Epoch: 1560, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4109, Test Loss: 0.5295\n",
      "Epoch: 1570, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4088, Test Loss: 0.5318\n",
      "Epoch: 1580, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4100, Test Loss: 0.5306\n",
      "Epoch: 1590, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4082, Test Loss: 0.5291\n",
      "Epoch: 1600, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4094, Test Loss: 0.5287\n",
      "Epoch: 1610, Train Acc: 0.8362, Test Acc: 0.7450, Train Loss: 0.4083, Test Loss: 0.5277\n",
      "Epoch: 1620, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4095, Test Loss: 0.5302\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▂▁▁▃▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Test F1</td><td>▂▂▂▂▂▁▁▂▃▃▃▃▁▁▂▃▃▂▄▃▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█▇█▇</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>█████▇▇▆▄▃▂▂▁▁▁▂▂▁▃▁▂▃▃▃▂▃▂▃▂▃▃▃▃▃▄▄▄▄▄▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▂▂▁▃▅▆▇▇▇▇▇█▇█▇█▇▇▇████▇██████▇█▇███</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▃▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████▇███████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▂▂▂▃▄▄▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>███████▇▇▆▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██▇█▇▇▇▆▄▂▂▁▁▂▂▂▂▂▃▂▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▂▃▆▇▇▇████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.755</td></tr><tr><td>Test F1</td><td>0.76555</td></tr><tr><td>Test Loss</td><td>0.52941</td></tr><tr><td>Test Sensitivity</td><td>0.7767</td></tr><tr><td>Test Specificity</td><td>0.73196</td></tr><tr><td>Train Accuracy</td><td>0.83405</td></tr><tr><td>Train F1</td><td>0.83992</td></tr><tr><td>Train Loss</td><td>0.40536</td></tr><tr><td>Train Sensitivity</td><td>0.82114</td></tr><tr><td>Train Specificity</td><td>0.84862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-sweep-41</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/gjwttk22' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/gjwttk22</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_190823-gjwttk22/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2nir3rvt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.6826036579418484e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.661364694006566e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_191534-2nir3rvt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/2nir3rvt' target=\"_blank\">glad-sweep-42</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2nir3rvt' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2nir3rvt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6931\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6920\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6920\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6894, Test Loss: 0.6914\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6914\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6908\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6906\n",
      "Epoch: 090, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6904\n",
      "Epoch: 100, Train Acc: 0.5431, Test Acc: 0.5200, Train Loss: 0.6873, Test Loss: 0.6898\n",
      "Epoch: 110, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6869, Test Loss: 0.6896\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6872, Test Loss: 0.6895\n",
      "Epoch: 130, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6861, Test Loss: 0.6889\n",
      "Epoch: 140, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 150, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6846, Test Loss: 0.6883\n",
      "Epoch: 160, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6837, Test Loss: 0.6875\n",
      "Epoch: 170, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6830, Test Loss: 0.6872\n",
      "Epoch: 180, Train Acc: 0.5560, Test Acc: 0.5150, Train Loss: 0.6825, Test Loss: 0.6865\n",
      "Epoch: 190, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6823, Test Loss: 0.6861\n",
      "Epoch: 200, Train Acc: 0.5647, Test Acc: 0.5100, Train Loss: 0.6816, Test Loss: 0.6852\n",
      "Epoch: 210, Train Acc: 0.5474, Test Acc: 0.5100, Train Loss: 0.6804, Test Loss: 0.6847\n",
      "Epoch: 220, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6787, Test Loss: 0.6832\n",
      "Epoch: 230, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6785, Test Loss: 0.6828\n",
      "Epoch: 240, Train Acc: 0.5948, Test Acc: 0.5350, Train Loss: 0.6766, Test Loss: 0.6812\n",
      "Epoch: 250, Train Acc: 0.5884, Test Acc: 0.5250, Train Loss: 0.6743, Test Loss: 0.6803\n",
      "Epoch: 260, Train Acc: 0.5862, Test Acc: 0.5250, Train Loss: 0.6727, Test Loss: 0.6790\n",
      "Epoch: 270, Train Acc: 0.6164, Test Acc: 0.5500, Train Loss: 0.6719, Test Loss: 0.6771\n",
      "Epoch: 280, Train Acc: 0.6099, Test Acc: 0.5550, Train Loss: 0.6692, Test Loss: 0.6756\n",
      "Epoch: 290, Train Acc: 0.6315, Test Acc: 0.5650, Train Loss: 0.6664, Test Loss: 0.6737\n",
      "Epoch: 300, Train Acc: 0.6573, Test Acc: 0.5950, Train Loss: 0.6643, Test Loss: 0.6714\n",
      "Epoch: 310, Train Acc: 0.6530, Test Acc: 0.5750, Train Loss: 0.6614, Test Loss: 0.6694\n",
      "Epoch: 320, Train Acc: 0.6724, Test Acc: 0.6300, Train Loss: 0.6581, Test Loss: 0.6666\n",
      "Epoch: 330, Train Acc: 0.6961, Test Acc: 0.6500, Train Loss: 0.6546, Test Loss: 0.6640\n",
      "Epoch: 340, Train Acc: 0.7091, Test Acc: 0.6400, Train Loss: 0.6512, Test Loss: 0.6612\n",
      "Epoch: 350, Train Acc: 0.6983, Test Acc: 0.6200, Train Loss: 0.6464, Test Loss: 0.6587\n",
      "Epoch: 360, Train Acc: 0.7241, Test Acc: 0.6800, Train Loss: 0.6438, Test Loss: 0.6549\n",
      "Epoch: 370, Train Acc: 0.7349, Test Acc: 0.6850, Train Loss: 0.6391, Test Loss: 0.6516\n",
      "Epoch: 380, Train Acc: 0.7392, Test Acc: 0.6650, Train Loss: 0.6333, Test Loss: 0.6482\n",
      "Epoch: 390, Train Acc: 0.7371, Test Acc: 0.6800, Train Loss: 0.6291, Test Loss: 0.6445\n",
      "Epoch: 400, Train Acc: 0.7478, Test Acc: 0.6800, Train Loss: 0.6249, Test Loss: 0.6409\n",
      "Epoch: 410, Train Acc: 0.7478, Test Acc: 0.7050, Train Loss: 0.6204, Test Loss: 0.6371\n",
      "Epoch: 420, Train Acc: 0.7435, Test Acc: 0.6950, Train Loss: 0.6152, Test Loss: 0.6333\n",
      "Epoch: 430, Train Acc: 0.7500, Test Acc: 0.6850, Train Loss: 0.6093, Test Loss: 0.6296\n",
      "Epoch: 440, Train Acc: 0.7586, Test Acc: 0.7000, Train Loss: 0.6031, Test Loss: 0.6257\n",
      "Epoch: 450, Train Acc: 0.7500, Test Acc: 0.6850, Train Loss: 0.6002, Test Loss: 0.6220\n",
      "Epoch: 460, Train Acc: 0.7586, Test Acc: 0.6950, Train Loss: 0.5931, Test Loss: 0.6183\n",
      "Epoch: 470, Train Acc: 0.7629, Test Acc: 0.6650, Train Loss: 0.5892, Test Loss: 0.6146\n",
      "Epoch: 480, Train Acc: 0.7672, Test Acc: 0.6800, Train Loss: 0.5834, Test Loss: 0.6111\n",
      "Epoch: 490, Train Acc: 0.7694, Test Acc: 0.6700, Train Loss: 0.5774, Test Loss: 0.6079\n",
      "Epoch: 500, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5746, Test Loss: 0.6047\n",
      "Epoch: 510, Train Acc: 0.7716, Test Acc: 0.6650, Train Loss: 0.5675, Test Loss: 0.6016\n",
      "Epoch: 520, Train Acc: 0.7716, Test Acc: 0.6650, Train Loss: 0.5608, Test Loss: 0.5986\n",
      "Epoch: 530, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5564, Test Loss: 0.5958\n",
      "Epoch: 540, Train Acc: 0.7716, Test Acc: 0.6750, Train Loss: 0.5541, Test Loss: 0.5930\n",
      "Epoch: 550, Train Acc: 0.7780, Test Acc: 0.6900, Train Loss: 0.5507, Test Loss: 0.5909\n",
      "Epoch: 560, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5477, Test Loss: 0.5883\n",
      "Epoch: 570, Train Acc: 0.7823, Test Acc: 0.6900, Train Loss: 0.5423, Test Loss: 0.5859\n",
      "Epoch: 580, Train Acc: 0.7780, Test Acc: 0.6850, Train Loss: 0.5400, Test Loss: 0.5837\n",
      "Epoch: 590, Train Acc: 0.7780, Test Acc: 0.6850, Train Loss: 0.5351, Test Loss: 0.5817\n",
      "Epoch: 600, Train Acc: 0.7823, Test Acc: 0.6850, Train Loss: 0.5297, Test Loss: 0.5798\n",
      "Epoch: 610, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.5255, Test Loss: 0.5785\n",
      "Epoch: 620, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.5235, Test Loss: 0.5772\n",
      "Epoch: 630, Train Acc: 0.7974, Test Acc: 0.6950, Train Loss: 0.5203, Test Loss: 0.5758\n",
      "Epoch: 640, Train Acc: 0.7931, Test Acc: 0.6900, Train Loss: 0.5167, Test Loss: 0.5735\n",
      "Epoch: 650, Train Acc: 0.7888, Test Acc: 0.6900, Train Loss: 0.5132, Test Loss: 0.5718\n",
      "Epoch: 660, Train Acc: 0.7953, Test Acc: 0.7000, Train Loss: 0.5097, Test Loss: 0.5709\n",
      "Epoch: 670, Train Acc: 0.7931, Test Acc: 0.7050, Train Loss: 0.5081, Test Loss: 0.5695\n",
      "Epoch: 680, Train Acc: 0.7953, Test Acc: 0.6950, Train Loss: 0.5043, Test Loss: 0.5683\n",
      "Epoch: 690, Train Acc: 0.7953, Test Acc: 0.6900, Train Loss: 0.5054, Test Loss: 0.5669\n",
      "Epoch: 700, Train Acc: 0.8017, Test Acc: 0.6950, Train Loss: 0.4999, Test Loss: 0.5669\n",
      "Epoch: 710, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4968, Test Loss: 0.5661\n",
      "Epoch: 720, Train Acc: 0.8039, Test Acc: 0.6950, Train Loss: 0.4976, Test Loss: 0.5646\n",
      "Epoch: 730, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4919, Test Loss: 0.5639\n",
      "Epoch: 740, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4910, Test Loss: 0.5633\n",
      "Epoch: 750, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4866, Test Loss: 0.5621\n",
      "Epoch: 760, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4912, Test Loss: 0.5619\n",
      "Epoch: 770, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.4869, Test Loss: 0.5592\n",
      "Epoch: 780, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4825, Test Loss: 0.5598\n",
      "Epoch: 790, Train Acc: 0.7931, Test Acc: 0.7300, Train Loss: 0.4812, Test Loss: 0.5614\n",
      "Epoch: 800, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4813, Test Loss: 0.5597\n",
      "Epoch: 810, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4783, Test Loss: 0.5573\n",
      "Epoch: 820, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4777, Test Loss: 0.5556\n",
      "Epoch: 830, Train Acc: 0.7974, Test Acc: 0.7200, Train Loss: 0.4750, Test Loss: 0.5581\n",
      "Epoch: 840, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4734, Test Loss: 0.5547\n",
      "Epoch: 850, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4729, Test Loss: 0.5545\n",
      "Epoch: 860, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4710, Test Loss: 0.5522\n",
      "Epoch: 870, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4681, Test Loss: 0.5529\n",
      "Epoch: 880, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4673, Test Loss: 0.5514\n",
      "Epoch: 890, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4674, Test Loss: 0.5507\n",
      "Epoch: 900, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4646, Test Loss: 0.5519\n",
      "Epoch: 910, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4630, Test Loss: 0.5517\n",
      "Epoch: 920, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4601, Test Loss: 0.5502\n",
      "Epoch: 930, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4578, Test Loss: 0.5499\n",
      "Epoch: 940, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4605, Test Loss: 0.5508\n",
      "Epoch: 950, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4592, Test Loss: 0.5495\n",
      "Epoch: 960, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4562, Test Loss: 0.5465\n",
      "Epoch: 970, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4570, Test Loss: 0.5471\n",
      "Epoch: 980, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4542, Test Loss: 0.5450\n",
      "Epoch: 990, Train Acc: 0.7996, Test Acc: 0.7400, Train Loss: 0.4513, Test Loss: 0.5439\n",
      "Epoch: 1000, Train Acc: 0.7996, Test Acc: 0.7400, Train Loss: 0.4511, Test Loss: 0.5433\n",
      "Epoch: 1010, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4559, Test Loss: 0.5434\n",
      "Epoch: 1020, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4498, Test Loss: 0.5434\n",
      "Epoch: 1030, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4480, Test Loss: 0.5424\n",
      "Epoch: 1040, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4465, Test Loss: 0.5427\n",
      "Epoch: 1050, Train Acc: 0.8147, Test Acc: 0.7350, Train Loss: 0.4438, Test Loss: 0.5421\n",
      "Epoch: 1060, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4466, Test Loss: 0.5421\n",
      "Epoch: 1070, Train Acc: 0.8082, Test Acc: 0.7500, Train Loss: 0.4485, Test Loss: 0.5396\n",
      "Epoch: 1080, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4459, Test Loss: 0.5394\n",
      "Epoch: 1090, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4417, Test Loss: 0.5399\n",
      "Epoch: 1100, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4425, Test Loss: 0.5404\n",
      "Epoch: 1110, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4470, Test Loss: 0.5504\n",
      "Epoch: 1120, Train Acc: 0.8168, Test Acc: 0.7400, Train Loss: 0.4416, Test Loss: 0.5380\n",
      "Epoch: 1130, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4383, Test Loss: 0.5369\n",
      "Epoch: 1140, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4391, Test Loss: 0.5368\n",
      "Epoch: 1150, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4384, Test Loss: 0.5357\n",
      "Epoch: 1160, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4385, Test Loss: 0.5365\n",
      "Epoch: 1170, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4372, Test Loss: 0.5374\n",
      "Epoch: 1180, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4330, Test Loss: 0.5379\n",
      "Epoch: 1190, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4313, Test Loss: 0.5366\n",
      "Epoch: 1200, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4351, Test Loss: 0.5357\n",
      "Epoch: 1210, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4357, Test Loss: 0.5340\n",
      "Epoch: 1220, Train Acc: 0.8190, Test Acc: 0.7450, Train Loss: 0.4260, Test Loss: 0.5350\n",
      "Epoch: 1230, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4320, Test Loss: 0.5352\n",
      "Epoch: 1240, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4282, Test Loss: 0.5391\n",
      "Epoch: 1250, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4351, Test Loss: 0.5334\n",
      "Epoch: 1260, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4270, Test Loss: 0.5331\n",
      "Epoch: 1270, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.4261, Test Loss: 0.5327\n",
      "Epoch: 1280, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4282, Test Loss: 0.5309\n",
      "Epoch: 1290, Train Acc: 0.8168, Test Acc: 0.7450, Train Loss: 0.4234, Test Loss: 0.5335\n",
      "Epoch: 1300, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4272, Test Loss: 0.5307\n",
      "Epoch: 1310, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4234, Test Loss: 0.5320\n",
      "Epoch: 1320, Train Acc: 0.8211, Test Acc: 0.7500, Train Loss: 0.4194, Test Loss: 0.5322\n",
      "Epoch: 1330, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4199, Test Loss: 0.5312\n",
      "Epoch: 1340, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4214, Test Loss: 0.5325\n",
      "Epoch: 1350, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4235, Test Loss: 0.5297\n",
      "Epoch: 1360, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4217, Test Loss: 0.5304\n",
      "Epoch: 1370, Train Acc: 0.8233, Test Acc: 0.7500, Train Loss: 0.4202, Test Loss: 0.5318\n",
      "Epoch: 1380, Train Acc: 0.8254, Test Acc: 0.7450, Train Loss: 0.4196, Test Loss: 0.5302\n",
      "Epoch: 1390, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4196, Test Loss: 0.5295\n",
      "Epoch: 1400, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4145, Test Loss: 0.5292\n",
      "Epoch: 1410, Train Acc: 0.8254, Test Acc: 0.7550, Train Loss: 0.4165, Test Loss: 0.5302\n",
      "Epoch: 1420, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4138, Test Loss: 0.5298\n",
      "Epoch: 1430, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4146, Test Loss: 0.5281\n",
      "Epoch: 1440, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4161, Test Loss: 0.5298\n",
      "Epoch: 1450, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4113, Test Loss: 0.5282\n",
      "Epoch: 1460, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4125, Test Loss: 0.5294\n",
      "Epoch: 1470, Train Acc: 0.8276, Test Acc: 0.7550, Train Loss: 0.4101, Test Loss: 0.5284\n",
      "Epoch: 1480, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4117, Test Loss: 0.5321\n",
      "Epoch: 1490, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4092, Test Loss: 0.5299\n",
      "Epoch: 1500, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4085, Test Loss: 0.5256\n",
      "Epoch: 1510, Train Acc: 0.8297, Test Acc: 0.7550, Train Loss: 0.4069, Test Loss: 0.5260\n",
      "Epoch: 1520, Train Acc: 0.8341, Test Acc: 0.7500, Train Loss: 0.4116, Test Loss: 0.5267\n",
      "Epoch: 1530, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4072, Test Loss: 0.5282\n",
      "Epoch: 1540, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4050, Test Loss: 0.5317\n",
      "Epoch: 1550, Train Acc: 0.8297, Test Acc: 0.7650, Train Loss: 0.4077, Test Loss: 0.5295\n",
      "Epoch: 1560, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4052, Test Loss: 0.5288\n",
      "Epoch: 1570, Train Acc: 0.8276, Test Acc: 0.7650, Train Loss: 0.4039, Test Loss: 0.5313\n",
      "Epoch: 1580, Train Acc: 0.8319, Test Acc: 0.7550, Train Loss: 0.4046, Test Loss: 0.5281\n",
      "Epoch: 1590, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4036, Test Loss: 0.5258\n",
      "Epoch: 1600, Train Acc: 0.8341, Test Acc: 0.7550, Train Loss: 0.4041, Test Loss: 0.5260\n",
      "Epoch: 1610, Train Acc: 0.8384, Test Acc: 0.7550, Train Loss: 0.4030, Test Loss: 0.5253\n",
      "Epoch: 1620, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4040, Test Loss: 0.5295\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▃▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>Test F1</td><td>▂▂▂▂▁▁▁▂▃▃▃▃▁▁▂▃▃▂▅▃▄▅▆▆▆▆▆▇▆▇▇▇▇▇▇█████</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▇▆▄▃▃▂▁▁▁▂▂▁▃▁▂▃▃▃▃▃▃▃▂▃▃▃▃▃▄▄▄▄▄▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▃▅▆▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇█████▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▃▅▆▆▆▆▇▇▇▇▇▇▇▇█▇███▇█▇███████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▂▂▂▃▃▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>████▇█▇▆▃▂▂▁▁▁▂▂▂▂▃▁▂▃▃▃▃▃▂▃▂▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▂▃▆▇▇▇████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.755</td></tr><tr><td>Test F1</td><td>0.76777</td></tr><tr><td>Test Loss</td><td>0.52792</td></tr><tr><td>Test Sensitivity</td><td>0.78641</td></tr><tr><td>Test Specificity</td><td>0.72165</td></tr><tr><td>Train Accuracy</td><td>0.83405</td></tr><tr><td>Train F1</td><td>0.84058</td></tr><tr><td>Train Loss</td><td>0.39981</td></tr><tr><td>Train Sensitivity</td><td>0.8252</td></tr><tr><td>Train Specificity</td><td>0.84404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-42</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2nir3rvt' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2nir3rvt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_191534-2nir3rvt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h54ywdsn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007207192906989493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005419868990521047\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_192246-h54ywdsn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/h54ywdsn' target=\"_blank\">trim-sweep-43</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/h54ywdsn' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/h54ywdsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6929\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6926\n",
      "Epoch: 020, Train Acc: 0.4935, Test Acc: 0.5200, Train Loss: 0.6928, Test Loss: 0.6900\n",
      "Epoch: 030, Train Acc: 0.6422, Test Acc: 0.6250, Train Loss: 0.6722, Test Loss: 0.6717\n",
      "Epoch: 040, Train Acc: 0.5862, Test Acc: 0.6100, Train Loss: 0.6308, Test Loss: 0.6387\n",
      "Epoch: 050, Train Acc: 0.7091, Test Acc: 0.6500, Train Loss: 0.5496, Test Loss: 0.5810\n",
      "Epoch: 060, Train Acc: 0.6509, Test Acc: 0.6450, Train Loss: 0.6314, Test Loss: 0.6676\n",
      "Epoch: 070, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.4855, Test Loss: 0.5502\n",
      "Epoch: 080, Train Acc: 0.7694, Test Acc: 0.7050, Train Loss: 0.4978, Test Loss: 0.5583\n",
      "Epoch: 090, Train Acc: 0.6336, Test Acc: 0.6600, Train Loss: 0.7922, Test Loss: 0.8253\n",
      "Epoch: 100, Train Acc: 0.7802, Test Acc: 0.7300, Train Loss: 0.4850, Test Loss: 0.5402\n",
      "Epoch: 110, Train Acc: 0.8254, Test Acc: 0.7750, Train Loss: 0.4233, Test Loss: 0.5086\n",
      "Epoch: 120, Train Acc: 0.7694, Test Acc: 0.7250, Train Loss: 0.5121, Test Loss: 0.5815\n",
      "Epoch: 130, Train Acc: 0.6810, Test Acc: 0.7150, Train Loss: 0.6938, Test Loss: 0.7383\n",
      "Epoch: 140, Train Acc: 0.6918, Test Acc: 0.7050, Train Loss: 0.6644, Test Loss: 0.7366\n",
      "Epoch: 150, Train Acc: 0.8491, Test Acc: 0.8050, Train Loss: 0.3764, Test Loss: 0.5116\n",
      "Epoch: 160, Train Acc: 0.7241, Test Acc: 0.6350, Train Loss: 0.5155, Test Loss: 0.7173\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▁▁▂▂▃▄▃▃▄▅▄▇▅▄▇▆▆▇▆▆▆▆▆▇▆▇██▇▇▇▇▄▆▇▇▇▇</td></tr><tr><td>Test F1</td><td>▁▇▇▁▇▃▇▅▄▄▅▆▅▇▇▅▇▆▇▇▆▇▇▆█▇▆▇██▇▇▇▇▅▆▇▇▇▇</td></tr><tr><td>Test Loss</td><td>▃▃▃▃▃▃▃▃▃▃▃▂▄▂▂▄▁▃▂▂▃▂▂▃▂▁▄▂▁▁▂▄▂▄█▅▃▂▃▂</td></tr><tr><td>Test Sensitivity</td><td>▁█▆▁█▂▆▃▂▂▃▄▃▆▅▃▆▄▄▅▄▅▅▄▇▅▄▅▆▆▅▄▅▅▃▄▅▅▅▅</td></tr><tr><td>Test Specificity</td><td>█▁▃█▁█▄████▇█▆▇█▇▇▇██▇▇█▅▇█▇▇▇▇█▇████▇█▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▁▂▂▃▃▂▃▃▆▃▇▆▄▇▅▆▆▅▆▇▅▇▇▅▇██▇▅▇▅▃▅▆▇▆█</td></tr><tr><td>Train F1</td><td>▁▇▆▁▇▃▆▄▃▄▅▇▄█▇▅█▆▇▇▆▇▇▆█▇▆▇██▇▆▇▆▄▆▆▇▆█</td></tr><tr><td>Train Loss</td><td>▄▄▄▄▄▄▄▄▄▄▃▃▄▂▂▄▂▃▂▃▃▂▂▄▂▂▄▂▁▁▂▄▂▄█▅▃▂▃▂</td></tr><tr><td>Train Sensitivity</td><td>▁█▆▁█▂▆▃▂▂▃▅▃▆▅▃▆▄▅▅▄▅▅▄▇▅▄▅▇▇▅▄▅▄▃▄▄▅▄▆</td></tr><tr><td>Train Specificity</td><td>█▁▃█▁█▄████▇█▇▇█▇███████▆███▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.635</td></tr><tr><td>Test F1</td><td>0.71815</td></tr><tr><td>Test Loss</td><td>0.71727</td></tr><tr><td>Test Sensitivity</td><td>0.90291</td></tr><tr><td>Test Specificity</td><td>0.35052</td></tr><tr><td>Train Accuracy</td><td>0.72414</td></tr><tr><td>Train F1</td><td>0.78305</td></tr><tr><td>Train Loss</td><td>0.51548</td></tr><tr><td>Train Sensitivity</td><td>0.93902</td></tr><tr><td>Train Specificity</td><td>0.48165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-43</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/h54ywdsn' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/h54ywdsn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_192246-h54ywdsn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9uvwgnrx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00024405769594921132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.772063178292535e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_192353-9uvwgnrx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/9uvwgnrx' target=\"_blank\">helpful-sweep-44</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/9uvwgnrx' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/9uvwgnrx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6922, Test Loss: 0.6927\n",
      "Epoch: 010, Train Acc: 0.5431, Test Acc: 0.5050, Train Loss: 0.6906, Test Loss: 0.6911\n",
      "Epoch: 020, Train Acc: 0.5948, Test Acc: 0.6000, Train Loss: 0.6858, Test Loss: 0.6862\n",
      "Epoch: 030, Train Acc: 0.6293, Test Acc: 0.6400, Train Loss: 0.6711, Test Loss: 0.6729\n",
      "Epoch: 040, Train Acc: 0.7155, Test Acc: 0.6850, Train Loss: 0.6387, Test Loss: 0.6467\n",
      "Epoch: 050, Train Acc: 0.6767, Test Acc: 0.6400, Train Loss: 0.6076, Test Loss: 0.6208\n",
      "Epoch: 060, Train Acc: 0.7004, Test Acc: 0.6550, Train Loss: 0.5678, Test Loss: 0.5953\n",
      "Epoch: 070, Train Acc: 0.7371, Test Acc: 0.6700, Train Loss: 0.5218, Test Loss: 0.5697\n",
      "Epoch: 080, Train Acc: 0.7522, Test Acc: 0.6800, Train Loss: 0.5080, Test Loss: 0.5662\n",
      "Epoch: 090, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.4963, Test Loss: 0.5568\n",
      "Epoch: 100, Train Acc: 0.6573, Test Acc: 0.6600, Train Loss: 0.6471, Test Loss: 0.6820\n",
      "Epoch: 110, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4687, Test Loss: 0.5392\n",
      "Epoch: 120, Train Acc: 0.7069, Test Acc: 0.7050, Train Loss: 0.5828, Test Loss: 0.6358\n",
      "Epoch: 130, Train Acc: 0.6616, Test Acc: 0.6750, Train Loss: 0.6797, Test Loss: 0.7153\n",
      "Epoch: 140, Train Acc: 0.7565, Test Acc: 0.7200, Train Loss: 0.5260, Test Loss: 0.5947\n",
      "Epoch: 150, Train Acc: 0.7845, Test Acc: 0.7250, Train Loss: 0.4856, Test Loss: 0.5644\n",
      "Epoch: 160, Train Acc: 0.7522, Test Acc: 0.7150, Train Loss: 0.5374, Test Loss: 0.6050\n",
      "Epoch: 170, Train Acc: 0.7586, Test Acc: 0.7250, Train Loss: 0.5265, Test Loss: 0.5984\n",
      "Epoch: 180, Train Acc: 0.8254, Test Acc: 0.7950, Train Loss: 0.3917, Test Loss: 0.5148\n",
      "Epoch: 190, Train Acc: 0.7716, Test Acc: 0.7300, Train Loss: 0.5019, Test Loss: 0.5834\n",
      "Epoch: 200, Train Acc: 0.7866, Test Acc: 0.7350, Train Loss: 0.4870, Test Loss: 0.5792\n",
      "Epoch: 210, Train Acc: 0.6703, Test Acc: 0.6900, Train Loss: 0.7510, Test Loss: 0.8033\n",
      "Epoch: 220, Train Acc: 0.8448, Test Acc: 0.7850, Train Loss: 0.3761, Test Loss: 0.5184\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▄▅▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇█▇▇▇▅▆▆▃▇█▇</td></tr><tr><td>Test F1</td><td>▁▇▅▃▂▅▇▅▆▅▇▆▆▆▆▆▇▇▇▇▆▇▇█▇▇█▇▇█▇▇█▇▇▇▇▇██</td></tr><tr><td>Test Loss</td><td>▆▆▆▅▅▅▅▄▄▄▃▃▃▃▄▃▂▂▂▂▄▂▂▁▂▂▁▃▁▁▁▁▁▄▅▅█▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁█▄▂▁▃▆▄▄▃▅▄▄▄▄▄▅▆▅▅▄▅▅▆▅▅▆▅▅▆▅▅▆▇▅▅▇▅▆▆</td></tr><tr><td>Test Specificity</td><td>█▁▅███▅▇▇█▇▇▇▇▇▇▇▆▇▇█▇▇▆▇▇▇▇▇▇▇▇▇▄██▃▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▁▃▅▄▅▄▆▆▆▆▅▆▇▇▇▇▅▇▇▇▇▇█▇▇█▇▇█▆▆▅▄▇██</td></tr><tr><td>Train F1</td><td>▁▇▅▃▂▄▇▆▆▅▇▇▇▆▆▆▇██▇▆▇▇█▇▇█▇██████▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>██████▇▇▆▆▅▅▄▅▅▅▃▃▃▃▆▃▃▂▃▃▂▄▂▂▂▂▁▃▆▆▆▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁█▄▂▁▃▆▄▅▃▅▅▅▅▄▅▆▇▆▆▄▅▆▇▆▆▇▅▆▇▆▆▇▇▄▄█▆▇▆</td></tr><tr><td>Train Specificity</td><td>█▁▅███▆▇▇█▇▇▇▇██▇▆▇▇███▇██▇█▇▇██▇▅██▃█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.76</td></tr><tr><td>Test F1</td><td>0.73913</td></tr><tr><td>Test Loss</td><td>0.52479</td></tr><tr><td>Test Sensitivity</td><td>0.66019</td></tr><tr><td>Test Specificity</td><td>0.86598</td></tr><tr><td>Train Accuracy</td><td>0.83836</td></tr><tr><td>Train F1</td><td>0.8307</td></tr><tr><td>Train Loss</td><td>0.39298</td></tr><tr><td>Train Sensitivity</td><td>0.74797</td></tr><tr><td>Train Specificity</td><td>0.94037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-44</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/9uvwgnrx' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/9uvwgnrx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_192353-9uvwgnrx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: elzp0jve with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.5226042047229e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001335245950331941\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_192525-elzp0jve</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/elzp0jve' target=\"_blank\">likely-sweep-45</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/elzp0jve' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/elzp0jve</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5172, Test Acc: 0.4800, Train Loss: 0.6929, Test Loss: 0.6934\n",
      "Epoch: 020, Train Acc: 0.4569, Test Acc: 0.4950, Train Loss: 0.6937, Test Loss: 0.6939\n",
      "Epoch: 030, Train Acc: 0.4849, Test Acc: 0.4900, Train Loss: 0.6935, Test Loss: 0.6938\n",
      "Epoch: 040, Train Acc: 0.5022, Test Acc: 0.4550, Train Loss: 0.6930, Test Loss: 0.6935\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5050, Train Loss: 0.6927, Test Loss: 0.6934\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██████▇▇▁▁▇▆▇▆▅▆▅▇▇▆▇▆▅▅▅▅▃▂▅▁▂▂▄▅▆▇▇▇▇▇</td></tr><tr><td>Test F1</td><td>████████▇▆▅▃▃▂▁▁▁▂▂▂▃▄▄▄▅▅▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Test Loss</td><td>▄▃▂▁▁▁▃▃▅▆▆▇▇████████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄</td></tr><tr><td>Test Sensitivity</td><td>████████▆▅▄▂▂▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆▆▆▇▇▇▇██████</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▂▃▅▇▇██████▇▇▆▆▆▅▅▃▃▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>████████▅▃▃▄▃▃▂▁▂▂▃▃▄▄▄▄▄▄▃▅▄▅▅▆▆▇██▇███</td></tr><tr><td>Train F1</td><td>████████▇▆▅▃▃▂▁▁▂▂▂▃▃▄▄▄▅▅▆▆▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>▁▁▂▂▂▄▅▅▆▇▇▇█████████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▅</td></tr><tr><td>Train Sensitivity</td><td>████████▇▅▃▂▂▁▁▁▁▁▂▂▂▃▃▃▄▄▅▅▆▇▇▇▇███████</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▂▄▆▇▇██████▇▇▇▇▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.505</td></tr><tr><td>Test F1</td><td>0.6711</td></tr><tr><td>Test Loss</td><td>0.69332</td></tr><tr><td>Test Sensitivity</td><td>0.98058</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.52802</td></tr><tr><td>Train F1</td><td>0.69024</td></tr><tr><td>Train Loss</td><td>0.69255</td></tr><tr><td>Train Sensitivity</td><td>0.99187</td></tr><tr><td>Train Specificity</td><td>0.00459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-45</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/elzp0jve' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/elzp0jve</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_192525-elzp0jve/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eux08dk0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.5853019752240393e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.585720201375238e-07\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_192550-eux08dk0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/eux08dk0' target=\"_blank\">logical-sweep-46</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/eux08dk0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/eux08dk0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6961, Test Loss: 0.6950\n",
      "Epoch: 010, Train Acc: 0.5388, Test Acc: 0.5000, Train Loss: 0.6930, Test Loss: 0.6931\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6911, Test Loss: 0.6926\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6923\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6921\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6918\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6917\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6913\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6890, Test Loss: 0.6911\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6908\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6907\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6883, Test Loss: 0.6907\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6878, Test Loss: 0.6904\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6904\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6900\n",
      "Epoch: 150, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6896\n",
      "Epoch: 160, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6895\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6894\n",
      "Epoch: 180, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6858, Test Loss: 0.6891\n",
      "Epoch: 190, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6861, Test Loss: 0.6890\n",
      "Epoch: 200, Train Acc: 0.5409, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6885\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6884\n",
      "Epoch: 220, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6879\n",
      "Epoch: 230, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6845, Test Loss: 0.6876\n",
      "Epoch: 240, Train Acc: 0.5582, Test Acc: 0.5250, Train Loss: 0.6839, Test Loss: 0.6871\n",
      "Epoch: 250, Train Acc: 0.5625, Test Acc: 0.5200, Train Loss: 0.6838, Test Loss: 0.6867\n",
      "Epoch: 260, Train Acc: 0.5647, Test Acc: 0.5150, Train Loss: 0.6828, Test Loss: 0.6863\n",
      "Epoch: 270, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6833, Test Loss: 0.6858\n",
      "Epoch: 280, Train Acc: 0.5841, Test Acc: 0.5250, Train Loss: 0.6817, Test Loss: 0.6853\n",
      "Epoch: 290, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6813, Test Loss: 0.6849\n",
      "Epoch: 300, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6805, Test Loss: 0.6846\n",
      "Epoch: 310, Train Acc: 0.5690, Test Acc: 0.5150, Train Loss: 0.6801, Test Loss: 0.6839\n",
      "Epoch: 320, Train Acc: 0.5905, Test Acc: 0.5250, Train Loss: 0.6790, Test Loss: 0.6831\n",
      "Epoch: 330, Train Acc: 0.5905, Test Acc: 0.5300, Train Loss: 0.6787, Test Loss: 0.6824\n",
      "Epoch: 340, Train Acc: 0.5948, Test Acc: 0.5300, Train Loss: 0.6771, Test Loss: 0.6817\n",
      "Epoch: 350, Train Acc: 0.5711, Test Acc: 0.5150, Train Loss: 0.6766, Test Loss: 0.6813\n",
      "Epoch: 360, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6752, Test Loss: 0.6800\n",
      "Epoch: 370, Train Acc: 0.5690, Test Acc: 0.5200, Train Loss: 0.6741, Test Loss: 0.6798\n",
      "Epoch: 380, Train Acc: 0.6078, Test Acc: 0.5500, Train Loss: 0.6727, Test Loss: 0.6783\n",
      "Epoch: 390, Train Acc: 0.6078, Test Acc: 0.5450, Train Loss: 0.6718, Test Loss: 0.6774\n",
      "Epoch: 400, Train Acc: 0.6078, Test Acc: 0.5400, Train Loss: 0.6709, Test Loss: 0.6765\n",
      "Epoch: 410, Train Acc: 0.6185, Test Acc: 0.5600, Train Loss: 0.6697, Test Loss: 0.6751\n",
      "Epoch: 420, Train Acc: 0.6142, Test Acc: 0.5450, Train Loss: 0.6676, Test Loss: 0.6741\n",
      "Epoch: 430, Train Acc: 0.6379, Test Acc: 0.5650, Train Loss: 0.6661, Test Loss: 0.6726\n",
      "Epoch: 440, Train Acc: 0.6164, Test Acc: 0.5600, Train Loss: 0.6648, Test Loss: 0.6717\n",
      "Epoch: 450, Train Acc: 0.6315, Test Acc: 0.5750, Train Loss: 0.6624, Test Loss: 0.6701\n",
      "Epoch: 460, Train Acc: 0.6466, Test Acc: 0.5800, Train Loss: 0.6608, Test Loss: 0.6685\n",
      "Epoch: 470, Train Acc: 0.6659, Test Acc: 0.6000, Train Loss: 0.6593, Test Loss: 0.6667\n",
      "Epoch: 480, Train Acc: 0.6659, Test Acc: 0.6050, Train Loss: 0.6570, Test Loss: 0.6652\n",
      "Epoch: 490, Train Acc: 0.6897, Test Acc: 0.6050, Train Loss: 0.6543, Test Loss: 0.6632\n",
      "Epoch: 500, Train Acc: 0.7004, Test Acc: 0.6100, Train Loss: 0.6524, Test Loss: 0.6615\n",
      "Epoch: 510, Train Acc: 0.6853, Test Acc: 0.6200, Train Loss: 0.6499, Test Loss: 0.6600\n",
      "Epoch: 520, Train Acc: 0.7069, Test Acc: 0.6350, Train Loss: 0.6475, Test Loss: 0.6578\n",
      "Epoch: 530, Train Acc: 0.7112, Test Acc: 0.6450, Train Loss: 0.6440, Test Loss: 0.6556\n",
      "Epoch: 540, Train Acc: 0.7112, Test Acc: 0.6450, Train Loss: 0.6424, Test Loss: 0.6540\n",
      "Epoch: 550, Train Acc: 0.7177, Test Acc: 0.6600, Train Loss: 0.6399, Test Loss: 0.6516\n",
      "Epoch: 560, Train Acc: 0.7241, Test Acc: 0.6700, Train Loss: 0.6364, Test Loss: 0.6494\n",
      "Epoch: 570, Train Acc: 0.7328, Test Acc: 0.6750, Train Loss: 0.6343, Test Loss: 0.6468\n",
      "Epoch: 580, Train Acc: 0.7306, Test Acc: 0.6750, Train Loss: 0.6316, Test Loss: 0.6451\n",
      "Epoch: 590, Train Acc: 0.7457, Test Acc: 0.6600, Train Loss: 0.6271, Test Loss: 0.6422\n",
      "Epoch: 600, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6254, Test Loss: 0.6401\n",
      "Epoch: 610, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6227, Test Loss: 0.6377\n",
      "Epoch: 620, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6188, Test Loss: 0.6354\n",
      "Epoch: 630, Train Acc: 0.7565, Test Acc: 0.6800, Train Loss: 0.6141, Test Loss: 0.6329\n",
      "Epoch: 640, Train Acc: 0.7565, Test Acc: 0.6700, Train Loss: 0.6126, Test Loss: 0.6306\n",
      "Epoch: 650, Train Acc: 0.7608, Test Acc: 0.6700, Train Loss: 0.6096, Test Loss: 0.6284\n",
      "Epoch: 660, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.6055, Test Loss: 0.6261\n",
      "Epoch: 670, Train Acc: 0.7672, Test Acc: 0.6850, Train Loss: 0.6024, Test Loss: 0.6237\n",
      "Epoch: 680, Train Acc: 0.7629, Test Acc: 0.6850, Train Loss: 0.5992, Test Loss: 0.6209\n",
      "Epoch: 690, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5960, Test Loss: 0.6188\n",
      "Epoch: 700, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.5910, Test Loss: 0.6170\n",
      "Epoch: 710, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.5883, Test Loss: 0.6142\n",
      "Epoch: 720, Train Acc: 0.7737, Test Acc: 0.6850, Train Loss: 0.5861, Test Loss: 0.6121\n",
      "Epoch: 730, Train Acc: 0.7586, Test Acc: 0.7000, Train Loss: 0.5823, Test Loss: 0.6095\n",
      "Epoch: 740, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5799, Test Loss: 0.6077\n",
      "Epoch: 750, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5785, Test Loss: 0.6066\n",
      "Epoch: 760, Train Acc: 0.7651, Test Acc: 0.7050, Train Loss: 0.5742, Test Loss: 0.6036\n",
      "Epoch: 770, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5705, Test Loss: 0.6016\n",
      "Epoch: 780, Train Acc: 0.7737, Test Acc: 0.7100, Train Loss: 0.5665, Test Loss: 0.6001\n",
      "Epoch: 790, Train Acc: 0.7716, Test Acc: 0.7050, Train Loss: 0.5647, Test Loss: 0.5983\n",
      "Epoch: 800, Train Acc: 0.7716, Test Acc: 0.6850, Train Loss: 0.5602, Test Loss: 0.5962\n",
      "Epoch: 810, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5582, Test Loss: 0.5953\n",
      "Epoch: 820, Train Acc: 0.7629, Test Acc: 0.6850, Train Loss: 0.5553, Test Loss: 0.5926\n",
      "Epoch: 830, Train Acc: 0.7716, Test Acc: 0.6900, Train Loss: 0.5547, Test Loss: 0.5914\n",
      "Epoch: 840, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5520, Test Loss: 0.5899\n",
      "Epoch: 850, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5490, Test Loss: 0.5886\n",
      "Epoch: 860, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5461, Test Loss: 0.5872\n",
      "Epoch: 870, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5435, Test Loss: 0.5859\n",
      "Epoch: 880, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5444, Test Loss: 0.5840\n",
      "Epoch: 890, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5369, Test Loss: 0.5833\n",
      "Epoch: 900, Train Acc: 0.7737, Test Acc: 0.6900, Train Loss: 0.5362, Test Loss: 0.5815\n",
      "Epoch: 910, Train Acc: 0.7737, Test Acc: 0.6750, Train Loss: 0.5354, Test Loss: 0.5799\n",
      "Epoch: 920, Train Acc: 0.7737, Test Acc: 0.6800, Train Loss: 0.5309, Test Loss: 0.5787\n",
      "Epoch: 930, Train Acc: 0.7737, Test Acc: 0.6800, Train Loss: 0.5324, Test Loss: 0.5776\n",
      "Epoch: 940, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5311, Test Loss: 0.5771\n",
      "Epoch: 950, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5236, Test Loss: 0.5759\n",
      "Epoch: 960, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.5236, Test Loss: 0.5761\n",
      "Epoch: 970, Train Acc: 0.7780, Test Acc: 0.6850, Train Loss: 0.5218, Test Loss: 0.5733\n",
      "Epoch: 980, Train Acc: 0.7823, Test Acc: 0.7100, Train Loss: 0.5175, Test Loss: 0.5745\n",
      "Epoch: 990, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5178, Test Loss: 0.5724\n",
      "Epoch: 1000, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5185, Test Loss: 0.5712\n",
      "Epoch: 1010, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.5155, Test Loss: 0.5716\n",
      "Epoch: 1020, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5132, Test Loss: 0.5692\n",
      "Epoch: 1030, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.5120, Test Loss: 0.5692\n",
      "Epoch: 1040, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.5112, Test Loss: 0.5674\n",
      "Epoch: 1050, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.5066, Test Loss: 0.5671\n",
      "Epoch: 1060, Train Acc: 0.7823, Test Acc: 0.7000, Train Loss: 0.5037, Test Loss: 0.5658\n",
      "Epoch: 1070, Train Acc: 0.7823, Test Acc: 0.7150, Train Loss: 0.5028, Test Loss: 0.5658\n",
      "Epoch: 1080, Train Acc: 0.7866, Test Acc: 0.7050, Train Loss: 0.5028, Test Loss: 0.5647\n",
      "Epoch: 1090, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5019, Test Loss: 0.5635\n",
      "Epoch: 1100, Train Acc: 0.7845, Test Acc: 0.7050, Train Loss: 0.4974, Test Loss: 0.5633\n",
      "Epoch: 1110, Train Acc: 0.7909, Test Acc: 0.7000, Train Loss: 0.4974, Test Loss: 0.5620\n",
      "Epoch: 1120, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4997, Test Loss: 0.5627\n",
      "Epoch: 1130, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4967, Test Loss: 0.5616\n",
      "Epoch: 1140, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4967, Test Loss: 0.5609\n",
      "Epoch: 1150, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4939, Test Loss: 0.5594\n",
      "Epoch: 1160, Train Acc: 0.7909, Test Acc: 0.7300, Train Loss: 0.4905, Test Loss: 0.5614\n",
      "Epoch: 1170, Train Acc: 0.7866, Test Acc: 0.7100, Train Loss: 0.4904, Test Loss: 0.5587\n",
      "Epoch: 1180, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4895, Test Loss: 0.5583\n",
      "Epoch: 1190, Train Acc: 0.7909, Test Acc: 0.7100, Train Loss: 0.4908, Test Loss: 0.5572\n",
      "Epoch: 1200, Train Acc: 0.7931, Test Acc: 0.7150, Train Loss: 0.4878, Test Loss: 0.5565\n",
      "Epoch: 1210, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4887, Test Loss: 0.5566\n",
      "Epoch: 1220, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4874, Test Loss: 0.5552\n",
      "Epoch: 1230, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4800, Test Loss: 0.5557\n",
      "Epoch: 1240, Train Acc: 0.7909, Test Acc: 0.7300, Train Loss: 0.4822, Test Loss: 0.5545\n",
      "Epoch: 1250, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4833, Test Loss: 0.5547\n",
      "Epoch: 1260, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.4775, Test Loss: 0.5533\n",
      "Epoch: 1270, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.4814, Test Loss: 0.5528\n",
      "Epoch: 1280, Train Acc: 0.7931, Test Acc: 0.7300, Train Loss: 0.4786, Test Loss: 0.5524\n",
      "Epoch: 1290, Train Acc: 0.7953, Test Acc: 0.7200, Train Loss: 0.4781, Test Loss: 0.5513\n",
      "Epoch: 1300, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4763, Test Loss: 0.5513\n",
      "Epoch: 1310, Train Acc: 0.7931, Test Acc: 0.7300, Train Loss: 0.4722, Test Loss: 0.5503\n",
      "Epoch: 1320, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4753, Test Loss: 0.5503\n",
      "Epoch: 1330, Train Acc: 0.7974, Test Acc: 0.7300, Train Loss: 0.4730, Test Loss: 0.5496\n",
      "Epoch: 1340, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4700, Test Loss: 0.5499\n",
      "Epoch: 1350, Train Acc: 0.8017, Test Acc: 0.7300, Train Loss: 0.4680, Test Loss: 0.5487\n",
      "Epoch: 1360, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4688, Test Loss: 0.5474\n",
      "Epoch: 1370, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4672, Test Loss: 0.5483\n",
      "Epoch: 1380, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4640, Test Loss: 0.5478\n",
      "Epoch: 1390, Train Acc: 0.7996, Test Acc: 0.7400, Train Loss: 0.4670, Test Loss: 0.5455\n",
      "Epoch: 1400, Train Acc: 0.8017, Test Acc: 0.7400, Train Loss: 0.4633, Test Loss: 0.5455\n",
      "Epoch: 1410, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4678, Test Loss: 0.5453\n",
      "Epoch: 1420, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4635, Test Loss: 0.5449\n",
      "Epoch: 1430, Train Acc: 0.8082, Test Acc: 0.7300, Train Loss: 0.4650, Test Loss: 0.5443\n",
      "Epoch: 1440, Train Acc: 0.8103, Test Acc: 0.7400, Train Loss: 0.4625, Test Loss: 0.5441\n",
      "Epoch: 1450, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4623, Test Loss: 0.5438\n",
      "Epoch: 1460, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4604, Test Loss: 0.5443\n",
      "Epoch: 1470, Train Acc: 0.8039, Test Acc: 0.7500, Train Loss: 0.4601, Test Loss: 0.5414\n",
      "Epoch: 1480, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4592, Test Loss: 0.5418\n",
      "Epoch: 1490, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4566, Test Loss: 0.5413\n",
      "Epoch: 1500, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4500, Test Loss: 0.5413\n",
      "Epoch: 1510, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4574, Test Loss: 0.5416\n",
      "Epoch: 1520, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4592, Test Loss: 0.5400\n",
      "Epoch: 1530, Train Acc: 0.8060, Test Acc: 0.7400, Train Loss: 0.4596, Test Loss: 0.5391\n",
      "Epoch: 1540, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4486, Test Loss: 0.5388\n",
      "Epoch: 1550, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4506, Test Loss: 0.5399\n",
      "Epoch: 1560, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4538, Test Loss: 0.5397\n",
      "Epoch: 1570, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4536, Test Loss: 0.5387\n",
      "Epoch: 1580, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4515, Test Loss: 0.5373\n",
      "Epoch: 1590, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4469, Test Loss: 0.5364\n",
      "Epoch: 1600, Train Acc: 0.8039, Test Acc: 0.7450, Train Loss: 0.4570, Test Loss: 0.5355\n",
      "Epoch: 1610, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4463, Test Loss: 0.5361\n",
      "Epoch: 1620, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4471, Test Loss: 0.5353\n",
      "Epoch: 1630, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4464, Test Loss: 0.5354\n",
      "Epoch: 1640, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4474, Test Loss: 0.5344\n",
      "Epoch: 1650, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4442, Test Loss: 0.5343\n",
      "Epoch: 1660, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4457, Test Loss: 0.5349\n",
      "Epoch: 1670, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4456, Test Loss: 0.5333\n",
      "Epoch: 1680, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4411, Test Loss: 0.5335\n",
      "Epoch: 1690, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4432, Test Loss: 0.5329\n",
      "Epoch: 1700, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4441, Test Loss: 0.5341\n",
      "Epoch: 1710, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4414, Test Loss: 0.5325\n",
      "Epoch: 1720, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4388, Test Loss: 0.5329\n",
      "Epoch: 1730, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4363, Test Loss: 0.5312\n",
      "Epoch: 1740, Train Acc: 0.8168, Test Acc: 0.7600, Train Loss: 0.4366, Test Loss: 0.5314\n",
      "Epoch: 1750, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4413, Test Loss: 0.5300\n",
      "Epoch: 1760, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4371, Test Loss: 0.5319\n",
      "Epoch: 1770, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4381, Test Loss: 0.5313\n",
      "Epoch: 1780, Train Acc: 0.8147, Test Acc: 0.7600, Train Loss: 0.4350, Test Loss: 0.5312\n",
      "Epoch: 1790, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4388, Test Loss: 0.5302\n",
      "Epoch: 1800, Train Acc: 0.8125, Test Acc: 0.7600, Train Loss: 0.4319, Test Loss: 0.5302\n",
      "Epoch: 1810, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4315, Test Loss: 0.5294\n",
      "Epoch: 1820, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4329, Test Loss: 0.5288\n",
      "Epoch: 1830, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4318, Test Loss: 0.5282\n",
      "Epoch: 1840, Train Acc: 0.8147, Test Acc: 0.7650, Train Loss: 0.4352, Test Loss: 0.5292\n",
      "Epoch: 1850, Train Acc: 0.8211, Test Acc: 0.7600, Train Loss: 0.4327, Test Loss: 0.5273\n",
      "Epoch: 1860, Train Acc: 0.8211, Test Acc: 0.7650, Train Loss: 0.4284, Test Loss: 0.5259\n",
      "Epoch: 1870, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4328, Test Loss: 0.5260\n",
      "Epoch: 1880, Train Acc: 0.8168, Test Acc: 0.7700, Train Loss: 0.4299, Test Loss: 0.5272\n",
      "Epoch: 1890, Train Acc: 0.8211, Test Acc: 0.7600, Train Loss: 0.4284, Test Loss: 0.5265\n",
      "Epoch: 1900, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4304, Test Loss: 0.5259\n",
      "Epoch: 1910, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4311, Test Loss: 0.5249\n",
      "Epoch: 1920, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4268, Test Loss: 0.5245\n",
      "Epoch: 1930, Train Acc: 0.8147, Test Acc: 0.7700, Train Loss: 0.4266, Test Loss: 0.5265\n",
      "Epoch: 1940, Train Acc: 0.8254, Test Acc: 0.7700, Train Loss: 0.4269, Test Loss: 0.5239\n",
      "Epoch: 1950, Train Acc: 0.8211, Test Acc: 0.7700, Train Loss: 0.4232, Test Loss: 0.5247\n",
      "Epoch: 1960, Train Acc: 0.8276, Test Acc: 0.7600, Train Loss: 0.4261, Test Loss: 0.5235\n",
      "Epoch: 1970, Train Acc: 0.8276, Test Acc: 0.7700, Train Loss: 0.4252, Test Loss: 0.5230\n",
      "Epoch: 1980, Train Acc: 0.8168, Test Acc: 0.7700, Train Loss: 0.4257, Test Loss: 0.5252\n",
      "Epoch: 1990, Train Acc: 0.8254, Test Acc: 0.7700, Train Loss: 0.4209, Test Loss: 0.5233\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▂▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█████</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▁▁▁▂▃▄▃▃▃▄▂▁▂▃▂▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇█▇▇█</td></tr><tr><td>Test Loss</td><td>███████▇▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>██████▇▇▇▆▆▅▃▃▃▃▂▁▂▂▂▃▃▃▂▂▃▃▃▃▄▄▃▃▄▄▄▃▄▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▂▂▂▃▄▅▆▇▇▇▇█████████████▇▇████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▂▂▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▂▂▂▃▄▅▅▆▆▆▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇██████</td></tr><tr><td>Train Loss</td><td>████████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>██████▇▇▆▅▆▄▂▂▂▂▁▁▂▂▁▂▂▂▂▂▂▂▂▃▃▃▃▂▃▃▃▃▃▃</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▂▂▃▄▅▆▇▇▇▇████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.78095</td></tr><tr><td>Test Loss</td><td>0.52288</td></tr><tr><td>Test Sensitivity</td><td>0.79612</td></tr><tr><td>Test Specificity</td><td>0.74227</td></tr><tr><td>Train Accuracy</td><td>0.82759</td></tr><tr><td>Train F1</td><td>0.83264</td></tr><tr><td>Train Loss</td><td>0.42359</td></tr><tr><td>Train Sensitivity</td><td>0.80894</td></tr><tr><td>Train Specificity</td><td>0.84862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-46</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/eux08dk0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/eux08dk0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_192550-eux08dk0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pp6x0u5r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.074763928250069e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00026087677929191507\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_193556-pp6x0u5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/pp6x0u5r' target=\"_blank\">fearless-sweep-47</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/pp6x0u5r' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/pp6x0u5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6923, Test Loss: 0.6932\n",
      "Epoch: 020, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6920, Test Loss: 0.6932\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6933\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6933\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>Test F1</td><td>██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>Test Loss</td><td>▇▅▄▁▁▂▃▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████▇▇▇▆▆▆</td></tr><tr><td>Test Sensitivity</td><td>██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▁███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▃▃▄▅▄▆▇▇███▇▇▇▆▆▆▄▅▅▄▅▄▄▃▄▃▅▁▃▃▃▄▂▃▄▅▁▂▅</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69325</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69173</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-sweep-47</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/pp6x0u5r' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/pp6x0u5r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_193556-pp6x0u5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2s8t2ihd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0017628201948494263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.004610720648421546\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_193621-2s8t2ihd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/2s8t2ihd' target=\"_blank\">cosmic-sweep-48</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2s8t2ihd' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2s8t2ihd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6940\n",
      "Epoch: 010, Train Acc: 0.5388, Test Acc: 0.5350, Train Loss: 0.6912, Test Loss: 0.6912\n",
      "Epoch: 020, Train Acc: 0.4763, Test Acc: 0.5000, Train Loss: 0.7351, Test Loss: 0.7267\n",
      "Epoch: 030, Train Acc: 0.5345, Test Acc: 0.5650, Train Loss: 0.9727, Test Loss: 0.9748\n",
      "Epoch: 040, Train Acc: 0.5991, Test Acc: 0.6050, Train Loss: 0.9172, Test Loss: 0.9303\n",
      "Epoch: 050, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4732, Test Loss: 0.5244\n",
      "Epoch: 060, Train Acc: 0.5819, Test Acc: 0.6150, Train Loss: 1.0511, Test Loss: 1.0306\n",
      "Epoch: 070, Train Acc: 0.7004, Test Acc: 0.7200, Train Loss: 0.6256, Test Loss: 0.6681\n",
      "Epoch: 080, Train Acc: 0.5108, Test Acc: 0.5700, Train Loss: 1.5976, Test Loss: 1.5207\n",
      "Epoch: 090, Train Acc: 0.7328, Test Acc: 0.6550, Train Loss: 0.5041, Test Loss: 0.6574\n",
      "Epoch: 100, Train Acc: 0.7974, Test Acc: 0.6850, Train Loss: 0.4319, Test Loss: 0.5817\n",
      "Epoch: 110, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4045, Test Loss: 0.5592\n",
      "Epoch: 120, Train Acc: 0.8470, Test Acc: 0.7900, Train Loss: 0.3985, Test Loss: 0.5129\n",
      "Epoch: 130, Train Acc: 0.6250, Test Acc: 0.6550, Train Loss: 0.9245, Test Loss: 0.9717\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▂▁▁▁▁▂▃▅▆▄▅▅▅▄▄▇▆▆▆▅▄▁█▆▇▆▆▅▄▆▁▂▄▆▃▇▃</td></tr><tr><td>Test F1</td><td>▇▇▇▆▁▁▁▂▃▄▆▇▅▆▅▇▅▄▇▇▇█▇▅▇█▇█▆█▇▇▆▇▇▇▇▄█▇</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▃▃▄▃▃▂▁▃▃▄▂▄▅▂▂▂▁▂▄█▁▂▁▃▂▂▃▃▇▄▃▂▇▁▃</td></tr><tr><td>Test Sensitivity</td><td>███▅▁▁▁▁▂▃▄▅▃▄▃▇▃▃▅▅▅▇▇▃█▆▅▇▄▇▇▇▄██▇▅▂▆▇</td></tr><tr><td>Test Specificity</td><td>▁▁▁▅██████▇▇███▄██▇█▇▅▄█▁▇▇▅█▅▄▃█▁▂▃██▇▂</td></tr><tr><td>Train Accuracy</td><td>▂▂▂▃▁▁▁▁▂▃▆▇▄▄▄▆▄▃▇▆▇▇▇▄▂█▆█▅▇▇▆▅▂▄▆▆▂█▅</td></tr><tr><td>Train F1</td><td>▇▇▇▆▁▁▁▂▂▄▇▇▅▅▄█▄▄▇▇▇██▄▇█▇█▆███▆▇▇█▇▃█▇</td></tr><tr><td>Train Loss</td><td>▃▃▃▃▃▃▄▅▄▄▂▂▄▃▄▂▄▆▂▂▂▁▂▅▇▁▂▁▃▁▁▂▃▅▃▂▂█▁▂</td></tr><tr><td>Train Sensitivity</td><td>███▅▁▁▁▁▂▂▅▆▃▃▃▇▃▂▅▅▅▇▇▃█▇▅▇▄▇▇█▄███▅▂▆█</td></tr><tr><td>Train Specificity</td><td>▁▁▁▅███████▇███▅█████▆▅█▁▇█▆█▆▅▄█▁▃▄███▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.575</td></tr><tr><td>Test F1</td><td>0.69091</td></tr><tr><td>Test Loss</td><td>0.81081</td></tr><tr><td>Test Sensitivity</td><td>0.92233</td></tr><tr><td>Test Specificity</td><td>0.20619</td></tr><tr><td>Train Accuracy</td><td>0.67457</td></tr><tr><td>Train F1</td><td>0.7584</td></tr><tr><td>Train Loss</td><td>0.60261</td></tr><tr><td>Train Sensitivity</td><td>0.96341</td></tr><tr><td>Train Specificity</td><td>0.34862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-48</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/2s8t2ihd' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/2s8t2ihd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_193621-2s8t2ihd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fywzq9s6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.3910898489120795e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.339358473640524e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_193702-fywzq9s6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/fywzq9s6' target=\"_blank\">apricot-sweep-49</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/fywzq9s6' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/fywzq9s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6961, Test Loss: 0.6951\n",
      "Epoch: 010, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6941, Test Loss: 0.6936\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6929\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6910, Test Loss: 0.6931\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6928\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6926\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6925\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6922\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6919\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6917\n",
      "Epoch: 100, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6915\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6915\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6914\n",
      "Epoch: 130, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6889, Test Loss: 0.6913\n",
      "Epoch: 140, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6887, Test Loss: 0.6912\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6908\n",
      "Epoch: 160, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6908\n",
      "Epoch: 170, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6907\n",
      "Epoch: 180, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6908\n",
      "Epoch: 190, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6908\n",
      "Epoch: 200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6904\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6903\n",
      "Epoch: 220, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6903\n",
      "Epoch: 230, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6899\n",
      "Epoch: 240, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6897\n",
      "Epoch: 250, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6896\n",
      "Epoch: 260, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6869, Test Loss: 0.6896\n",
      "Epoch: 270, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6894\n",
      "Epoch: 280, Train Acc: 0.5409, Test Acc: 0.5200, Train Loss: 0.6866, Test Loss: 0.6891\n",
      "Epoch: 290, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6867, Test Loss: 0.6891\n",
      "Epoch: 300, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6890\n",
      "Epoch: 310, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6863, Test Loss: 0.6888\n",
      "Epoch: 320, Train Acc: 0.5323, Test Acc: 0.5200, Train Loss: 0.6859, Test Loss: 0.6886\n",
      "Epoch: 330, Train Acc: 0.5388, Test Acc: 0.5150, Train Loss: 0.6862, Test Loss: 0.6884\n",
      "Epoch: 340, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6854, Test Loss: 0.6882\n",
      "Epoch: 350, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6854, Test Loss: 0.6882\n",
      "Epoch: 360, Train Acc: 0.5625, Test Acc: 0.5250, Train Loss: 0.6848, Test Loss: 0.6877\n",
      "Epoch: 370, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6846, Test Loss: 0.6878\n",
      "Epoch: 380, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6841, Test Loss: 0.6875\n",
      "Epoch: 390, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6841, Test Loss: 0.6875\n",
      "Epoch: 400, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6841, Test Loss: 0.6870\n",
      "Epoch: 410, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6840, Test Loss: 0.6867\n",
      "Epoch: 420, Train Acc: 0.5474, Test Acc: 0.5150, Train Loss: 0.6834, Test Loss: 0.6866\n",
      "Epoch: 430, Train Acc: 0.5647, Test Acc: 0.5150, Train Loss: 0.6829, Test Loss: 0.6862\n",
      "Epoch: 440, Train Acc: 0.5668, Test Acc: 0.5150, Train Loss: 0.6831, Test Loss: 0.6859\n",
      "Epoch: 450, Train Acc: 0.5539, Test Acc: 0.5150, Train Loss: 0.6820, Test Loss: 0.6857\n",
      "Epoch: 460, Train Acc: 0.5668, Test Acc: 0.5200, Train Loss: 0.6819, Test Loss: 0.6854\n",
      "Epoch: 470, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6818, Test Loss: 0.6850\n",
      "Epoch: 480, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6812, Test Loss: 0.6849\n",
      "Epoch: 490, Train Acc: 0.5862, Test Acc: 0.5250, Train Loss: 0.6806, Test Loss: 0.6842\n",
      "Epoch: 500, Train Acc: 0.5905, Test Acc: 0.5400, Train Loss: 0.6805, Test Loss: 0.6838\n",
      "Epoch: 510, Train Acc: 0.5690, Test Acc: 0.5200, Train Loss: 0.6796, Test Loss: 0.6837\n",
      "Epoch: 520, Train Acc: 0.5841, Test Acc: 0.5200, Train Loss: 0.6797, Test Loss: 0.6833\n",
      "Epoch: 530, Train Acc: 0.5905, Test Acc: 0.5300, Train Loss: 0.6780, Test Loss: 0.6828\n",
      "Epoch: 540, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.6788, Test Loss: 0.6827\n",
      "Epoch: 550, Train Acc: 0.5862, Test Acc: 0.5250, Train Loss: 0.6777, Test Loss: 0.6821\n",
      "Epoch: 560, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6766, Test Loss: 0.6816\n",
      "Epoch: 570, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6768, Test Loss: 0.6808\n",
      "Epoch: 580, Train Acc: 0.5948, Test Acc: 0.5350, Train Loss: 0.6760, Test Loss: 0.6804\n",
      "Epoch: 590, Train Acc: 0.5991, Test Acc: 0.5350, Train Loss: 0.6745, Test Loss: 0.6799\n",
      "Epoch: 600, Train Acc: 0.5991, Test Acc: 0.5300, Train Loss: 0.6749, Test Loss: 0.6793\n",
      "Epoch: 610, Train Acc: 0.6056, Test Acc: 0.5300, Train Loss: 0.6743, Test Loss: 0.6790\n",
      "Epoch: 620, Train Acc: 0.6078, Test Acc: 0.5500, Train Loss: 0.6730, Test Loss: 0.6782\n",
      "Epoch: 630, Train Acc: 0.6121, Test Acc: 0.5400, Train Loss: 0.6721, Test Loss: 0.6777\n",
      "Epoch: 640, Train Acc: 0.6099, Test Acc: 0.5300, Train Loss: 0.6723, Test Loss: 0.6772\n",
      "Epoch: 650, Train Acc: 0.6056, Test Acc: 0.5500, Train Loss: 0.6710, Test Loss: 0.6764\n",
      "Epoch: 660, Train Acc: 0.6121, Test Acc: 0.5450, Train Loss: 0.6702, Test Loss: 0.6757\n",
      "Epoch: 670, Train Acc: 0.6099, Test Acc: 0.5500, Train Loss: 0.6692, Test Loss: 0.6750\n",
      "Epoch: 680, Train Acc: 0.6121, Test Acc: 0.5500, Train Loss: 0.6684, Test Loss: 0.6743\n",
      "Epoch: 690, Train Acc: 0.6164, Test Acc: 0.5650, Train Loss: 0.6679, Test Loss: 0.6736\n",
      "Epoch: 700, Train Acc: 0.6228, Test Acc: 0.5600, Train Loss: 0.6660, Test Loss: 0.6727\n",
      "Epoch: 710, Train Acc: 0.6272, Test Acc: 0.5600, Train Loss: 0.6652, Test Loss: 0.6720\n",
      "Epoch: 720, Train Acc: 0.6358, Test Acc: 0.5850, Train Loss: 0.6643, Test Loss: 0.6710\n",
      "Epoch: 730, Train Acc: 0.6379, Test Acc: 0.5800, Train Loss: 0.6631, Test Loss: 0.6702\n",
      "Epoch: 740, Train Acc: 0.6379, Test Acc: 0.5750, Train Loss: 0.6624, Test Loss: 0.6694\n",
      "Epoch: 750, Train Acc: 0.6509, Test Acc: 0.5850, Train Loss: 0.6618, Test Loss: 0.6684\n",
      "Epoch: 760, Train Acc: 0.6595, Test Acc: 0.5950, Train Loss: 0.6599, Test Loss: 0.6674\n",
      "Epoch: 770, Train Acc: 0.6509, Test Acc: 0.5850, Train Loss: 0.6591, Test Loss: 0.6666\n",
      "Epoch: 780, Train Acc: 0.6595, Test Acc: 0.5950, Train Loss: 0.6572, Test Loss: 0.6656\n",
      "Epoch: 790, Train Acc: 0.6681, Test Acc: 0.6150, Train Loss: 0.6558, Test Loss: 0.6645\n",
      "Epoch: 800, Train Acc: 0.6875, Test Acc: 0.6200, Train Loss: 0.6543, Test Loss: 0.6633\n",
      "Epoch: 810, Train Acc: 0.6767, Test Acc: 0.6250, Train Loss: 0.6534, Test Loss: 0.6624\n",
      "Epoch: 820, Train Acc: 0.7047, Test Acc: 0.6150, Train Loss: 0.6512, Test Loss: 0.6610\n",
      "Epoch: 830, Train Acc: 0.7026, Test Acc: 0.6200, Train Loss: 0.6508, Test Loss: 0.6599\n",
      "Epoch: 840, Train Acc: 0.6832, Test Acc: 0.6300, Train Loss: 0.6490, Test Loss: 0.6592\n",
      "Epoch: 850, Train Acc: 0.7091, Test Acc: 0.6450, Train Loss: 0.6473, Test Loss: 0.6576\n",
      "Epoch: 860, Train Acc: 0.7091, Test Acc: 0.6400, Train Loss: 0.6464, Test Loss: 0.6565\n",
      "Epoch: 870, Train Acc: 0.7047, Test Acc: 0.6400, Train Loss: 0.6447, Test Loss: 0.6555\n",
      "Epoch: 880, Train Acc: 0.7155, Test Acc: 0.6500, Train Loss: 0.6437, Test Loss: 0.6538\n",
      "Epoch: 890, Train Acc: 0.7112, Test Acc: 0.6550, Train Loss: 0.6415, Test Loss: 0.6527\n",
      "Epoch: 900, Train Acc: 0.7220, Test Acc: 0.6650, Train Loss: 0.6402, Test Loss: 0.6513\n",
      "Epoch: 910, Train Acc: 0.7198, Test Acc: 0.6500, Train Loss: 0.6382, Test Loss: 0.6502\n",
      "Epoch: 920, Train Acc: 0.7371, Test Acc: 0.6650, Train Loss: 0.6359, Test Loss: 0.6483\n",
      "Epoch: 930, Train Acc: 0.7284, Test Acc: 0.6850, Train Loss: 0.6352, Test Loss: 0.6475\n",
      "Epoch: 940, Train Acc: 0.7478, Test Acc: 0.6650, Train Loss: 0.6338, Test Loss: 0.6457\n",
      "Epoch: 950, Train Acc: 0.7500, Test Acc: 0.6800, Train Loss: 0.6304, Test Loss: 0.6446\n",
      "Epoch: 960, Train Acc: 0.7586, Test Acc: 0.6750, Train Loss: 0.6289, Test Loss: 0.6431\n",
      "Epoch: 970, Train Acc: 0.7565, Test Acc: 0.6600, Train Loss: 0.6278, Test Loss: 0.6415\n",
      "Epoch: 980, Train Acc: 0.7522, Test Acc: 0.6800, Train Loss: 0.6245, Test Loss: 0.6406\n",
      "Epoch: 990, Train Acc: 0.7543, Test Acc: 0.6750, Train Loss: 0.6234, Test Loss: 0.6384\n",
      "Epoch: 1000, Train Acc: 0.7565, Test Acc: 0.6700, Train Loss: 0.6224, Test Loss: 0.6371\n",
      "Epoch: 1010, Train Acc: 0.7629, Test Acc: 0.6700, Train Loss: 0.6200, Test Loss: 0.6360\n",
      "Epoch: 1020, Train Acc: 0.7586, Test Acc: 0.6800, Train Loss: 0.6179, Test Loss: 0.6342\n",
      "Epoch: 1030, Train Acc: 0.7608, Test Acc: 0.6850, Train Loss: 0.6162, Test Loss: 0.6328\n",
      "Epoch: 1040, Train Acc: 0.7586, Test Acc: 0.6700, Train Loss: 0.6146, Test Loss: 0.6309\n",
      "Epoch: 1050, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.6118, Test Loss: 0.6301\n",
      "Epoch: 1060, Train Acc: 0.7651, Test Acc: 0.6750, Train Loss: 0.6089, Test Loss: 0.6282\n",
      "Epoch: 1070, Train Acc: 0.7694, Test Acc: 0.6800, Train Loss: 0.6072, Test Loss: 0.6271\n",
      "Epoch: 1080, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.6053, Test Loss: 0.6255\n",
      "Epoch: 1090, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.6039, Test Loss: 0.6236\n",
      "Epoch: 1100, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.6008, Test Loss: 0.6224\n",
      "Epoch: 1110, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5989, Test Loss: 0.6211\n",
      "Epoch: 1120, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5984, Test Loss: 0.6197\n",
      "Epoch: 1130, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5954, Test Loss: 0.6181\n",
      "Epoch: 1140, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5946, Test Loss: 0.6168\n",
      "Epoch: 1150, Train Acc: 0.7672, Test Acc: 0.6850, Train Loss: 0.5912, Test Loss: 0.6152\n",
      "Epoch: 1160, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5890, Test Loss: 0.6140\n",
      "Epoch: 1170, Train Acc: 0.7608, Test Acc: 0.6950, Train Loss: 0.5870, Test Loss: 0.6122\n",
      "Epoch: 1180, Train Acc: 0.7651, Test Acc: 0.7000, Train Loss: 0.5859, Test Loss: 0.6110\n",
      "Epoch: 1190, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5840, Test Loss: 0.6099\n",
      "Epoch: 1200, Train Acc: 0.7651, Test Acc: 0.7000, Train Loss: 0.5824, Test Loss: 0.6083\n",
      "Epoch: 1210, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5807, Test Loss: 0.6071\n",
      "Epoch: 1220, Train Acc: 0.7672, Test Acc: 0.7050, Train Loss: 0.5786, Test Loss: 0.6054\n",
      "Epoch: 1230, Train Acc: 0.7629, Test Acc: 0.6900, Train Loss: 0.5735, Test Loss: 0.6053\n",
      "Epoch: 1240, Train Acc: 0.7716, Test Acc: 0.7100, Train Loss: 0.5739, Test Loss: 0.6031\n",
      "Epoch: 1250, Train Acc: 0.7737, Test Acc: 0.7100, Train Loss: 0.5734, Test Loss: 0.6018\n",
      "Epoch: 1260, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5684, Test Loss: 0.6012\n",
      "Epoch: 1270, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5687, Test Loss: 0.5998\n",
      "Epoch: 1280, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5661, Test Loss: 0.5981\n",
      "Epoch: 1290, Train Acc: 0.7759, Test Acc: 0.7100, Train Loss: 0.5647, Test Loss: 0.5973\n",
      "Epoch: 1300, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5626, Test Loss: 0.5962\n",
      "Epoch: 1310, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5595, Test Loss: 0.5946\n",
      "Epoch: 1320, Train Acc: 0.7780, Test Acc: 0.7100, Train Loss: 0.5602, Test Loss: 0.5938\n",
      "Epoch: 1330, Train Acc: 0.7694, Test Acc: 0.6850, Train Loss: 0.5566, Test Loss: 0.5922\n",
      "Epoch: 1340, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5542, Test Loss: 0.5921\n",
      "Epoch: 1350, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5521, Test Loss: 0.5902\n",
      "Epoch: 1360, Train Acc: 0.7780, Test Acc: 0.6900, Train Loss: 0.5506, Test Loss: 0.5892\n",
      "Epoch: 1370, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5498, Test Loss: 0.5886\n",
      "Epoch: 1380, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5462, Test Loss: 0.5872\n",
      "Epoch: 1390, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5462, Test Loss: 0.5861\n",
      "Epoch: 1400, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5430, Test Loss: 0.5854\n",
      "Epoch: 1410, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5440, Test Loss: 0.5847\n",
      "Epoch: 1420, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5419, Test Loss: 0.5831\n",
      "Epoch: 1430, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5417, Test Loss: 0.5823\n",
      "Epoch: 1440, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5391, Test Loss: 0.5818\n",
      "Epoch: 1450, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5377, Test Loss: 0.5809\n",
      "Epoch: 1460, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5355, Test Loss: 0.5800\n",
      "Epoch: 1470, Train Acc: 0.7694, Test Acc: 0.6900, Train Loss: 0.5340, Test Loss: 0.5785\n",
      "Epoch: 1480, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5334, Test Loss: 0.5780\n",
      "Epoch: 1490, Train Acc: 0.7759, Test Acc: 0.7050, Train Loss: 0.5311, Test Loss: 0.5774\n",
      "Epoch: 1500, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5253, Test Loss: 0.5772\n",
      "Epoch: 1510, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5291, Test Loss: 0.5763\n",
      "Epoch: 1520, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5303, Test Loss: 0.5746\n",
      "Epoch: 1530, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5292, Test Loss: 0.5740\n",
      "Epoch: 1540, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5206, Test Loss: 0.5744\n",
      "Epoch: 1550, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5218, Test Loss: 0.5738\n",
      "Epoch: 1560, Train Acc: 0.7759, Test Acc: 0.7050, Train Loss: 0.5234, Test Loss: 0.5725\n",
      "Epoch: 1570, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5225, Test Loss: 0.5725\n",
      "Epoch: 1580, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5200, Test Loss: 0.5705\n",
      "Epoch: 1590, Train Acc: 0.7780, Test Acc: 0.7050, Train Loss: 0.5158, Test Loss: 0.5704\n",
      "Epoch: 1600, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5209, Test Loss: 0.5695\n",
      "Epoch: 1610, Train Acc: 0.7780, Test Acc: 0.7150, Train Loss: 0.5147, Test Loss: 0.5694\n",
      "Epoch: 1620, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5142, Test Loss: 0.5680\n",
      "Epoch: 1630, Train Acc: 0.7780, Test Acc: 0.7150, Train Loss: 0.5130, Test Loss: 0.5678\n",
      "Epoch: 1640, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5126, Test Loss: 0.5671\n",
      "Epoch: 1650, Train Acc: 0.7802, Test Acc: 0.7100, Train Loss: 0.5100, Test Loss: 0.5664\n",
      "Epoch: 1660, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5106, Test Loss: 0.5664\n",
      "Epoch: 1670, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.5106, Test Loss: 0.5649\n",
      "Epoch: 1680, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.5059, Test Loss: 0.5650\n",
      "Epoch: 1690, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.5068, Test Loss: 0.5648\n",
      "Epoch: 1700, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.5078, Test Loss: 0.5643\n",
      "Epoch: 1710, Train Acc: 0.7780, Test Acc: 0.7150, Train Loss: 0.5048, Test Loss: 0.5629\n",
      "Epoch: 1720, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.5016, Test Loss: 0.5626\n",
      "Epoch: 1730, Train Acc: 0.7802, Test Acc: 0.7150, Train Loss: 0.5002, Test Loss: 0.5615\n",
      "Epoch: 1740, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.4997, Test Loss: 0.5620\n",
      "Epoch: 1750, Train Acc: 0.7802, Test Acc: 0.7150, Train Loss: 0.5026, Test Loss: 0.5606\n",
      "Epoch: 1760, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.4978, Test Loss: 0.5613\n",
      "Epoch: 1770, Train Acc: 0.7802, Test Acc: 0.7150, Train Loss: 0.4990, Test Loss: 0.5608\n",
      "Epoch: 1780, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.4967, Test Loss: 0.5598\n",
      "Epoch: 1790, Train Acc: 0.7823, Test Acc: 0.7250, Train Loss: 0.4997, Test Loss: 0.5589\n",
      "Epoch: 1800, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.4928, Test Loss: 0.5588\n",
      "Epoch: 1810, Train Acc: 0.7802, Test Acc: 0.7200, Train Loss: 0.4927, Test Loss: 0.5584\n",
      "Epoch: 1820, Train Acc: 0.7845, Test Acc: 0.7250, Train Loss: 0.4938, Test Loss: 0.5573\n",
      "Epoch: 1830, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4919, Test Loss: 0.5571\n",
      "Epoch: 1840, Train Acc: 0.7866, Test Acc: 0.7250, Train Loss: 0.4948, Test Loss: 0.5566\n",
      "Epoch: 1850, Train Acc: 0.7866, Test Acc: 0.7150, Train Loss: 0.4926, Test Loss: 0.5557\n",
      "Epoch: 1860, Train Acc: 0.7866, Test Acc: 0.7250, Train Loss: 0.4880, Test Loss: 0.5555\n",
      "Epoch: 1870, Train Acc: 0.7823, Test Acc: 0.7250, Train Loss: 0.4913, Test Loss: 0.5557\n",
      "Epoch: 1880, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4885, Test Loss: 0.5549\n",
      "Epoch: 1890, Train Acc: 0.7845, Test Acc: 0.7200, Train Loss: 0.4870, Test Loss: 0.5550\n",
      "Epoch: 1900, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4878, Test Loss: 0.5541\n",
      "Epoch: 1910, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4885, Test Loss: 0.5535\n",
      "Epoch: 1920, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4847, Test Loss: 0.5546\n",
      "Epoch: 1930, Train Acc: 0.7888, Test Acc: 0.7250, Train Loss: 0.4846, Test Loss: 0.5530\n",
      "Epoch: 1940, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4839, Test Loss: 0.5521\n",
      "Epoch: 1950, Train Acc: 0.7909, Test Acc: 0.7200, Train Loss: 0.4808, Test Loss: 0.5530\n",
      "Epoch: 1960, Train Acc: 0.7953, Test Acc: 0.7250, Train Loss: 0.4832, Test Loss: 0.5515\n",
      "Epoch: 1970, Train Acc: 0.7888, Test Acc: 0.7300, Train Loss: 0.4821, Test Loss: 0.5514\n",
      "Epoch: 1980, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4822, Test Loss: 0.5520\n",
      "Epoch: 1990, Train Acc: 0.7931, Test Acc: 0.7300, Train Loss: 0.4778, Test Loss: 0.5507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Test F1</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▁▁▃▂▅▆▇▄▄▅▄▅▆▄▃▃▄▅▅▇▆▇▇▇▇▇▇█</td></tr><tr><td>Test Loss</td><td>███████████▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>███████████▇▇▇▆▆▆▅▅▃▃▃▂▂▃▂▁▁▁▂▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▅▆▆▇▇▇▇▇███████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▅▆▆▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▅▅▆▇▇▇▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>Train Loss</td><td>███████████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>████████▇▇▇▇▆▆▆▆▅▄▄▃▂▃▂▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▆▆▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.73</td></tr><tr><td>Test F1</td><td>0.73</td></tr><tr><td>Test Loss</td><td>0.54986</td></tr><tr><td>Test Sensitivity</td><td>0.70874</td></tr><tr><td>Test Specificity</td><td>0.75258</td></tr><tr><td>Train Accuracy</td><td>0.7931</td></tr><tr><td>Train F1</td><td>0.79916</td></tr><tr><td>Train Loss</td><td>0.47972</td></tr><tr><td>Train Sensitivity</td><td>0.77642</td></tr><tr><td>Train Specificity</td><td>0.81193</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-49</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/fywzq9s6' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/fywzq9s6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_193702-fywzq9s6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvzb92bm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003932800201010922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.5945918180442992e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_194708-nvzb92bm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/nvzb92bm' target=\"_blank\">northern-sweep-50</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/nvzb92bm' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/nvzb92bm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6934, Test Loss: 0.6965\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6938, Test Loss: 0.6995\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6926\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6916\n",
      "Epoch: 040, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6902\n",
      "Epoch: 050, Train Acc: 0.5474, Test Acc: 0.5250, Train Loss: 0.6821, Test Loss: 0.6833\n",
      "Epoch: 060, Train Acc: 0.6703, Test Acc: 0.6450, Train Loss: 0.5954, Test Loss: 0.6144\n",
      "Epoch: 070, Train Acc: 0.6918, Test Acc: 0.7050, Train Loss: 0.6076, Test Loss: 0.6285\n",
      "Epoch: 080, Train Acc: 0.6336, Test Acc: 0.6600, Train Loss: 0.7354, Test Loss: 0.7243\n",
      "Epoch: 090, Train Acc: 0.7694, Test Acc: 0.7400, Train Loss: 0.5148, Test Loss: 0.5476\n",
      "Epoch: 100, Train Acc: 0.7284, Test Acc: 0.7400, Train Loss: 0.5819, Test Loss: 0.5869\n",
      "Epoch: 110, Train Acc: 0.7522, Test Acc: 0.7500, Train Loss: 0.5469, Test Loss: 0.5631\n",
      "Epoch: 120, Train Acc: 0.8233, Test Acc: 0.7750, Train Loss: 0.4458, Test Loss: 0.5050\n",
      "Epoch: 130, Train Acc: 0.7953, Test Acc: 0.7500, Train Loss: 0.4810, Test Loss: 0.5367\n",
      "Epoch: 140, Train Acc: 0.6616, Test Acc: 0.6850, Train Loss: 0.8004, Test Loss: 0.8126\n",
      "Epoch: 150, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4149, Test Loss: 0.5866\n",
      "Epoch: 160, Train Acc: 0.4784, Test Acc: 0.5100, Train Loss: 3.1949, Test Loss: 2.9881\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▁▂▂▂▂▂▂▂▂▅▅▅▆▅▅▅▅▆▇▇█▇█▇████▇▇▆▇▂▇▅▃</td></tr><tr><td>Test F1</td><td>▁▇▇▇▁▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▆▇▇▇█▇██████▇▇▆▇▇█▅▃</td></tr><tr><td>Test Loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▃▂▄▁▄█</td></tr><tr><td>Test Sensitivity</td><td>▁███▁████████▇▄▄▄▄▃▃▃▄▅▅▅▅▅▅▅▅▆▆▅▅▄▅█▅▃▂</td></tr><tr><td>Test Specificity</td><td>█▁▁▁█▁▁▁▁▁▁▁▁▄▇▇▇█████▇█▇█▇▇▇▇▇▇▇▇██▁▇██</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▁▂▂▂▂▂▂▂▂▆▅▅▅▅▄▄▄▆▇▇▇▇▇▇▇▇██▆▇▅▆▃▇▃▂</td></tr><tr><td>Train F1</td><td>▁▇▇▇▁▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▇▇▇▇▇█▇████▇▇▆▆▇█▄▂</td></tr><tr><td>Train Loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▃▂▃▁▅█</td></tr><tr><td>Train Sensitivity</td><td>▁███▁████████▇▄▄▄▄▃▃▃▄▅▅▅▅▆▅▆▆▆▆▅▅▄▄█▅▃▂</td></tr><tr><td>Train Specificity</td><td>█▁▁▁█▁▁▁▁▁▁▁▁▅▇▇███████████████▇████▂███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.64</td></tr><tr><td>Test F1</td><td>0.712</td></tr><tr><td>Test Loss</td><td>0.69418</td></tr><tr><td>Test Sensitivity</td><td>0.86408</td></tr><tr><td>Test Specificity</td><td>0.40206</td></tr><tr><td>Train Accuracy</td><td>0.71983</td></tr><tr><td>Train F1</td><td>0.77352</td></tr><tr><td>Train Loss</td><td>0.51743</td></tr><tr><td>Train Sensitivity</td><td>0.90244</td></tr><tr><td>Train Specificity</td><td>0.51376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-50</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/nvzb92bm' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/nvzb92bm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_194708-nvzb92bm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wq8e084w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008402416056617856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.8506167466851085e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_194804-wq8e084w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/wq8e084w' target=\"_blank\">rich-sweep-51</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/wq8e084w' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/wq8e084w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7080, Test Loss: 0.7157\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7142, Test Loss: 0.7243\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6919, Test Loss: 0.6923\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6906, Test Loss: 0.6921\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6915\n",
      "Epoch: 050, Train Acc: 0.6185, Test Acc: 0.6050, Train Loss: 0.6799, Test Loss: 0.6802\n",
      "Epoch: 060, Train Acc: 0.6142, Test Acc: 0.6150, Train Loss: 0.6357, Test Loss: 0.6373\n",
      "Epoch: 070, Train Acc: 0.5905, Test Acc: 0.6200, Train Loss: 0.9267, Test Loss: 0.8589\n",
      "Epoch: 080, Train Acc: 0.7091, Test Acc: 0.7400, Train Loss: 0.6382, Test Loss: 0.6259\n",
      "Epoch: 090, Train Acc: 0.7651, Test Acc: 0.7550, Train Loss: 0.5213, Test Loss: 0.5435\n",
      "Epoch: 100, Train Acc: 0.7629, Test Acc: 0.7500, Train Loss: 0.5167, Test Loss: 0.5466\n",
      "Epoch: 110, Train Acc: 0.7651, Test Acc: 0.7550, Train Loss: 0.5176, Test Loss: 0.5695\n",
      "Epoch: 120, Train Acc: 0.8405, Test Acc: 0.7750, Train Loss: 0.4276, Test Loss: 0.5247\n",
      "Epoch: 130, Train Acc: 0.6746, Test Acc: 0.7050, Train Loss: 0.7003, Test Loss: 0.6962\n",
      "Epoch: 140, Train Acc: 0.8103, Test Acc: 0.7800, Train Loss: 0.4552, Test Loss: 0.5070\n",
      "Epoch: 150, Train Acc: 0.8233, Test Acc: 0.7800, Train Loss: 0.4277, Test Loss: 0.5121\n",
      "Epoch: 160, Train Acc: 0.5733, Test Acc: 0.5150, Train Loss: 0.7864, Test Loss: 1.0752\n",
      "Epoch: 170, Train Acc: 0.5582, Test Acc: 0.5200, Train Loss: 0.8562, Test Loss: 1.2222\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 5.0042, Test Loss: 5.6944\n",
      "Epoch: 190, Train Acc: 0.7780, Test Acc: 0.6650, Train Loss: 0.4604, Test Loss: 0.6853\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▂▂▂▂▂▂▂▂▆▄▅▆▆▇▇▇▇█▇▇▇▇▇▃▇▇█▇█▅▆▂▂▂▇▆▃</td></tr><tr><td>Test F1</td><td>▁▁▇▄▂▇▇▇▇▇▇▇▅▆▆▆▇▇▇▇██▇▇██▃▇████▇█▇▇▇█▆▄</td></tr><tr><td>Test Loss</td><td>▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁██▄▁▃▄</td></tr><tr><td>Test Sensitivity</td><td>▁▁█▃▁██████▅▃▄▄▄▅▅▅▅▆▅▅▅▆▆▂▅▆▆▇▆▇▇███▆▄▂</td></tr><tr><td>Test Specificity</td><td>██▁▆█▁▁▁▁▁▁▇████▇██▇▇▇█▇▆▇██▇▇▆▇▅▅▁▁▁▇██</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▆▃▅▄▄▆▆▆▇▇▇▅▇██▂▆▇▇▇█▇▇▂▂▂█▄▂</td></tr><tr><td>Train F1</td><td>▁▁▇▄▁▇▇▇▇▇▇▇▅▆▅▅▇▇▇▇█▇▆▇██▂▇██████▇▇▇█▅▂</td></tr><tr><td>Train Loss</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▅▂▁▁▁▁▁▁██▄▁▃▅</td></tr><tr><td>Train Sensitivity</td><td>▁▁█▃▁██████▅▃▄▃▃▅▅▅▅▆▆▄▆▇▆▁▅▆▆▇▆▇▇███▇▃▂</td></tr><tr><td>Train Specificity</td><td>██▁▆█▁▁▁▁▁▁▇████████████▇███▇▇▇█▆▆▁▁▁▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.52</td></tr><tr><td>Test F1</td><td>0.12727</td></tr><tr><td>Test Loss</td><td>2.52322</td></tr><tr><td>Test Sensitivity</td><td>0.06796</td></tr><tr><td>Test Specificity</td><td>1.0</td></tr><tr><td>Train Accuracy</td><td>0.47845</td></tr><tr><td>Train F1</td><td>0.032</td></tr><tr><td>Train Loss</td><td>2.77392</td></tr><tr><td>Train Sensitivity</td><td>0.01626</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-51</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/wq8e084w' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/wq8e084w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_194804-wq8e084w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t9u6yr5n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00015860304405483262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.209564348360998e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_194906-t9u6yr5n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/t9u6yr5n' target=\"_blank\">pious-sweep-52</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/t9u6yr5n' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/t9u6yr5n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6941, Test Loss: 0.6937\n",
      "Epoch: 010, Train Acc: 0.5172, Test Acc: 0.5500, Train Loss: 0.6930, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5280, Test Acc: 0.5050, Train Loss: 0.6879, Test Loss: 0.6892\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6829, Test Loss: 0.6874\n",
      "Epoch: 040, Train Acc: 0.5927, Test Acc: 0.5400, Train Loss: 0.6750, Test Loss: 0.6798\n",
      "Epoch: 050, Train Acc: 0.6207, Test Acc: 0.5650, Train Loss: 0.6608, Test Loss: 0.6691\n",
      "Epoch: 060, Train Acc: 0.7177, Test Acc: 0.6750, Train Loss: 0.6373, Test Loss: 0.6486\n",
      "Epoch: 070, Train Acc: 0.7134, Test Acc: 0.6650, Train Loss: 0.6096, Test Loss: 0.6250\n",
      "Epoch: 080, Train Acc: 0.7306, Test Acc: 0.6700, Train Loss: 0.5752, Test Loss: 0.6015\n",
      "Epoch: 090, Train Acc: 0.7047, Test Acc: 0.6650, Train Loss: 0.5591, Test Loss: 0.5965\n",
      "Epoch: 100, Train Acc: 0.7328, Test Acc: 0.6750, Train Loss: 0.5397, Test Loss: 0.5821\n",
      "Epoch: 110, Train Acc: 0.7371, Test Acc: 0.6850, Train Loss: 0.5235, Test Loss: 0.5746\n",
      "Epoch: 120, Train Acc: 0.7284, Test Acc: 0.6800, Train Loss: 0.5439, Test Loss: 0.5944\n",
      "Epoch: 130, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.4986, Test Loss: 0.5616\n",
      "Epoch: 140, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4716, Test Loss: 0.5429\n",
      "Epoch: 150, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4578, Test Loss: 0.5367\n",
      "Epoch: 160, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4481, Test Loss: 0.5347\n",
      "Epoch: 170, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4422, Test Loss: 0.5282\n",
      "Epoch: 180, Train Acc: 0.7759, Test Acc: 0.7050, Train Loss: 0.4845, Test Loss: 0.5535\n",
      "Epoch: 190, Train Acc: 0.7522, Test Acc: 0.7100, Train Loss: 0.5307, Test Loss: 0.5908\n",
      "Epoch: 200, Train Acc: 0.7909, Test Acc: 0.7250, Train Loss: 0.4672, Test Loss: 0.5406\n",
      "Epoch: 210, Train Acc: 0.8297, Test Acc: 0.7500, Train Loss: 0.4281, Test Loss: 0.5214\n",
      "Epoch: 220, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4188, Test Loss: 0.5157\n",
      "Epoch: 230, Train Acc: 0.8082, Test Acc: 0.7350, Train Loss: 0.4394, Test Loss: 0.5351\n",
      "Epoch: 240, Train Acc: 0.7737, Test Acc: 0.7150, Train Loss: 0.4901, Test Loss: 0.5774\n",
      "Epoch: 250, Train Acc: 0.8276, Test Acc: 0.7750, Train Loss: 0.4074, Test Loss: 0.5111\n",
      "Epoch: 260, Train Acc: 0.8405, Test Acc: 0.8000, Train Loss: 0.3904, Test Loss: 0.5123\n",
      "Epoch: 270, Train Acc: 0.7996, Test Acc: 0.7250, Train Loss: 0.4506, Test Loss: 0.5501\n",
      "Epoch: 280, Train Acc: 0.8405, Test Acc: 0.7950, Train Loss: 0.3811, Test Loss: 0.5096\n",
      "Epoch: 290, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4456, Test Loss: 0.5501\n",
      "Epoch: 300, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4305, Test Loss: 0.5406\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▁▂▂▂▃▄▅▅▅▅▅▆▅▅▆▅▆▆▇▆▆▆▆▆▆▆▆▆▆▆▇▆█▆▆▇██</td></tr><tr><td>Test F1</td><td>▁▅▇▇▇▇▇▆▇▇▆▇▆▇▆▆▇▆▇▆█▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██</td></tr><tr><td>Test Loss</td><td>█████▇▇▇▆▅▅▄▄▃▄▄▃▃▂▄▂▃▃▃▂▃▂▂▂▂▂▂▂▂▁▃▂▂▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▄▇███▇▅▆▇▅▅▄▆▄▄▆▅▆▄▇▅▅▅▅▅▅▅▅▅▅▅▇▅▇▅▅▅▇▆</td></tr><tr><td>Test Specificity</td><td>█▅▁▁▁▂▂▆▅▅▇▇▇▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▂▃▃▄▅▆▆▅▆▆▇▅▆▇▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███</td></tr><tr><td>Train F1</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇█▇█▇▇▇█▇▇▇▇▇▇▇█▇█▇▇███</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▆▅▅▄▅▅▃▄▃▅▃▄▄▄▃▄▃▃▃▃▃▃▂▃▁▃▃▂▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▄▇██▇▇▆▆▇▅▅▅▆▅▅▇▆▆▅▇▅▅▅▆▅▆▆▆▆▆▆▇▆▇▅▆▆▇▇</td></tr><tr><td>Train Specificity</td><td>█▅▂▁▂▂▃▆▆▆▇▇▇▇▇▇▇▇▇█▆███▇███████▇█▇███▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.755</td></tr><tr><td>Test F1</td><td>0.72928</td></tr><tr><td>Test Loss</td><td>0.52442</td></tr><tr><td>Test Sensitivity</td><td>0.64078</td></tr><tr><td>Test Specificity</td><td>0.87629</td></tr><tr><td>Train Accuracy</td><td>0.82328</td></tr><tr><td>Train F1</td><td>0.81193</td></tr><tr><td>Train Loss</td><td>0.40757</td></tr><tr><td>Train Sensitivity</td><td>0.71951</td></tr><tr><td>Train Specificity</td><td>0.94037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-52</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/t9u6yr5n' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/t9u6yr5n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_194906-t9u6yr5n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uudpwweg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00498769471063491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.8746039318908703e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195043-uudpwweg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/uudpwweg' target=\"_blank\">youthful-sweep-53</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/uudpwweg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/uudpwweg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7042, Test Loss: 0.7100\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7044, Test Loss: 0.7137\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6936\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6919\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6912\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6870, Test Loss: 0.6879\n",
      "Epoch: 060, Train Acc: 0.6746, Test Acc: 0.6450, Train Loss: 0.6331, Test Loss: 0.6400\n",
      "Epoch: 070, Train Acc: 0.7026, Test Acc: 0.6750, Train Loss: 0.5923, Test Loss: 0.6164\n",
      "Epoch: 080, Train Acc: 0.6401, Test Acc: 0.6800, Train Loss: 0.7155, Test Loss: 0.6913\n",
      "Epoch: 090, Train Acc: 0.7435, Test Acc: 0.7450, Train Loss: 0.5676, Test Loss: 0.5769\n",
      "Epoch: 100, Train Acc: 0.6918, Test Acc: 0.7350, Train Loss: 0.6544, Test Loss: 0.6308\n",
      "Epoch: 110, Train Acc: 0.7672, Test Acc: 0.7550, Train Loss: 0.5184, Test Loss: 0.5394\n",
      "Epoch: 120, Train Acc: 0.8190, Test Acc: 0.7800, Train Loss: 0.4355, Test Loss: 0.5082\n",
      "Epoch: 130, Train Acc: 0.7414, Test Acc: 0.7400, Train Loss: 0.5625, Test Loss: 0.5871\n",
      "Epoch: 140, Train Acc: 0.8384, Test Acc: 0.7950, Train Loss: 0.4151, Test Loss: 0.5136\n",
      "Epoch: 150, Train Acc: 0.6746, Test Acc: 0.7050, Train Loss: 0.7163, Test Loss: 0.7277\n",
      "Epoch: 160, Train Acc: 0.6379, Test Acc: 0.6850, Train Loss: 0.8771, Test Loss: 0.8969\n",
      "Epoch: 170, Train Acc: 0.8427, Test Acc: 0.7700, Train Loss: 0.3876, Test Loss: 0.5368\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▂▂▅▄▅▅▆▆▆▇▇▇█▇███▇▇▆▇██▅██▆▇▇</td></tr><tr><td>Test F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▇▆▅▆▆▆▆▆▇▇▇█▇███▇▇█▇██▅███▇▇</td></tr><tr><td>Test Loss</td><td>▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▄▃▃▃▃▂▃▁▂▁▁▁▂▂▂▃▁▁█▁▁▃▄▅</td></tr><tr><td>Test Sensitivity</td><td>▁▁██▁████████▄▃▄▄▄▄▄▄▅▅▅▅▆▅▅▅▅▇▅▆▆▃▆▆▇▅▅</td></tr><tr><td>Test Specificity</td><td>██▁▁█▁▁▁▁▁▁▁▁▇▇▇███████▇█▇▇▇██▅█▇▇█▇▇▅██</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▂▂▅▄▄▄▅▅▅▅▆▅▇▆▇▇▇▆▆▆▆█▇▃██▇▅▆</td></tr><tr><td>Train F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▇▆▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▆█▇█▇▄███▆▆</td></tr><tr><td>Train Loss</td><td>▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▅▃▄▄▄▃▄▂▃▂▂▂▃▃▂▃▁▂█▁▁▁▄▄</td></tr><tr><td>Train Sensitivity</td><td>▁▁██▁████████▄▄▄▄▄▄▄▄▅▄▆▅▆▅▅▅▅▇▅▇▆▃▆▇▇▄▄</td></tr><tr><td>Train Specificity</td><td>██▁▁█▁▁▁▁▁▁▁▁▇████████████████▅█▇███▇▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.78</td></tr><tr><td>Test F1</td><td>0.76344</td></tr><tr><td>Test Loss</td><td>0.5633</td></tr><tr><td>Test Sensitivity</td><td>0.68932</td></tr><tr><td>Test Specificity</td><td>0.87629</td></tr><tr><td>Train Accuracy</td><td>0.84052</td></tr><tr><td>Train F1</td><td>0.82791</td></tr><tr><td>Train Loss</td><td>0.38682</td></tr><tr><td>Train Sensitivity</td><td>0.72358</td></tr><tr><td>Train Specificity</td><td>0.97248</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-53</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/uudpwweg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/uudpwweg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195043-uudpwweg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rug80jo2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003982003716639433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.6927540428135133e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195145-rug80jo2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/rug80jo2' target=\"_blank\">noble-sweep-54</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/rug80jo2' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/rug80jo2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4677, Test Acc: 0.5200, Train Loss: 0.6933, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5259, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6916\n",
      "Epoch: 020, Train Acc: 0.5711, Test Acc: 0.5500, Train Loss: 0.6853, Test Loss: 0.6865\n",
      "Epoch: 030, Train Acc: 0.6422, Test Acc: 0.6150, Train Loss: 0.6671, Test Loss: 0.6712\n",
      "Epoch: 040, Train Acc: 0.6961, Test Acc: 0.6850, Train Loss: 0.6225, Test Loss: 0.6349\n",
      "Epoch: 050, Train Acc: 0.6379, Test Acc: 0.6250, Train Loss: 0.5982, Test Loss: 0.6199\n",
      "Epoch: 060, Train Acc: 0.6983, Test Acc: 0.6700, Train Loss: 0.5626, Test Loss: 0.6018\n",
      "Epoch: 070, Train Acc: 0.7349, Test Acc: 0.6750, Train Loss: 0.5257, Test Loss: 0.5798\n",
      "Epoch: 080, Train Acc: 0.7586, Test Acc: 0.6900, Train Loss: 0.5014, Test Loss: 0.5587\n",
      "Epoch: 090, Train Acc: 0.7522, Test Acc: 0.7000, Train Loss: 0.5159, Test Loss: 0.5794\n",
      "Epoch: 100, Train Acc: 0.6185, Test Acc: 0.6350, Train Loss: 0.7831, Test Loss: 0.8042\n",
      "Epoch: 110, Train Acc: 0.6466, Test Acc: 0.6550, Train Loss: 0.7336, Test Loss: 0.7583\n",
      "Epoch: 120, Train Acc: 0.8297, Test Acc: 0.7700, Train Loss: 0.4233, Test Loss: 0.5153\n",
      "Epoch: 130, Train Acc: 0.7306, Test Acc: 0.7200, Train Loss: 0.5645, Test Loss: 0.6247\n",
      "Epoch: 140, Train Acc: 0.7543, Test Acc: 0.7150, Train Loss: 0.5427, Test Loss: 0.5998\n",
      "Epoch: 150, Train Acc: 0.7823, Test Acc: 0.7200, Train Loss: 0.4982, Test Loss: 0.5754\n",
      "Epoch: 160, Train Acc: 0.5948, Test Acc: 0.6300, Train Loss: 1.0207, Test Loss: 1.0197\n",
      "Epoch: 170, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4668, Test Loss: 0.5647\n",
      "Epoch: 180, Train Acc: 0.7866, Test Acc: 0.7350, Train Loss: 0.4735, Test Loss: 0.5695\n",
      "Epoch: 190, Train Acc: 0.6659, Test Acc: 0.6850, Train Loss: 0.7678, Test Loss: 0.8249\n",
      "Epoch: 200, Train Acc: 0.8642, Test Acc: 0.8050, Train Loss: 0.3669, Test Loss: 0.5109\n",
      "Epoch: 210, Train Acc: 0.8470, Test Acc: 0.7950, Train Loss: 0.3609, Test Loss: 0.5327\n",
      "Epoch: 220, Train Acc: 0.7694, Test Acc: 0.7300, Train Loss: 0.5067, Test Loss: 0.6253\n",
      "Epoch: 230, Train Acc: 0.8254, Test Acc: 0.7500, Train Loss: 0.3974, Test Loss: 0.5580\n",
      "Epoch: 240, Train Acc: 0.8599, Test Acc: 0.7600, Train Loss: 0.3609, Test Loss: 0.5464\n",
      "Epoch: 250, Train Acc: 0.8621, Test Acc: 0.7750, Train Loss: 0.3528, Test Loss: 0.5404\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▃▄▄▅▅▆▅▆▅▅▆▅▆▇▆▆▇▆▇▆▆▇▇▆▆█▇▇█▇▇▆▇██▇▅</td></tr><tr><td>Test F1</td><td>▁▁▁▄▆▇▆▇█▆▇▇▇▇▆▇▇▇▆▇▆█▇▇▇▇▇▇█▇▇█▇▇▆▇███▇</td></tr><tr><td>Test Loss</td><td>▅▅▅▅▅▄▄▃▃▃▂▂▂▂▄▂▁▄▄▁▅▁▃▂▄▂▂▆▂▄▄▁▂▂█▁▁▁▂▆</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▃▆▇▅▆▇▅▆▅▅▅▄▅▆▅▅▆▅▇▅▅▅▆▅▅▇▅▅▆▆▆▅▆▇▇▇█</td></tr><tr><td>Test Specificity</td><td>███▇▃▂▆▅▄▇▅▆▆▇▇▇▇▇█▇█▆▇▇█▇▇█▅▇▇▇▇▇█▇▆▆▅▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▃▄▅▆▆▅▆▇▇▆▅▆▇▅▅▇▅▇▆▇▅▇▇▅▇▆▆█▇▇▅████▆</td></tr><tr><td>Train F1</td><td>▁▁▁▄▆▇▆▇▇▆▇▇▇▇▆▇▇▆▆█▆█▇▇▆▇▇▆█▇▆██▇▅█████</td></tr><tr><td>Train Loss</td><td>▇▇▇▇▇▆▆▅▄▄▄▄▃▄▅▃▃▅▆▃▇▂▄▃▅▃▃▇▂▄▅▂▂▃█▂▁▁▁▃</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▃▆▇▅▆▇▅▇▆▆▅▄▆▆▅▄▆▄▇▅▆▄▆▆▄▇▅▅▇▆▆▄▆▇▇▇█</td></tr><tr><td>Train Specificity</td><td>███▇▂▁▆▅▄▇▅▆▆▇▇▇▇██▇█▆███▇██▅██▇▇███▇▇▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.775</td></tr><tr><td>Test F1</td><td>0.7541</td></tr><tr><td>Test Loss</td><td>0.54037</td></tr><tr><td>Test Sensitivity</td><td>0.6699</td></tr><tr><td>Test Specificity</td><td>0.8866</td></tr><tr><td>Train Accuracy</td><td>0.86207</td></tr><tr><td>Train F1</td><td>0.85586</td></tr><tr><td>Train Loss</td><td>0.35285</td></tr><tr><td>Train Sensitivity</td><td>0.77236</td></tr><tr><td>Train Specificity</td><td>0.9633</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-54</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/rug80jo2' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/rug80jo2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195145-rug80jo2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j9at586k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.4537735839905063e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0017303597669902444\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195307-j9at586k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/j9at586k' target=\"_blank\">expert-sweep-55</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/j9at586k' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/j9at586k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6939, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5108, Test Acc: 0.5050, Train Loss: 0.6928, Test Loss: 0.6927\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6914, Test Loss: 0.6917\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6905, Test Loss: 0.6917\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6918\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6918\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6918\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6899, Test Loss: 0.6918\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▅▆█▆▅▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test F1</td><td>▁▁▁▂▅▇▇▇▇███████████████████████████████</td></tr><tr><td>Test Loss</td><td>███▇▆▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▃▅▆▆▇███████████████████████████████</td></tr><tr><td>Test Specificity</td><td>████▆▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▇▅▄▆███▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train F1</td><td>▁▁▁▁▅▇▇▇████████████████████████████████</td></tr><tr><td>Train Loss</td><td>███▇▇▆▆▅▅▄▄▄▃▂▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▁▁▁▂▂▁▂▂▂▂▂</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▃▅▆▆▇▇██████████████████████████████</td></tr><tr><td>Train Specificity</td><td>████▆▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69176</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69071</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-55</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/j9at586k' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/j9at586k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195307-j9at586k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jkeljdrf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.243638886193042e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.3332279704098067e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195349-jkeljdrf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/jkeljdrf' target=\"_blank\">rose-sweep-56</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/jkeljdrf' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/jkeljdrf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6933\n",
      "Epoch: 010, Train Acc: 0.5323, Test Acc: 0.5100, Train Loss: 0.6925, Test Loss: 0.6932\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6924, Test Loss: 0.6933\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6918, Test Loss: 0.6932\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6933\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6918, Test Loss: 0.6933\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█████▆▆▆▃▃▁▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████</td></tr><tr><td>Test F1</td><td>█████▆▆▆▃▃▁▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████</td></tr><tr><td>Test Loss</td><td>▇▅▃▁▁▂▃▅▇▇████▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test Sensitivity</td><td>█████▆▆▆▃▃▁▁▁▃▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▅▅▅▅▅▅▅█▁▅▅▅▅▁▁▅████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Train F1</td><td>▆▆▆▆▆▆▆█▁▃▁▁▁▁▁▅████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Train Loss</td><td>▂▃▃▄▃▅▆▆▇████▇▇▆▆▅▅▅▅▅▄▄▃▄▃▄▁▃▃▃▄▂▃▄▄▁▂▄</td></tr><tr><td>Train Sensitivity</td><td>████████▃▃▁▁▁▃▃▆████████████████████████</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▃▃▆███▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69329</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.53017</td></tr><tr><td>Train F1</td><td>0.69296</td></tr><tr><td>Train Loss</td><td>0.69185</td></tr><tr><td>Train Sensitivity</td><td>1.0</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-56</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/jkeljdrf' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/jkeljdrf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195349-jkeljdrf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yk75hzr6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.375900263754598e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.553642417091371e-06\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195415-yk75hzr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/yk75hzr6' target=\"_blank\">youthful-sweep-57</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/yk75hzr6' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/yk75hzr6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6950, Test Loss: 0.6943\n",
      "Epoch: 010, Train Acc: 0.4849, Test Acc: 0.5050, Train Loss: 0.6934, Test Loss: 0.6930\n",
      "Epoch: 020, Train Acc: 0.5345, Test Acc: 0.4850, Train Loss: 0.6900, Test Loss: 0.6909\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6905\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6866, Test Loss: 0.6898\n",
      "Epoch: 050, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6882\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6838, Test Loss: 0.6875\n",
      "Epoch: 070, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6809, Test Loss: 0.6848\n",
      "Epoch: 080, Train Acc: 0.5539, Test Acc: 0.5200, Train Loss: 0.6772, Test Loss: 0.6821\n",
      "Epoch: 090, Train Acc: 0.5625, Test Acc: 0.5150, Train Loss: 0.6726, Test Loss: 0.6784\n",
      "Epoch: 100, Train Acc: 0.6056, Test Acc: 0.5500, Train Loss: 0.6670, Test Loss: 0.6728\n",
      "Epoch: 110, Train Acc: 0.6595, Test Acc: 0.6000, Train Loss: 0.6578, Test Loss: 0.6656\n",
      "Epoch: 120, Train Acc: 0.7091, Test Acc: 0.6350, Train Loss: 0.6465, Test Loss: 0.6570\n",
      "Epoch: 130, Train Acc: 0.7349, Test Acc: 0.6800, Train Loss: 0.6346, Test Loss: 0.6467\n",
      "Epoch: 140, Train Acc: 0.7457, Test Acc: 0.6700, Train Loss: 0.6209, Test Loss: 0.6359\n",
      "Epoch: 150, Train Acc: 0.7392, Test Acc: 0.6750, Train Loss: 0.6048, Test Loss: 0.6244\n",
      "Epoch: 160, Train Acc: 0.7328, Test Acc: 0.6650, Train Loss: 0.5903, Test Loss: 0.6130\n",
      "Epoch: 170, Train Acc: 0.7414, Test Acc: 0.6650, Train Loss: 0.5737, Test Loss: 0.6026\n",
      "Epoch: 180, Train Acc: 0.7241, Test Acc: 0.6700, Train Loss: 0.5641, Test Loss: 0.5956\n",
      "Epoch: 190, Train Acc: 0.7371, Test Acc: 0.6800, Train Loss: 0.5514, Test Loss: 0.5881\n",
      "Epoch: 200, Train Acc: 0.7414, Test Acc: 0.6700, Train Loss: 0.5407, Test Loss: 0.5809\n",
      "Epoch: 210, Train Acc: 0.7672, Test Acc: 0.6900, Train Loss: 0.5263, Test Loss: 0.5733\n",
      "Epoch: 220, Train Acc: 0.7802, Test Acc: 0.6800, Train Loss: 0.5128, Test Loss: 0.5680\n",
      "Epoch: 230, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5043, Test Loss: 0.5646\n",
      "Epoch: 240, Train Acc: 0.7478, Test Acc: 0.6750, Train Loss: 0.5097, Test Loss: 0.5676\n",
      "Epoch: 250, Train Acc: 0.7974, Test Acc: 0.7350, Train Loss: 0.4870, Test Loss: 0.5585\n",
      "Epoch: 260, Train Acc: 0.7888, Test Acc: 0.6850, Train Loss: 0.4909, Test Loss: 0.5530\n",
      "Epoch: 270, Train Acc: 0.7953, Test Acc: 0.7300, Train Loss: 0.4746, Test Loss: 0.5488\n",
      "Epoch: 280, Train Acc: 0.7953, Test Acc: 0.6950, Train Loss: 0.4778, Test Loss: 0.5466\n",
      "Epoch: 290, Train Acc: 0.7996, Test Acc: 0.7500, Train Loss: 0.4641, Test Loss: 0.5423\n",
      "Epoch: 300, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4593, Test Loss: 0.5417\n",
      "Epoch: 310, Train Acc: 0.7953, Test Acc: 0.7050, Train Loss: 0.4639, Test Loss: 0.5394\n",
      "Epoch: 320, Train Acc: 0.7802, Test Acc: 0.7050, Train Loss: 0.4789, Test Loss: 0.5480\n",
      "Epoch: 330, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4460, Test Loss: 0.5335\n",
      "Epoch: 340, Train Acc: 0.8125, Test Acc: 0.7650, Train Loss: 0.4433, Test Loss: 0.5283\n",
      "Epoch: 350, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4691, Test Loss: 0.5397\n",
      "Epoch: 360, Train Acc: 0.8168, Test Acc: 0.7700, Train Loss: 0.4354, Test Loss: 0.5276\n",
      "Epoch: 370, Train Acc: 0.7996, Test Acc: 0.7400, Train Loss: 0.4475, Test Loss: 0.5274\n",
      "Epoch: 380, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4500, Test Loss: 0.5272\n",
      "Epoch: 390, Train Acc: 0.8082, Test Acc: 0.7400, Train Loss: 0.4392, Test Loss: 0.5215\n",
      "Epoch: 400, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4304, Test Loss: 0.5186\n",
      "Epoch: 410, Train Acc: 0.8039, Test Acc: 0.7250, Train Loss: 0.4463, Test Loss: 0.5289\n",
      "Epoch: 420, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4312, Test Loss: 0.5187\n",
      "Epoch: 430, Train Acc: 0.8297, Test Acc: 0.7750, Train Loss: 0.4160, Test Loss: 0.5142\n",
      "Epoch: 440, Train Acc: 0.8254, Test Acc: 0.7900, Train Loss: 0.4062, Test Loss: 0.5173\n",
      "Epoch: 450, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4193, Test Loss: 0.5130\n",
      "Epoch: 460, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4121, Test Loss: 0.5118\n",
      "Epoch: 470, Train Acc: 0.8297, Test Acc: 0.7950, Train Loss: 0.4022, Test Loss: 0.5127\n",
      "Epoch: 480, Train Acc: 0.8319, Test Acc: 0.7950, Train Loss: 0.3965, Test Loss: 0.5098\n",
      "Epoch: 490, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4030, Test Loss: 0.5102\n",
      "Epoch: 500, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4066, Test Loss: 0.5336\n",
      "Epoch: 510, Train Acc: 0.8341, Test Acc: 0.8050, Train Loss: 0.3912, Test Loss: 0.5134\n",
      "Epoch: 520, Train Acc: 0.8319, Test Acc: 0.8100, Train Loss: 0.3863, Test Loss: 0.5127\n",
      "Epoch: 530, Train Acc: 0.8362, Test Acc: 0.8050, Train Loss: 0.3824, Test Loss: 0.5145\n",
      "Epoch: 540, Train Acc: 0.8448, Test Acc: 0.7550, Train Loss: 0.3935, Test Loss: 0.5140\n",
      "Epoch: 550, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4035, Test Loss: 0.5183\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▂▂▂▄▅▅▅▅▅▅▅▅▅▆▆▅▇▇▆▆▆▇▇▇█▇▇██▇█▇██▇</td></tr><tr><td>Test F1</td><td>▁▇▇▇▇▇▇▇▇▇▇▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇█▇▇█████▇█▇██▇</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▆▅▅▄▄▃▃▃▃▂▃▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>Test Sensitivity</td><td>▁█████▇█▇▆▇▅▅▅▅▅▅▅▅▆▅▆▆▅▅▅▆▆▅▇▆▆▇▇▅▇▅▆▆▅</td></tr><tr><td>Test Specificity</td><td>█▁▁▁▁▁▂▁▃▅▅▆▆▆▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▂▂▃▃▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇█▇▇███████▇██▇</td></tr><tr><td>Train F1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████████████████</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂</td></tr><tr><td>Train Sensitivity</td><td>▁█████▇█▇▆▇▆▆▆▅▅▅▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▆▇▆▇▇▆</td></tr><tr><td>Train Specificity</td><td>█▁▁▁▁▁▃▂▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.775</td></tr><tr><td>Test F1</td><td>0.78873</td></tr><tr><td>Test Loss</td><td>0.52886</td></tr><tr><td>Test Sensitivity</td><td>0.81553</td></tr><tr><td>Test Specificity</td><td>0.73196</td></tr><tr><td>Train Accuracy</td><td>0.82328</td></tr><tr><td>Train F1</td><td>0.836</td></tr><tr><td>Train Loss</td><td>0.38311</td></tr><tr><td>Train Sensitivity</td><td>0.84959</td></tr><tr><td>Train Specificity</td><td>0.79358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-57</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/yk75hzr6' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/yk75hzr6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195415-yk75hzr6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qx1pd99j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.2609173789278554e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.7461667115129103e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_195704-qx1pd99j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/qx1pd99j' target=\"_blank\">sage-sweep-58</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qx1pd99j' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qx1pd99j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6916, Test Loss: 0.6932\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6933\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6928\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6927\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6925\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6897, Test Loss: 0.6923\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6919\n",
      "Epoch: 080, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6917\n",
      "Epoch: 090, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6917\n",
      "Epoch: 100, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6893, Test Loss: 0.6913\n",
      "Epoch: 110, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6891, Test Loss: 0.6912\n",
      "Epoch: 120, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6913\n",
      "Epoch: 130, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6888, Test Loss: 0.6911\n",
      "Epoch: 140, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6908\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6882, Test Loss: 0.6908\n",
      "Epoch: 160, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6905\n",
      "Epoch: 170, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6905\n",
      "Epoch: 180, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6876, Test Loss: 0.6903\n",
      "Epoch: 190, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6879, Test Loss: 0.6903\n",
      "Epoch: 200, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6880, Test Loss: 0.6902\n",
      "Epoch: 210, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6875, Test Loss: 0.6901\n",
      "Epoch: 220, Train Acc: 0.5388, Test Acc: 0.5200, Train Loss: 0.6869, Test Loss: 0.6896\n",
      "Epoch: 230, Train Acc: 0.5323, Test Acc: 0.5250, Train Loss: 0.6875, Test Loss: 0.6895\n",
      "Epoch: 240, Train Acc: 0.5366, Test Acc: 0.5250, Train Loss: 0.6870, Test Loss: 0.6893\n",
      "Epoch: 250, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6860, Test Loss: 0.6892\n",
      "Epoch: 260, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6860, Test Loss: 0.6893\n",
      "Epoch: 270, Train Acc: 0.5431, Test Acc: 0.5150, Train Loss: 0.6867, Test Loss: 0.6888\n",
      "Epoch: 280, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6886\n",
      "Epoch: 290, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6852, Test Loss: 0.6887\n",
      "Epoch: 300, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6853, Test Loss: 0.6882\n",
      "Epoch: 310, Train Acc: 0.5496, Test Acc: 0.5150, Train Loss: 0.6856, Test Loss: 0.6881\n",
      "Epoch: 320, Train Acc: 0.5453, Test Acc: 0.5150, Train Loss: 0.6846, Test Loss: 0.6879\n",
      "Epoch: 330, Train Acc: 0.5582, Test Acc: 0.5150, Train Loss: 0.6840, Test Loss: 0.6875\n",
      "Epoch: 340, Train Acc: 0.5690, Test Acc: 0.5150, Train Loss: 0.6840, Test Loss: 0.6872\n",
      "Epoch: 350, Train Acc: 0.5302, Test Acc: 0.5200, Train Loss: 0.6832, Test Loss: 0.6874\n",
      "Epoch: 360, Train Acc: 0.5603, Test Acc: 0.5150, Train Loss: 0.6834, Test Loss: 0.6868\n",
      "Epoch: 370, Train Acc: 0.5819, Test Acc: 0.5250, Train Loss: 0.6831, Test Loss: 0.6864\n",
      "Epoch: 380, Train Acc: 0.5819, Test Acc: 0.5200, Train Loss: 0.6824, Test Loss: 0.6861\n",
      "Epoch: 390, Train Acc: 0.5819, Test Acc: 0.5300, Train Loss: 0.6819, Test Loss: 0.6858\n",
      "Epoch: 400, Train Acc: 0.5754, Test Acc: 0.5150, Train Loss: 0.6820, Test Loss: 0.6856\n",
      "Epoch: 410, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6818, Test Loss: 0.6852\n",
      "Epoch: 420, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6818, Test Loss: 0.6849\n",
      "Epoch: 430, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6802, Test Loss: 0.6845\n",
      "Epoch: 440, Train Acc: 0.5862, Test Acc: 0.5250, Train Loss: 0.6798, Test Loss: 0.6841\n",
      "Epoch: 450, Train Acc: 0.5776, Test Acc: 0.5150, Train Loss: 0.6793, Test Loss: 0.6838\n",
      "Epoch: 460, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6789, Test Loss: 0.6834\n",
      "Epoch: 470, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6781, Test Loss: 0.6828\n",
      "Epoch: 480, Train Acc: 0.5862, Test Acc: 0.5200, Train Loss: 0.6775, Test Loss: 0.6824\n",
      "Epoch: 490, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6764, Test Loss: 0.6819\n",
      "Epoch: 500, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6769, Test Loss: 0.6813\n",
      "Epoch: 510, Train Acc: 0.5668, Test Acc: 0.5200, Train Loss: 0.6759, Test Loss: 0.6811\n",
      "Epoch: 520, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6743, Test Loss: 0.6803\n",
      "Epoch: 530, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6740, Test Loss: 0.6797\n",
      "Epoch: 540, Train Acc: 0.6034, Test Acc: 0.5300, Train Loss: 0.6737, Test Loss: 0.6791\n",
      "Epoch: 550, Train Acc: 0.6056, Test Acc: 0.5450, Train Loss: 0.6732, Test Loss: 0.6783\n",
      "Epoch: 560, Train Acc: 0.5970, Test Acc: 0.5350, Train Loss: 0.6716, Test Loss: 0.6779\n",
      "Epoch: 570, Train Acc: 0.6078, Test Acc: 0.5500, Train Loss: 0.6713, Test Loss: 0.6769\n",
      "Epoch: 580, Train Acc: 0.6121, Test Acc: 0.5600, Train Loss: 0.6699, Test Loss: 0.6762\n",
      "Epoch: 590, Train Acc: 0.6121, Test Acc: 0.5600, Train Loss: 0.6689, Test Loss: 0.6754\n",
      "Epoch: 600, Train Acc: 0.6315, Test Acc: 0.5700, Train Loss: 0.6676, Test Loss: 0.6745\n",
      "Epoch: 610, Train Acc: 0.6185, Test Acc: 0.5650, Train Loss: 0.6665, Test Loss: 0.6738\n",
      "Epoch: 620, Train Acc: 0.6315, Test Acc: 0.5750, Train Loss: 0.6655, Test Loss: 0.6728\n",
      "Epoch: 630, Train Acc: 0.6272, Test Acc: 0.5700, Train Loss: 0.6645, Test Loss: 0.6720\n",
      "Epoch: 640, Train Acc: 0.6422, Test Acc: 0.5700, Train Loss: 0.6632, Test Loss: 0.6709\n",
      "Epoch: 650, Train Acc: 0.6595, Test Acc: 0.5850, Train Loss: 0.6615, Test Loss: 0.6697\n",
      "Epoch: 660, Train Acc: 0.6659, Test Acc: 0.5850, Train Loss: 0.6601, Test Loss: 0.6686\n",
      "Epoch: 670, Train Acc: 0.6703, Test Acc: 0.5850, Train Loss: 0.6587, Test Loss: 0.6676\n",
      "Epoch: 680, Train Acc: 0.6746, Test Acc: 0.6000, Train Loss: 0.6563, Test Loss: 0.6665\n",
      "Epoch: 690, Train Acc: 0.6832, Test Acc: 0.6000, Train Loss: 0.6565, Test Loss: 0.6652\n",
      "Epoch: 700, Train Acc: 0.6832, Test Acc: 0.6050, Train Loss: 0.6538, Test Loss: 0.6640\n",
      "Epoch: 710, Train Acc: 0.6897, Test Acc: 0.6100, Train Loss: 0.6524, Test Loss: 0.6627\n",
      "Epoch: 720, Train Acc: 0.6940, Test Acc: 0.6200, Train Loss: 0.6517, Test Loss: 0.6615\n",
      "Epoch: 730, Train Acc: 0.7004, Test Acc: 0.6300, Train Loss: 0.6493, Test Loss: 0.6601\n",
      "Epoch: 740, Train Acc: 0.6983, Test Acc: 0.6350, Train Loss: 0.6471, Test Loss: 0.6588\n",
      "Epoch: 750, Train Acc: 0.7004, Test Acc: 0.6300, Train Loss: 0.6450, Test Loss: 0.6576\n",
      "Epoch: 760, Train Acc: 0.7091, Test Acc: 0.6550, Train Loss: 0.6443, Test Loss: 0.6559\n",
      "Epoch: 770, Train Acc: 0.7047, Test Acc: 0.6400, Train Loss: 0.6422, Test Loss: 0.6546\n",
      "Epoch: 780, Train Acc: 0.7177, Test Acc: 0.6700, Train Loss: 0.6393, Test Loss: 0.6530\n",
      "Epoch: 790, Train Acc: 0.7263, Test Acc: 0.6750, Train Loss: 0.6376, Test Loss: 0.6515\n",
      "Epoch: 800, Train Acc: 0.7284, Test Acc: 0.6700, Train Loss: 0.6356, Test Loss: 0.6500\n",
      "Epoch: 810, Train Acc: 0.7435, Test Acc: 0.6850, Train Loss: 0.6344, Test Loss: 0.6484\n",
      "Epoch: 820, Train Acc: 0.7414, Test Acc: 0.6800, Train Loss: 0.6319, Test Loss: 0.6469\n",
      "Epoch: 830, Train Acc: 0.7500, Test Acc: 0.6800, Train Loss: 0.6295, Test Loss: 0.6452\n",
      "Epoch: 840, Train Acc: 0.7522, Test Acc: 0.6650, Train Loss: 0.6276, Test Loss: 0.6435\n",
      "Epoch: 850, Train Acc: 0.7522, Test Acc: 0.6700, Train Loss: 0.6263, Test Loss: 0.6420\n",
      "Epoch: 860, Train Acc: 0.7565, Test Acc: 0.6650, Train Loss: 0.6234, Test Loss: 0.6401\n",
      "Epoch: 870, Train Acc: 0.7608, Test Acc: 0.6650, Train Loss: 0.6206, Test Loss: 0.6385\n",
      "Epoch: 880, Train Acc: 0.7608, Test Acc: 0.6750, Train Loss: 0.6182, Test Loss: 0.6370\n",
      "Epoch: 890, Train Acc: 0.7694, Test Acc: 0.6750, Train Loss: 0.6165, Test Loss: 0.6351\n",
      "Epoch: 900, Train Acc: 0.7672, Test Acc: 0.6750, Train Loss: 0.6143, Test Loss: 0.6337\n",
      "Epoch: 910, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.6111, Test Loss: 0.6316\n",
      "Epoch: 920, Train Acc: 0.7651, Test Acc: 0.6800, Train Loss: 0.6083, Test Loss: 0.6300\n",
      "Epoch: 930, Train Acc: 0.7716, Test Acc: 0.6850, Train Loss: 0.6062, Test Loss: 0.6285\n",
      "Epoch: 940, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.6054, Test Loss: 0.6267\n",
      "Epoch: 950, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.6027, Test Loss: 0.6251\n",
      "Epoch: 960, Train Acc: 0.7586, Test Acc: 0.6800, Train Loss: 0.5989, Test Loss: 0.6231\n",
      "Epoch: 970, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5977, Test Loss: 0.6220\n",
      "Epoch: 980, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5952, Test Loss: 0.6200\n",
      "Epoch: 990, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.5914, Test Loss: 0.6182\n",
      "Epoch: 1000, Train Acc: 0.7651, Test Acc: 0.6900, Train Loss: 0.5895, Test Loss: 0.6169\n",
      "Epoch: 1010, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5900, Test Loss: 0.6151\n",
      "Epoch: 1020, Train Acc: 0.7672, Test Acc: 0.6950, Train Loss: 0.5859, Test Loss: 0.6139\n",
      "Epoch: 1030, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5829, Test Loss: 0.6121\n",
      "Epoch: 1040, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5804, Test Loss: 0.6106\n",
      "Epoch: 1050, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.5774, Test Loss: 0.6090\n",
      "Epoch: 1060, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5761, Test Loss: 0.6079\n",
      "Epoch: 1070, Train Acc: 0.7651, Test Acc: 0.6950, Train Loss: 0.5759, Test Loss: 0.6062\n",
      "Epoch: 1080, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5720, Test Loss: 0.6049\n",
      "Epoch: 1090, Train Acc: 0.7716, Test Acc: 0.6900, Train Loss: 0.5689, Test Loss: 0.6037\n",
      "Epoch: 1100, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5675, Test Loss: 0.6023\n",
      "Epoch: 1110, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5666, Test Loss: 0.6014\n",
      "Epoch: 1120, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5642, Test Loss: 0.5996\n",
      "Epoch: 1130, Train Acc: 0.7694, Test Acc: 0.7000, Train Loss: 0.5610, Test Loss: 0.5985\n",
      "Epoch: 1140, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5604, Test Loss: 0.5972\n",
      "Epoch: 1150, Train Acc: 0.7716, Test Acc: 0.7000, Train Loss: 0.5573, Test Loss: 0.5960\n",
      "Epoch: 1160, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5577, Test Loss: 0.5948\n",
      "Epoch: 1170, Train Acc: 0.7759, Test Acc: 0.6950, Train Loss: 0.5540, Test Loss: 0.5939\n",
      "Epoch: 1180, Train Acc: 0.7759, Test Acc: 0.7000, Train Loss: 0.5512, Test Loss: 0.5928\n",
      "Epoch: 1190, Train Acc: 0.7802, Test Acc: 0.6950, Train Loss: 0.5482, Test Loss: 0.5914\n",
      "Epoch: 1200, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5491, Test Loss: 0.5903\n",
      "Epoch: 1210, Train Acc: 0.7802, Test Acc: 0.7000, Train Loss: 0.5472, Test Loss: 0.5892\n",
      "Epoch: 1220, Train Acc: 0.7823, Test Acc: 0.6850, Train Loss: 0.5413, Test Loss: 0.5887\n",
      "Epoch: 1230, Train Acc: 0.7845, Test Acc: 0.6950, Train Loss: 0.5429, Test Loss: 0.5878\n",
      "Epoch: 1240, Train Acc: 0.7845, Test Acc: 0.6950, Train Loss: 0.5406, Test Loss: 0.5866\n",
      "Epoch: 1250, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5437, Test Loss: 0.5853\n",
      "Epoch: 1260, Train Acc: 0.7845, Test Acc: 0.6950, Train Loss: 0.5378, Test Loss: 0.5851\n",
      "Epoch: 1270, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5350, Test Loss: 0.5839\n",
      "Epoch: 1280, Train Acc: 0.7802, Test Acc: 0.6900, Train Loss: 0.5344, Test Loss: 0.5828\n",
      "Epoch: 1290, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.5323, Test Loss: 0.5823\n",
      "Epoch: 1300, Train Acc: 0.7845, Test Acc: 0.6900, Train Loss: 0.5312, Test Loss: 0.5813\n",
      "Epoch: 1310, Train Acc: 0.7823, Test Acc: 0.6900, Train Loss: 0.5296, Test Loss: 0.5803\n",
      "Epoch: 1320, Train Acc: 0.7866, Test Acc: 0.7000, Train Loss: 0.5261, Test Loss: 0.5801\n",
      "Epoch: 1330, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.5254, Test Loss: 0.5788\n",
      "Epoch: 1340, Train Acc: 0.7866, Test Acc: 0.7000, Train Loss: 0.5251, Test Loss: 0.5786\n",
      "Epoch: 1350, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.5239, Test Loss: 0.5775\n",
      "Epoch: 1360, Train Acc: 0.7888, Test Acc: 0.6900, Train Loss: 0.5229, Test Loss: 0.5771\n",
      "Epoch: 1370, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5210, Test Loss: 0.5765\n",
      "Epoch: 1380, Train Acc: 0.7909, Test Acc: 0.6900, Train Loss: 0.5198, Test Loss: 0.5758\n",
      "Epoch: 1390, Train Acc: 0.7866, Test Acc: 0.7000, Train Loss: 0.5195, Test Loss: 0.5749\n",
      "Epoch: 1400, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5147, Test Loss: 0.5742\n",
      "Epoch: 1410, Train Acc: 0.7953, Test Acc: 0.7000, Train Loss: 0.5147, Test Loss: 0.5742\n",
      "Epoch: 1420, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.5130, Test Loss: 0.5732\n",
      "Epoch: 1430, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.5119, Test Loss: 0.5725\n",
      "Epoch: 1440, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.5120, Test Loss: 0.5720\n",
      "Epoch: 1450, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.5084, Test Loss: 0.5713\n",
      "Epoch: 1460, Train Acc: 0.7974, Test Acc: 0.6900, Train Loss: 0.5084, Test Loss: 0.5714\n",
      "Epoch: 1470, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.5070, Test Loss: 0.5705\n",
      "Epoch: 1480, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.5073, Test Loss: 0.5708\n",
      "Epoch: 1490, Train Acc: 0.8017, Test Acc: 0.7000, Train Loss: 0.5048, Test Loss: 0.5696\n",
      "Epoch: 1500, Train Acc: 0.7931, Test Acc: 0.6950, Train Loss: 0.5027, Test Loss: 0.5682\n",
      "Epoch: 1510, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.5011, Test Loss: 0.5686\n",
      "Epoch: 1520, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.5036, Test Loss: 0.5681\n",
      "Epoch: 1530, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.5020, Test Loss: 0.5671\n",
      "Epoch: 1540, Train Acc: 0.8017, Test Acc: 0.6950, Train Loss: 0.4981, Test Loss: 0.5671\n",
      "Epoch: 1550, Train Acc: 0.8017, Test Acc: 0.7000, Train Loss: 0.5003, Test Loss: 0.5669\n",
      "Epoch: 1560, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.4986, Test Loss: 0.5657\n",
      "Epoch: 1570, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4978, Test Loss: 0.5662\n",
      "Epoch: 1580, Train Acc: 0.8017, Test Acc: 0.7000, Train Loss: 0.4965, Test Loss: 0.5654\n",
      "Epoch: 1590, Train Acc: 0.8039, Test Acc: 0.6900, Train Loss: 0.4937, Test Loss: 0.5649\n",
      "Epoch: 1600, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.4948, Test Loss: 0.5640\n",
      "Epoch: 1610, Train Acc: 0.7996, Test Acc: 0.7000, Train Loss: 0.4936, Test Loss: 0.5637\n",
      "Epoch: 1620, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4939, Test Loss: 0.5638\n",
      "Epoch: 1630, Train Acc: 0.7996, Test Acc: 0.7100, Train Loss: 0.4908, Test Loss: 0.5640\n",
      "Epoch: 1640, Train Acc: 0.7974, Test Acc: 0.7000, Train Loss: 0.4948, Test Loss: 0.5619\n",
      "Epoch: 1650, Train Acc: 0.8039, Test Acc: 0.7100, Train Loss: 0.4898, Test Loss: 0.5628\n",
      "Epoch: 1660, Train Acc: 0.8039, Test Acc: 0.7100, Train Loss: 0.4891, Test Loss: 0.5626\n",
      "Epoch: 1670, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4902, Test Loss: 0.5620\n",
      "Epoch: 1680, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4857, Test Loss: 0.5616\n",
      "Epoch: 1690, Train Acc: 0.8039, Test Acc: 0.7150, Train Loss: 0.4855, Test Loss: 0.5615\n",
      "Epoch: 1700, Train Acc: 0.8017, Test Acc: 0.7000, Train Loss: 0.4871, Test Loss: 0.5604\n",
      "Epoch: 1710, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4838, Test Loss: 0.5602\n",
      "Epoch: 1720, Train Acc: 0.8017, Test Acc: 0.7050, Train Loss: 0.4837, Test Loss: 0.5602\n",
      "Epoch: 1730, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4841, Test Loss: 0.5596\n",
      "Epoch: 1740, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4805, Test Loss: 0.5595\n",
      "Epoch: 1750, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4829, Test Loss: 0.5596\n",
      "Epoch: 1760, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4819, Test Loss: 0.5585\n",
      "Epoch: 1770, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4786, Test Loss: 0.5581\n",
      "Epoch: 1780, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4809, Test Loss: 0.5578\n",
      "Epoch: 1790, Train Acc: 0.8039, Test Acc: 0.7050, Train Loss: 0.4803, Test Loss: 0.5574\n",
      "Epoch: 1800, Train Acc: 0.8039, Test Acc: 0.7100, Train Loss: 0.4764, Test Loss: 0.5573\n",
      "Epoch: 1810, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4744, Test Loss: 0.5567\n",
      "Epoch: 1820, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4760, Test Loss: 0.5567\n",
      "Epoch: 1830, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4759, Test Loss: 0.5562\n",
      "Epoch: 1840, Train Acc: 0.8060, Test Acc: 0.7100, Train Loss: 0.4732, Test Loss: 0.5561\n",
      "Epoch: 1850, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4755, Test Loss: 0.5550\n",
      "Epoch: 1860, Train Acc: 0.8082, Test Acc: 0.7100, Train Loss: 0.4721, Test Loss: 0.5560\n",
      "Epoch: 1870, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4726, Test Loss: 0.5549\n",
      "Epoch: 1880, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4710, Test Loss: 0.5543\n",
      "Epoch: 1890, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4661, Test Loss: 0.5554\n",
      "Epoch: 1900, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4690, Test Loss: 0.5534\n",
      "Epoch: 1910, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4707, Test Loss: 0.5544\n",
      "Epoch: 1920, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4712, Test Loss: 0.5538\n",
      "Epoch: 1930, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4703, Test Loss: 0.5531\n",
      "Epoch: 1940, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4720, Test Loss: 0.5537\n",
      "Epoch: 1950, Train Acc: 0.8125, Test Acc: 0.7150, Train Loss: 0.4640, Test Loss: 0.5529\n",
      "Epoch: 1960, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4674, Test Loss: 0.5540\n",
      "Epoch: 1970, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4667, Test Loss: 0.5545\n",
      "Epoch: 1980, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4620, Test Loss: 0.5522\n",
      "Epoch: 1990, Train Acc: 0.8125, Test Acc: 0.7200, Train Loss: 0.4616, Test Loss: 0.5516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▃▃▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████</td></tr><tr><td>Test F1</td><td>▂▂▂▂▂▂▂▂▂▁▂▂▃▂▄▄▇▆▆▆▆▅▆▆▅▄▄▄▅▅▄▃▇▆▇▆▇▇██</td></tr><tr><td>Test Loss</td><td>██████████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>█████████▇▇▇▆▅▄▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▆▇▇▇▇█▇█████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Train F1</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▃▄▄▄▆▆▆▆▆▅▆▆▇▆▇▇▇▇▇█▇█▇█████</td></tr><tr><td>Train Loss</td><td>███████████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>███████▇█▇▇▇▆▅▄▄▃▃▂▂▁▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▄▅▆▆▇▇▇██▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.725</td></tr><tr><td>Test F1</td><td>0.72362</td></tr><tr><td>Test Loss</td><td>0.55038</td></tr><tr><td>Test Sensitivity</td><td>0.69903</td></tr><tr><td>Test Specificity</td><td>0.75258</td></tr><tr><td>Train Accuracy</td><td>0.80819</td></tr><tr><td>Train F1</td><td>0.81342</td></tr><tr><td>Train Loss</td><td>0.46049</td></tr><tr><td>Train Sensitivity</td><td>0.78862</td></tr><tr><td>Train Specificity</td><td>0.83028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-sweep-58</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qx1pd99j' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qx1pd99j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_195704-qx1pd99j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qyklva0t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.894378503734162e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.4687234475012352e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_200558-qyklva0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/qyklva0t' target=\"_blank\">dark-sweep-59</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qyklva0t' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qyklva0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6939, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5108, Test Acc: 0.5050, Train Loss: 0.6927, Test Loss: 0.6927\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5100, Train Loss: 0.6914, Test Loss: 0.6917\n",
      "Epoch: 030, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6904, Test Loss: 0.6917\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6918\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6902, Test Loss: 0.6918\n",
      "Epoch: 060, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6903, Test Loss: 0.6918\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6898, Test Loss: 0.6917\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▄█▆▇▂▁▃▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test F1</td><td>▁▁▁▂▆▇▇▇▇███████████████████████████████</td></tr><tr><td>Test Loss</td><td>███▇▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁▁▁▄▅▆▆▇███████████████████████████████</td></tr><tr><td>Test Specificity</td><td>████▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▅▅▅▇▆▇█▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train F1</td><td>▁▁▁▁▅▇▇▇▇███████████████████████████████</td></tr><tr><td>Train Loss</td><td>███▇▇▆▆▅▅▄▄▄▃▂▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▁▁▁▂▂▁▂▂▂▂▂</td></tr><tr><td>Train Sensitivity</td><td>▁▁▁▁▄▅▆▆▇▇██████████████████████████████</td></tr><tr><td>Train Specificity</td><td>████▆▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.515</td></tr><tr><td>Test F1</td><td>0.67987</td></tr><tr><td>Test Loss</td><td>0.69168</td></tr><tr><td>Test Sensitivity</td><td>1.0</td></tr><tr><td>Test Specificity</td><td>0.0</td></tr><tr><td>Train Accuracy</td><td>0.52802</td></tr><tr><td>Train F1</td><td>0.69111</td></tr><tr><td>Train Loss</td><td>0.69058</td></tr><tr><td>Train Sensitivity</td><td>0.99593</td></tr><tr><td>Train Specificity</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-59</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/qyklva0t' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/qyklva0t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_200558-qyklva0t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x9convyw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006008069340572645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001769515676143384\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_200634-x9convyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/x9convyw' target=\"_blank\">denim-sweep-60</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/x9convyw' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/x9convyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6979, Test Loss: 0.7035\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.7424, Test Loss: 0.7546\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6917, Test Loss: 0.6925\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6908, Test Loss: 0.6918\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6901, Test Loss: 0.6911\n",
      "Epoch: 050, Train Acc: 0.5560, Test Acc: 0.5350, Train Loss: 0.6857, Test Loss: 0.6861\n",
      "Epoch: 060, Train Acc: 0.5453, Test Acc: 0.5500, Train Loss: 0.6617, Test Loss: 0.6642\n",
      "Epoch: 070, Train Acc: 0.6530, Test Acc: 0.6550, Train Loss: 0.6312, Test Loss: 0.6343\n",
      "Epoch: 080, Train Acc: 0.6228, Test Acc: 0.6550, Train Loss: 0.8420, Test Loss: 0.8024\n",
      "Epoch: 090, Train Acc: 0.6487, Test Acc: 0.6850, Train Loss: 0.7430, Test Loss: 0.7242\n",
      "Epoch: 100, Train Acc: 0.7672, Test Acc: 0.7450, Train Loss: 0.5222, Test Loss: 0.5491\n",
      "Epoch: 110, Train Acc: 0.7974, Test Acc: 0.7700, Train Loss: 0.4766, Test Loss: 0.5211\n",
      "Epoch: 120, Train Acc: 0.5970, Test Acc: 0.6350, Train Loss: 1.0210, Test Loss: 0.9966\n",
      "Epoch: 130, Train Acc: 0.8319, Test Acc: 0.7850, Train Loss: 0.4348, Test Loss: 0.5047\n",
      "Epoch: 140, Train Acc: 0.6746, Test Acc: 0.7050, Train Loss: 0.7274, Test Loss: 0.7295\n",
      "Epoch: 150, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 3.7616, Test Loss: 4.1092\n",
      "Epoch: 160, Train Acc: 0.8017, Test Acc: 0.7600, Train Loss: 0.4815, Test Loss: 0.5873\n",
      "Epoch: 170, Train Acc: 0.8621, Test Acc: 0.7700, Train Loss: 0.3905, Test Loss: 0.5280\n",
      "Epoch: 180, Train Acc: 0.6013, Test Acc: 0.6250, Train Loss: 1.1419, Test Loss: 1.1848\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▃▄▃▃▅▆▄▄▃▇▆▇▇▇▅▅▆███▇▂▇▇▆▆▄▇▇</td></tr><tr><td>Test F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▆▄▄▆▇▅▅▄▇▆▇▇▇▆▆▇███▇▇██▇█▅▇▇</td></tr><tr><td>Test Loss</td><td>▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▄▄▂▂▁▁▂▂▃▂▁▁▁▂█▁▁▂▂▅▂▁</td></tr><tr><td>Test Sensitivity</td><td>▁▁██▁███████▄▂▂▄▄▃▃▂▅▄▅▅▄▄▃▄▆▆▆▅█▇▇▅▇▃▄▅</td></tr><tr><td>Test Specificity</td><td>██▁▁█▁▁▁▁▁▁▂▇███████████████▇▇▇█▁▅▆▇▅██▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▁▂▂▂▂▂▂▃▄▃▃▄▅▄▃▂▆▅▆▆▅▄▄▅███▆▂██▇▇▃▆█</td></tr><tr><td>Train F1</td><td>▁▁▇▇▁▇▇▇▇▇▇▇▆▃▄▅▆▅▄▃▆▆▇▇▆▅▅▆███▆▇██▇█▄▆█</td></tr><tr><td>Train Loss</td><td>▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▄▅▆▂▃▂▂▃▃▄▃▁▁▁▂█▁▁▂▁▆▂▁</td></tr><tr><td>Train Sensitivity</td><td>▁▁██▁███████▄▂▂▃▄▃▂▂▄▄▅▄▄▃▃▄▆▆▆▄█▇▇▅▇▂▄▆</td></tr><tr><td>Train Specificity</td><td>██▁▁█▁▁▁▁▁▁▂▇████████████████▇██▁▆▆█▆███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.625</td></tr><tr><td>Test F1</td><td>0.43609</td></tr><tr><td>Test Loss</td><td>1.18477</td></tr><tr><td>Test Sensitivity</td><td>0.28155</td></tr><tr><td>Test Specificity</td><td>0.98969</td></tr><tr><td>Train Accuracy</td><td>0.60129</td></tr><tr><td>Train F1</td><td>0.39739</td></tr><tr><td>Train Loss</td><td>1.14189</td></tr><tr><td>Train Sensitivity</td><td>0.24797</td></tr><tr><td>Train Specificity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-60</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/x9convyw' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/x9convyw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_200634-x9convyw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tz6386sg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012029536360533096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.003660816365977102\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_200746-tz6386sg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/tz6386sg' target=\"_blank\">visionary-sweep-61</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/tz6386sg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/tz6386sg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6945, Test Loss: 0.6940\n",
      "Epoch: 010, Train Acc: 0.5280, Test Acc: 0.4950, Train Loss: 0.6919, Test Loss: 0.6922\n",
      "Epoch: 020, Train Acc: 0.5431, Test Acc: 0.5050, Train Loss: 0.6886, Test Loss: 0.6901\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6859, Test Loss: 0.6897\n",
      "Epoch: 040, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6827, Test Loss: 0.6868\n",
      "Epoch: 050, Train Acc: 0.5754, Test Acc: 0.5250, Train Loss: 0.6779, Test Loss: 0.6826\n",
      "Epoch: 060, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6712, Test Loss: 0.6782\n",
      "Epoch: 070, Train Acc: 0.6703, Test Acc: 0.6350, Train Loss: 0.6589, Test Loss: 0.6658\n",
      "Epoch: 080, Train Acc: 0.7112, Test Acc: 0.6650, Train Loss: 0.6415, Test Loss: 0.6522\n",
      "Epoch: 090, Train Acc: 0.7349, Test Acc: 0.6600, Train Loss: 0.6182, Test Loss: 0.6343\n",
      "Epoch: 100, Train Acc: 0.7543, Test Acc: 0.7000, Train Loss: 0.5953, Test Loss: 0.6194\n",
      "Epoch: 110, Train Acc: 0.7737, Test Acc: 0.7000, Train Loss: 0.5685, Test Loss: 0.6013\n",
      "Epoch: 120, Train Acc: 0.7241, Test Acc: 0.6650, Train Loss: 0.5557, Test Loss: 0.5914\n",
      "Epoch: 130, Train Acc: 0.7457, Test Acc: 0.6700, Train Loss: 0.5342, Test Loss: 0.5796\n",
      "Epoch: 140, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.5156, Test Loss: 0.5712\n",
      "Epoch: 150, Train Acc: 0.7845, Test Acc: 0.7100, Train Loss: 0.5023, Test Loss: 0.5630\n",
      "Epoch: 160, Train Acc: 0.7866, Test Acc: 0.7200, Train Loss: 0.4924, Test Loss: 0.5569\n",
      "Epoch: 170, Train Acc: 0.7845, Test Acc: 0.6850, Train Loss: 0.4871, Test Loss: 0.5535\n",
      "Epoch: 180, Train Acc: 0.7608, Test Acc: 0.6750, Train Loss: 0.4996, Test Loss: 0.5618\n",
      "Epoch: 190, Train Acc: 0.7543, Test Acc: 0.6900, Train Loss: 0.5024, Test Loss: 0.5644\n",
      "Epoch: 200, Train Acc: 0.7953, Test Acc: 0.7000, Train Loss: 0.4739, Test Loss: 0.5434\n",
      "Epoch: 210, Train Acc: 0.8017, Test Acc: 0.7150, Train Loss: 0.4629, Test Loss: 0.5382\n",
      "Epoch: 220, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4480, Test Loss: 0.5314\n",
      "Epoch: 230, Train Acc: 0.8060, Test Acc: 0.7250, Train Loss: 0.4433, Test Loss: 0.5307\n",
      "Epoch: 240, Train Acc: 0.7888, Test Acc: 0.7150, Train Loss: 0.4634, Test Loss: 0.5433\n",
      "Epoch: 250, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4614, Test Loss: 0.5388\n",
      "Epoch: 260, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4245, Test Loss: 0.5188\n",
      "Epoch: 270, Train Acc: 0.8254, Test Acc: 0.7850, Train Loss: 0.4172, Test Loss: 0.5195\n",
      "Epoch: 280, Train Acc: 0.8276, Test Acc: 0.7850, Train Loss: 0.4150, Test Loss: 0.5159\n",
      "Epoch: 290, Train Acc: 0.8103, Test Acc: 0.7300, Train Loss: 0.4450, Test Loss: 0.5314\n",
      "Epoch: 300, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4183, Test Loss: 0.5176\n",
      "Epoch: 310, Train Acc: 0.8341, Test Acc: 0.7600, Train Loss: 0.4181, Test Loss: 0.5168\n",
      "Epoch: 320, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4569, Test Loss: 0.5428\n",
      "Epoch: 330, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4577, Test Loss: 0.5484\n",
      "Epoch: 340, Train Acc: 0.8319, Test Acc: 0.7600, Train Loss: 0.4079, Test Loss: 0.5153\n",
      "Epoch: 350, Train Acc: 0.8254, Test Acc: 0.7900, Train Loss: 0.3914, Test Loss: 0.5282\n",
      "Epoch: 360, Train Acc: 0.8211, Test Acc: 0.7400, Train Loss: 0.3975, Test Loss: 0.5395\n",
      "Epoch: 370, Train Acc: 0.8276, Test Acc: 0.8000, Train Loss: 0.3826, Test Loss: 0.5203\n",
      "Epoch: 380, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4387, Test Loss: 0.5378\n",
      "Epoch: 390, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4400, Test Loss: 0.5455\n",
      "Epoch: 400, Train Acc: 0.8578, Test Acc: 0.7750, Train Loss: 0.3816, Test Loss: 0.5120\n",
      "Epoch: 410, Train Acc: 0.8578, Test Acc: 0.8050, Train Loss: 0.3644, Test Loss: 0.5148\n",
      "Epoch: 420, Train Acc: 0.8384, Test Acc: 0.7600, Train Loss: 0.3904, Test Loss: 0.5197\n",
      "Epoch: 430, Train Acc: 0.8642, Test Acc: 0.7950, Train Loss: 0.3642, Test Loss: 0.5123\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▂▂▂▂▂▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▇▆▇▇▆█▆▆▆▇▇▆▇▇▇▆▇█</td></tr><tr><td>Test F1</td><td>▁▆▇▇▇▇▇▇▇▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇▇██▇██</td></tr><tr><td>Test Loss</td><td>█████▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▃▄▁▁▃▁▁▁▃▁▁</td></tr><tr><td>Test Sensitivity</td><td>▁▆█████▆▆▇▄▅▅▄▆▅▅▅▅▆▅▅▆▅▇▆▅▇▅▅▅▆▆▅▆▆▆▅▆▇</td></tr><tr><td>Test Specificity</td><td>█▃▁▁▁▁▁▅▆▅▇▆▇▇▆▇▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇██▇█▇▇▆██▇███▇██</td></tr><tr><td>Train F1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█████▇██▇▇██▇███▇██</td></tr><tr><td>Train Loss</td><td>██████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▃▂▃▄▄▂▂▃▂▂▁▃▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▆█████▇▆▇▅▆▅▅▇▆▆▆▆▆▆▆▆▆▇▇▆▇▆▅▅▆▇▅▇▇▇▆▆▇</td></tr><tr><td>Train Specificity</td><td>█▃▁▁▂▂▂▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.8</td></tr><tr><td>Test F1</td><td>0.79798</td></tr><tr><td>Test Loss</td><td>0.51238</td></tr><tr><td>Test Sensitivity</td><td>0.76699</td></tr><tr><td>Test Specificity</td><td>0.83505</td></tr><tr><td>Train Accuracy</td><td>0.86422</td></tr><tr><td>Train F1</td><td>0.86334</td></tr><tr><td>Train Loss</td><td>0.36136</td></tr><tr><td>Train Sensitivity</td><td>0.80894</td></tr><tr><td>Train Specificity</td><td>0.92661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-sweep-61</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/tz6386sg' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/tz6386sg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_200746-tz6386sg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 04s87w3d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 320\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.478951372527657e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.093532559754664e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_201003-04s87w3d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/04s87w3d' target=\"_blank\">lyric-sweep-62</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/04s87w3d' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/04s87w3d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.4698, Test Acc: 0.4850, Train Loss: 0.6938, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5237, Test Acc: 0.5450, Train Loss: 0.6928, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5194, Test Acc: 0.5050, Train Loss: 0.6905, Test Loss: 0.6904\n",
      "Epoch: 030, Train Acc: 0.5539, Test Acc: 0.5300, Train Loss: 0.6877, Test Loss: 0.6895\n",
      "Epoch: 040, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6873, Test Loss: 0.6893\n",
      "Epoch: 050, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6854, Test Loss: 0.6887\n",
      "Epoch: 060, Train Acc: 0.5474, Test Acc: 0.5200, Train Loss: 0.6841, Test Loss: 0.6870\n",
      "Epoch: 070, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6825, Test Loss: 0.6868\n",
      "Epoch: 080, Train Acc: 0.5948, Test Acc: 0.5400, Train Loss: 0.6815, Test Loss: 0.6839\n",
      "Epoch: 090, Train Acc: 0.6185, Test Acc: 0.5450, Train Loss: 0.6788, Test Loss: 0.6823\n",
      "Epoch: 100, Train Acc: 0.5776, Test Acc: 0.5250, Train Loss: 0.6769, Test Loss: 0.6807\n",
      "Epoch: 110, Train Acc: 0.6315, Test Acc: 0.5650, Train Loss: 0.6730, Test Loss: 0.6778\n",
      "Epoch: 120, Train Acc: 0.6466, Test Acc: 0.5700, Train Loss: 0.6698, Test Loss: 0.6746\n",
      "Epoch: 130, Train Acc: 0.6659, Test Acc: 0.6000, Train Loss: 0.6654, Test Loss: 0.6709\n",
      "Epoch: 140, Train Acc: 0.6832, Test Acc: 0.6200, Train Loss: 0.6597, Test Loss: 0.6667\n",
      "Epoch: 150, Train Acc: 0.7263, Test Acc: 0.6400, Train Loss: 0.6532, Test Loss: 0.6614\n",
      "Epoch: 160, Train Acc: 0.7241, Test Acc: 0.6700, Train Loss: 0.6457, Test Loss: 0.6555\n",
      "Epoch: 170, Train Acc: 0.7349, Test Acc: 0.6850, Train Loss: 0.6377, Test Loss: 0.6489\n",
      "Epoch: 180, Train Acc: 0.7414, Test Acc: 0.6800, Train Loss: 0.6275, Test Loss: 0.6413\n",
      "Epoch: 190, Train Acc: 0.7672, Test Acc: 0.6750, Train Loss: 0.6157, Test Loss: 0.6334\n",
      "Epoch: 200, Train Acc: 0.7435, Test Acc: 0.6750, Train Loss: 0.6064, Test Loss: 0.6257\n",
      "Epoch: 210, Train Acc: 0.7565, Test Acc: 0.6650, Train Loss: 0.5951, Test Loss: 0.6171\n",
      "Epoch: 220, Train Acc: 0.7565, Test Acc: 0.6700, Train Loss: 0.5820, Test Loss: 0.6095\n",
      "Epoch: 230, Train Acc: 0.7694, Test Acc: 0.6700, Train Loss: 0.5692, Test Loss: 0.6013\n",
      "Epoch: 240, Train Acc: 0.7802, Test Acc: 0.6650, Train Loss: 0.5576, Test Loss: 0.5945\n",
      "Epoch: 250, Train Acc: 0.7716, Test Acc: 0.6750, Train Loss: 0.5457, Test Loss: 0.5882\n",
      "Epoch: 260, Train Acc: 0.7759, Test Acc: 0.6800, Train Loss: 0.5392, Test Loss: 0.5828\n",
      "Epoch: 270, Train Acc: 0.7845, Test Acc: 0.6850, Train Loss: 0.5299, Test Loss: 0.5777\n",
      "Epoch: 280, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.5235, Test Loss: 0.5738\n",
      "Epoch: 290, Train Acc: 0.7931, Test Acc: 0.6900, Train Loss: 0.5096, Test Loss: 0.5695\n",
      "Epoch: 300, Train Acc: 0.7802, Test Acc: 0.6850, Train Loss: 0.5097, Test Loss: 0.5662\n",
      "Epoch: 310, Train Acc: 0.7931, Test Acc: 0.7000, Train Loss: 0.4990, Test Loss: 0.5615\n",
      "Epoch: 320, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.4947, Test Loss: 0.5592\n",
      "Epoch: 330, Train Acc: 0.7909, Test Acc: 0.7050, Train Loss: 0.4891, Test Loss: 0.5564\n",
      "Epoch: 340, Train Acc: 0.8017, Test Acc: 0.7200, Train Loss: 0.4796, Test Loss: 0.5539\n",
      "Epoch: 350, Train Acc: 0.8017, Test Acc: 0.7250, Train Loss: 0.4756, Test Loss: 0.5525\n",
      "Epoch: 360, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.4813, Test Loss: 0.5525\n",
      "Epoch: 370, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4687, Test Loss: 0.5470\n",
      "Epoch: 380, Train Acc: 0.7888, Test Acc: 0.7100, Train Loss: 0.4699, Test Loss: 0.5481\n",
      "Epoch: 390, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4607, Test Loss: 0.5413\n",
      "Epoch: 400, Train Acc: 0.8125, Test Acc: 0.7300, Train Loss: 0.4541, Test Loss: 0.5407\n",
      "Epoch: 410, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4466, Test Loss: 0.5388\n",
      "Epoch: 420, Train Acc: 0.8168, Test Acc: 0.7350, Train Loss: 0.4430, Test Loss: 0.5369\n",
      "Epoch: 430, Train Acc: 0.8147, Test Acc: 0.7400, Train Loss: 0.4455, Test Loss: 0.5356\n",
      "Epoch: 440, Train Acc: 0.8125, Test Acc: 0.7350, Train Loss: 0.4397, Test Loss: 0.5333\n",
      "Epoch: 450, Train Acc: 0.8039, Test Acc: 0.7350, Train Loss: 0.4447, Test Loss: 0.5348\n",
      "Epoch: 460, Train Acc: 0.8276, Test Acc: 0.7450, Train Loss: 0.4311, Test Loss: 0.5320\n",
      "Epoch: 470, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4367, Test Loss: 0.5302\n",
      "Epoch: 480, Train Acc: 0.8125, Test Acc: 0.7400, Train Loss: 0.4380, Test Loss: 0.5289\n",
      "Epoch: 490, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4247, Test Loss: 0.5342\n",
      "Epoch: 500, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4237, Test Loss: 0.5261\n",
      "Epoch: 510, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4408, Test Loss: 0.5304\n",
      "Epoch: 520, Train Acc: 0.8276, Test Acc: 0.7500, Train Loss: 0.4176, Test Loss: 0.5235\n",
      "Epoch: 530, Train Acc: 0.8297, Test Acc: 0.7450, Train Loss: 0.4113, Test Loss: 0.5239\n",
      "Epoch: 540, Train Acc: 0.8297, Test Acc: 0.7600, Train Loss: 0.4070, Test Loss: 0.5242\n",
      "Epoch: 550, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4144, Test Loss: 0.5243\n",
      "Epoch: 560, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4047, Test Loss: 0.5224\n",
      "Epoch: 570, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4033, Test Loss: 0.5202\n",
      "Epoch: 580, Train Acc: 0.8341, Test Acc: 0.7750, Train Loss: 0.3984, Test Loss: 0.5215\n",
      "Epoch: 590, Train Acc: 0.8319, Test Acc: 0.7650, Train Loss: 0.4005, Test Loss: 0.5317\n",
      "Epoch: 600, Train Acc: 0.8211, Test Acc: 0.7450, Train Loss: 0.4220, Test Loss: 0.5299\n",
      "Epoch: 610, Train Acc: 0.8384, Test Acc: 0.7800, Train Loss: 0.3955, Test Loss: 0.5194\n",
      "Epoch: 620, Train Acc: 0.8448, Test Acc: 0.7550, Train Loss: 0.3945, Test Loss: 0.5199\n",
      "Epoch: 630, Train Acc: 0.8427, Test Acc: 0.7550, Train Loss: 0.3982, Test Loss: 0.5202\n",
      "Epoch: 640, Train Acc: 0.8534, Test Acc: 0.7550, Train Loss: 0.3886, Test Loss: 0.5211\n",
      "Epoch: 650, Train Acc: 0.8513, Test Acc: 0.7600, Train Loss: 0.3883, Test Loss: 0.5202\n",
      "Epoch: 660, Train Acc: 0.8448, Test Acc: 0.7900, Train Loss: 0.3815, Test Loss: 0.5214\n",
      "Epoch: 670, Train Acc: 0.8470, Test Acc: 0.7850, Train Loss: 0.3767, Test Loss: 0.5252\n",
      "Epoch: 680, Train Acc: 0.8556, Test Acc: 0.7700, Train Loss: 0.3834, Test Loss: 0.5220\n",
      "Epoch: 690, Train Acc: 0.8405, Test Acc: 0.7500, Train Loss: 0.3952, Test Loss: 0.5263\n",
      "Epoch: 700, Train Acc: 0.8384, Test Acc: 0.7500, Train Loss: 0.3856, Test Loss: 0.5232\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▁▂▂▂▂▃▃▄▆▅▆▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▆▇▇█▇███▇█</td></tr><tr><td>Test F1</td><td>▁▅▆▆▆▆▆▆▆▆▆▆▅▆▆▆▆▆▇▇▅▇▇▇▇▇▇▇▇█▆▇██▇█████</td></tr><tr><td>Test Loss</td><td>██████▇▇▇▆▆▅▅▄▄▃▃▃▂▂▃▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Test Sensitivity</td><td>▁▆████▇▇▆▅▅▄▃▄▄▅▄▅▅▅▃▅▅▅▅▅▅▄▅▆▄▅▆▆▅▆▆▆▆▆</td></tr><tr><td>Test Specificity</td><td>▇▂▁▁▁▂▂▃▄▇▆▇█▇▇▇▇▇▇▇█▇▇▇▇▇███▇██▇▇█▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▁▃▃▄▅▅▆▆▆▇▆▇▇▇▇▇▆▇▇▇▇█▇▇▇▇▇█████████</td></tr><tr><td>Train F1</td><td>▁▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▆▇█▇██▇▇██▇█████████</td></tr><tr><td>Train Loss</td><td>███████▇▇▇▆▆▆▅▅▄▄▄▃▃▄▃▃▃▃▂▂▂▂▂▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Sensitivity</td><td>▁▆████▇▇▆▅▅▅▄▆▅▆▅▆▆▆▄▆▆▆▆▆▅▅▆▆▅▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Train Specificity</td><td>▇▃▁▁▁▃▃▄▅▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇███▇██▇▇█▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.785</td></tr><tr><td>Test F1</td><td>0.78173</td></tr><tr><td>Test Loss</td><td>0.5232</td></tr><tr><td>Test Sensitivity</td><td>0.74757</td></tr><tr><td>Test Specificity</td><td>0.82474</td></tr><tr><td>Train Accuracy</td><td>0.8556</td></tr><tr><td>Train F1</td><td>0.85403</td></tr><tr><td>Train Loss</td><td>0.37174</td></tr><tr><td>Train Sensitivity</td><td>0.79675</td></tr><tr><td>Train Specificity</td><td>0.92202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-62</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/04s87w3d' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/04s87w3d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_201003-04s87w3d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mf1eq39l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00023222563535270176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002245482599159565\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_201446-mf1eq39l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/mf1eq39l' target=\"_blank\">serene-sweep-63</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mf1eq39l' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mf1eq39l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6915, Test Loss: 0.6940\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6907, Test Loss: 0.6925\n",
      "Epoch: 020, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 030, Train Acc: 0.5776, Test Acc: 0.5200, Train Loss: 0.6857, Test Loss: 0.6884\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6828, Test Loss: 0.6877\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6783, Test Loss: 0.6834\n",
      "Epoch: 060, Train Acc: 0.6509, Test Acc: 0.5950, Train Loss: 0.6696, Test Loss: 0.6750\n",
      "Epoch: 070, Train Acc: 0.6767, Test Acc: 0.6550, Train Loss: 0.6580, Test Loss: 0.6648\n",
      "Epoch: 080, Train Acc: 0.6595, Test Acc: 0.6250, Train Loss: 0.6476, Test Loss: 0.6537\n",
      "Epoch: 090, Train Acc: 0.7091, Test Acc: 0.6450, Train Loss: 0.6181, Test Loss: 0.6331\n",
      "Epoch: 100, Train Acc: 0.7241, Test Acc: 0.6650, Train Loss: 0.5915, Test Loss: 0.6135\n",
      "Epoch: 110, Train Acc: 0.7112, Test Acc: 0.6500, Train Loss: 0.5725, Test Loss: 0.6014\n",
      "Epoch: 120, Train Acc: 0.7780, Test Acc: 0.6950, Train Loss: 0.5391, Test Loss: 0.5804\n",
      "Epoch: 130, Train Acc: 0.7500, Test Acc: 0.6800, Train Loss: 0.5303, Test Loss: 0.5762\n",
      "Epoch: 140, Train Acc: 0.7306, Test Acc: 0.6800, Train Loss: 0.5361, Test Loss: 0.5828\n",
      "Epoch: 150, Train Acc: 0.7522, Test Acc: 0.6750, Train Loss: 0.5098, Test Loss: 0.5707\n",
      "Epoch: 160, Train Acc: 0.7845, Test Acc: 0.7000, Train Loss: 0.4879, Test Loss: 0.5527\n",
      "Epoch: 170, Train Acc: 0.7608, Test Acc: 0.6900, Train Loss: 0.5049, Test Loss: 0.5632\n",
      "Epoch: 180, Train Acc: 0.7608, Test Acc: 0.7000, Train Loss: 0.5019, Test Loss: 0.5637\n",
      "Epoch: 190, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.4616, Test Loss: 0.5353\n",
      "Epoch: 200, Train Acc: 0.8060, Test Acc: 0.7200, Train Loss: 0.4550, Test Loss: 0.5325\n",
      "Epoch: 210, Train Acc: 0.7974, Test Acc: 0.7250, Train Loss: 0.4568, Test Loss: 0.5326\n",
      "Epoch: 220, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4323, Test Loss: 0.5246\n",
      "Epoch: 230, Train Acc: 0.7931, Test Acc: 0.7200, Train Loss: 0.4700, Test Loss: 0.5428\n",
      "Epoch: 240, Train Acc: 0.8060, Test Acc: 0.7500, Train Loss: 0.4279, Test Loss: 0.5385\n",
      "Epoch: 250, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4421, Test Loss: 0.5275\n",
      "Epoch: 260, Train Acc: 0.8060, Test Acc: 0.7350, Train Loss: 0.4426, Test Loss: 0.5322\n",
      "Epoch: 270, Train Acc: 0.7392, Test Acc: 0.7150, Train Loss: 0.5330, Test Loss: 0.6041\n",
      "Epoch: 280, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4584, Test Loss: 0.5474\n",
      "Epoch: 290, Train Acc: 0.8341, Test Acc: 0.7650, Train Loss: 0.4135, Test Loss: 0.5216\n",
      "Epoch: 300, Train Acc: 0.7931, Test Acc: 0.7250, Train Loss: 0.4854, Test Loss: 0.5641\n",
      "Epoch: 310, Train Acc: 0.8341, Test Acc: 0.7700, Train Loss: 0.4016, Test Loss: 0.5168\n",
      "Epoch: 320, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4727, Test Loss: 0.5645\n",
      "50 epochs passed without 0 test loss improvement. \n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▁▁▁▁▁▁▂▄▅▅▄▄▄▅▅▅▅▅▆▅▅▇▆▆▆▇▇▇▆▇█▇▆█▆▆█▇▇</td></tr><tr><td>Test F1</td><td>▅▅▅▅▅▅▅▅▄▅▃▁▂▂▄▃▄▅▄▇▅▄▇▅▅▆▆▇▆▆▇██▅█▅▄█▆▇</td></tr><tr><td>Test Loss</td><td>███████▇▇▇▆▆▅▄▄▄▄▃▃▃▂▄▂▂▂▂▁▁▁▁▁▁▁▂▁▂▅▁▁▁</td></tr><tr><td>Test Sensitivity</td><td>███████▇▄▄▂▁▂▂▃▂▂▄▃▅▃▂▅▃▄▄▄▅▄▄▄▅▆▃▅▃▃▅▄▄</td></tr><tr><td>Test Specificity</td><td>▁▁▁▁▁▁▂▃▆▆▇███▇██▇█▇▇█▇▇▇▇▇▇███▇▆█▇██▇██</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▃▃▅▅▅▄▅▅▆▅▆▇▆▇▇▆▇▇▇▇██▇▇██▇▇█▇▆███</td></tr><tr><td>Train F1</td><td>▄▄▄▄▄▅▅▅▄▄▄▁▃▃▅▄▄▆▅▇▆▄▇▆▇▇▇▇▇▇▇██▆█▆▄███</td></tr><tr><td>Train Loss</td><td>████████▇▇▇▆▆▅▅▅▄▄▄▃▃▄▃▃▂▂▂▂▂▂▂▁▁▂▁▂▄▁▂▁</td></tr><tr><td>Train Sensitivity</td><td>███████▇▄▃▃▁▂▂▃▃▃▄▃▅▄▂▅▄▄▅▅▅▅▄▅▅▆▄▅▄▂▆▅▅</td></tr><tr><td>Train Specificity</td><td>▁▁▁▁▂▂▂▃▆▇▇█▇█▇██▇█▇▇█▇██▇▇▇███▇▇█▇██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.77</td></tr><tr><td>Test F1</td><td>0.75</td></tr><tr><td>Test Loss</td><td>0.52686</td></tr><tr><td>Test Sensitivity</td><td>0.6699</td></tr><tr><td>Test Specificity</td><td>0.87629</td></tr><tr><td>Train Accuracy</td><td>0.83836</td></tr><tr><td>Train F1</td><td>0.83146</td></tr><tr><td>Train Loss</td><td>0.40255</td></tr><tr><td>Train Sensitivity</td><td>0.75203</td></tr><tr><td>Train Specificity</td><td>0.93578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-sweep-63</strong> at: <a href='https://wandb.ai/dylan-home/19-node-feats/runs/mf1eq39l' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/mf1eq39l</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_201446-mf1eq39l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xrc6lusm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_channels: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2.8795466695938132e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.553849691762898e-08\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/alphafold-volume-1/dylan2/repos/tb-pnca-gnn/dd_pnca/wandb/run-20250704_201619-xrc6lusm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylan-home/19-node-feats/runs/xrc6lusm' target=\"_blank\">icy-sweep-64</a></strong> to <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylan-home/19-node-feats' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/sweeps/uuv8rla0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylan-home/19-node-feats/runs/xrc6lusm' target=\"_blank\">https://wandb.ai/dylan-home/19-node-feats/runs/xrc6lusm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Early stopping enabled. Patience: 50. Min Delta: 0.\n",
      "Epoch: 000, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6913, Test Loss: 0.6934\n",
      "Epoch: 010, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6914, Test Loss: 0.6931\n",
      "Epoch: 020, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6909, Test Loss: 0.6926\n",
      "Epoch: 030, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6900, Test Loss: 0.6921\n",
      "Epoch: 040, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6895, Test Loss: 0.6920\n",
      "Epoch: 050, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6896, Test Loss: 0.6916\n",
      "Epoch: 060, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6914\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6886, Test Loss: 0.6907\n",
      "Epoch: 080, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6884, Test Loss: 0.6908\n",
      "Epoch: 090, Train Acc: 0.5280, Test Acc: 0.5150, Train Loss: 0.6885, Test Loss: 0.6905\n",
      "Epoch: 100, Train Acc: 0.5453, Test Acc: 0.5200, Train Loss: 0.6877, Test Loss: 0.6900\n",
      "Epoch: 110, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6874, Test Loss: 0.6901\n",
      "Epoch: 120, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6877, Test Loss: 0.6897\n",
      "Epoch: 130, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6867, Test Loss: 0.6893\n",
      "Epoch: 140, Train Acc: 0.5388, Test Acc: 0.5250, Train Loss: 0.6860, Test Loss: 0.6889\n",
      "Epoch: 150, Train Acc: 0.5323, Test Acc: 0.5150, Train Loss: 0.6855, Test Loss: 0.6888\n",
      "Epoch: 160, Train Acc: 0.5366, Test Acc: 0.5200, Train Loss: 0.6846, Test Loss: 0.6882\n",
      "Epoch: 170, Train Acc: 0.5302, Test Acc: 0.5150, Train Loss: 0.6841, Test Loss: 0.6882\n",
      "Epoch: 180, Train Acc: 0.5366, Test Acc: 0.5150, Train Loss: 0.6838, Test Loss: 0.6874\n",
      "Epoch: 190, Train Acc: 0.5453, Test Acc: 0.5100, Train Loss: 0.6837, Test Loss: 0.6869\n",
      "Epoch: 200, Train Acc: 0.5345, Test Acc: 0.5150, Train Loss: 0.6833, Test Loss: 0.6866\n",
      "Epoch: 210, Train Acc: 0.5431, Test Acc: 0.5100, Train Loss: 0.6823, Test Loss: 0.6860\n",
      "Epoch: 220, Train Acc: 0.5754, Test Acc: 0.5250, Train Loss: 0.6810, Test Loss: 0.6848\n",
      "Epoch: 230, Train Acc: 0.5474, Test Acc: 0.5100, Train Loss: 0.6811, Test Loss: 0.6847\n",
      "Epoch: 240, Train Acc: 0.5927, Test Acc: 0.5300, Train Loss: 0.6796, Test Loss: 0.6833\n",
      "Epoch: 250, Train Acc: 0.5797, Test Acc: 0.5200, Train Loss: 0.6777, Test Loss: 0.6827\n",
      "Epoch: 260, Train Acc: 0.5690, Test Acc: 0.5050, Train Loss: 0.6766, Test Loss: 0.6820\n",
      "Epoch: 270, Train Acc: 0.5970, Test Acc: 0.5300, Train Loss: 0.6763, Test Loss: 0.6805\n",
      "Epoch: 280, Train Acc: 0.6013, Test Acc: 0.5350, Train Loss: 0.6742, Test Loss: 0.6794\n",
      "Epoch: 290, Train Acc: 0.6034, Test Acc: 0.5350, Train Loss: 0.6720, Test Loss: 0.6780\n",
      "Epoch: 300, Train Acc: 0.6207, Test Acc: 0.5550, Train Loss: 0.6706, Test Loss: 0.6764\n",
      "Epoch: 310, Train Acc: 0.6142, Test Acc: 0.5650, Train Loss: 0.6687, Test Loss: 0.6750\n",
      "Epoch: 320, Train Acc: 0.6422, Test Acc: 0.5600, Train Loss: 0.6660, Test Loss: 0.6730\n",
      "Epoch: 330, Train Acc: 0.6573, Test Acc: 0.5700, Train Loss: 0.6634, Test Loss: 0.6711\n",
      "Epoch: 340, Train Acc: 0.6767, Test Acc: 0.6150, Train Loss: 0.6611, Test Loss: 0.6688\n",
      "Epoch: 350, Train Acc: 0.6509, Test Acc: 0.5700, Train Loss: 0.6574, Test Loss: 0.6674\n",
      "Epoch: 360, Train Acc: 0.7004, Test Acc: 0.6450, Train Loss: 0.6556, Test Loss: 0.6640\n",
      "Epoch: 370, Train Acc: 0.7026, Test Acc: 0.6450, Train Loss: 0.6518, Test Loss: 0.6616\n",
      "Epoch: 380, Train Acc: 0.7198, Test Acc: 0.6700, Train Loss: 0.6477, Test Loss: 0.6587\n",
      "Epoch: 390, Train Acc: 0.7328, Test Acc: 0.6700, Train Loss: 0.6440, Test Loss: 0.6558\n",
      "Epoch: 400, Train Acc: 0.7457, Test Acc: 0.6750, Train Loss: 0.6407, Test Loss: 0.6530\n",
      "Epoch: 410, Train Acc: 0.7371, Test Acc: 0.6750, Train Loss: 0.6373, Test Loss: 0.6496\n",
      "Epoch: 420, Train Acc: 0.7435, Test Acc: 0.6750, Train Loss: 0.6331, Test Loss: 0.6463\n",
      "Epoch: 430, Train Acc: 0.7608, Test Acc: 0.6750, Train Loss: 0.6278, Test Loss: 0.6431\n",
      "Epoch: 440, Train Acc: 0.7586, Test Acc: 0.6800, Train Loss: 0.6225, Test Loss: 0.6395\n",
      "Epoch: 450, Train Acc: 0.7414, Test Acc: 0.7000, Train Loss: 0.6196, Test Loss: 0.6359\n",
      "Epoch: 460, Train Acc: 0.7651, Test Acc: 0.6850, Train Loss: 0.6137, Test Loss: 0.6326\n",
      "Epoch: 470, Train Acc: 0.7586, Test Acc: 0.6850, Train Loss: 0.6099, Test Loss: 0.6289\n",
      "Epoch: 480, Train Acc: 0.7608, Test Acc: 0.6800, Train Loss: 0.6047, Test Loss: 0.6255\n",
      "Epoch: 490, Train Acc: 0.7608, Test Acc: 0.6900, Train Loss: 0.5994, Test Loss: 0.6221\n",
      "Epoch: 500, Train Acc: 0.7629, Test Acc: 0.6950, Train Loss: 0.5963, Test Loss: 0.6188\n",
      "Epoch: 510, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.5893, Test Loss: 0.6156\n",
      "Epoch: 520, Train Acc: 0.7672, Test Acc: 0.6800, Train Loss: 0.5830, Test Loss: 0.6123\n",
      "Epoch: 530, Train Acc: 0.7629, Test Acc: 0.6800, Train Loss: 0.5786, Test Loss: 0.6092\n",
      "Epoch: 540, Train Acc: 0.7694, Test Acc: 0.6950, Train Loss: 0.5759, Test Loss: 0.6058\n",
      "Epoch: 550, Train Acc: 0.7716, Test Acc: 0.6950, Train Loss: 0.5723, Test Loss: 0.6032\n",
      "Epoch: 560, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5684, Test Loss: 0.6003\n",
      "Epoch: 570, Train Acc: 0.7737, Test Acc: 0.6850, Train Loss: 0.5632, Test Loss: 0.5973\n",
      "Epoch: 580, Train Acc: 0.7716, Test Acc: 0.6800, Train Loss: 0.5602, Test Loss: 0.5945\n",
      "Epoch: 590, Train Acc: 0.7780, Test Acc: 0.6650, Train Loss: 0.5555, Test Loss: 0.5921\n",
      "Epoch: 600, Train Acc: 0.7737, Test Acc: 0.6950, Train Loss: 0.5493, Test Loss: 0.5897\n",
      "Epoch: 610, Train Acc: 0.7780, Test Acc: 0.7000, Train Loss: 0.5450, Test Loss: 0.5878\n",
      "Epoch: 620, Train Acc: 0.7802, Test Acc: 0.6900, Train Loss: 0.5424, Test Loss: 0.5856\n",
      "Epoch: 630, Train Acc: 0.7823, Test Acc: 0.6950, Train Loss: 0.5385, Test Loss: 0.5836\n",
      "Epoch: 640, Train Acc: 0.7802, Test Acc: 0.6850, Train Loss: 0.5348, Test Loss: 0.5813\n",
      "Epoch: 650, Train Acc: 0.7802, Test Acc: 0.6850, Train Loss: 0.5309, Test Loss: 0.5793\n",
      "Epoch: 660, Train Acc: 0.7866, Test Acc: 0.6950, Train Loss: 0.5267, Test Loss: 0.5778\n",
      "Epoch: 670, Train Acc: 0.7888, Test Acc: 0.7000, Train Loss: 0.5244, Test Loss: 0.5762\n",
      "Epoch: 680, Train Acc: 0.7909, Test Acc: 0.7000, Train Loss: 0.5201, Test Loss: 0.5748\n",
      "Epoch: 690, Train Acc: 0.7909, Test Acc: 0.6950, Train Loss: 0.5206, Test Loss: 0.5732\n",
      "Epoch: 700, Train Acc: 0.7953, Test Acc: 0.7000, Train Loss: 0.5153, Test Loss: 0.5719\n",
      "Epoch: 710, Train Acc: 0.7974, Test Acc: 0.7050, Train Loss: 0.5114, Test Loss: 0.5709\n",
      "Epoch: 720, Train Acc: 0.7974, Test Acc: 0.6950, Train Loss: 0.5118, Test Loss: 0.5693\n",
      "Epoch: 730, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.5059, Test Loss: 0.5685\n",
      "Epoch: 740, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.5044, Test Loss: 0.5674\n",
      "Epoch: 750, Train Acc: 0.7996, Test Acc: 0.7050, Train Loss: 0.4997, Test Loss: 0.5662\n",
      "Epoch: 760, Train Acc: 0.7974, Test Acc: 0.7100, Train Loss: 0.5035, Test Loss: 0.5662\n",
      "Epoch: 770, Train Acc: 0.7931, Test Acc: 0.6950, Train Loss: 0.4991, Test Loss: 0.5630\n",
      "Epoch: 780, Train Acc: 0.7996, Test Acc: 0.6950, Train Loss: 0.4946, Test Loss: 0.5628\n",
      "Epoch: 790, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4922, Test Loss: 0.5631\n",
      "Epoch: 800, Train Acc: 0.7953, Test Acc: 0.7200, Train Loss: 0.4922, Test Loss: 0.5622\n",
      "Epoch: 810, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4895, Test Loss: 0.5600\n",
      "Epoch: 820, Train Acc: 0.8017, Test Acc: 0.7100, Train Loss: 0.4887, Test Loss: 0.5582\n",
      "Epoch: 830, Train Acc: 0.7909, Test Acc: 0.7150, Train Loss: 0.4854, Test Loss: 0.5607\n",
      "Epoch: 840, Train Acc: 0.8039, Test Acc: 0.7100, Train Loss: 0.4836, Test Loss: 0.5573\n",
      "Epoch: 850, Train Acc: 0.7996, Test Acc: 0.7200, Train Loss: 0.4830, Test Loss: 0.5578\n",
      "Epoch: 860, Train Acc: 0.7996, Test Acc: 0.7150, Train Loss: 0.4805, Test Loss: 0.5548\n",
      "Epoch: 870, Train Acc: 0.8082, Test Acc: 0.7200, Train Loss: 0.4775, Test Loss: 0.5557\n",
      "Epoch: 880, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4763, Test Loss: 0.5537\n",
      "Epoch: 890, Train Acc: 0.8060, Test Acc: 0.7250, Train Loss: 0.4762, Test Loss: 0.5527\n",
      "Epoch: 900, Train Acc: 0.8082, Test Acc: 0.7150, Train Loss: 0.4732, Test Loss: 0.5536\n",
      "Epoch: 910, Train Acc: 0.8060, Test Acc: 0.7150, Train Loss: 0.4713, Test Loss: 0.5532\n",
      "Epoch: 920, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4684, Test Loss: 0.5519\n",
      "Epoch: 930, Train Acc: 0.8103, Test Acc: 0.7200, Train Loss: 0.4660, Test Loss: 0.5520\n",
      "Epoch: 940, Train Acc: 0.7996, Test Acc: 0.7300, Train Loss: 0.4686, Test Loss: 0.5527\n",
      "Epoch: 950, Train Acc: 0.8103, Test Acc: 0.7150, Train Loss: 0.4667, Test Loss: 0.5504\n",
      "Epoch: 960, Train Acc: 0.8103, Test Acc: 0.7350, Train Loss: 0.4636, Test Loss: 0.5481\n",
      "Epoch: 970, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4644, Test Loss: 0.5478\n",
      "Epoch: 980, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4609, Test Loss: 0.5468\n",
      "Epoch: 990, Train Acc: 0.8039, Test Acc: 0.7350, Train Loss: 0.4578, Test Loss: 0.5453\n",
      "Epoch: 1000, Train Acc: 0.7931, Test Acc: 0.7350, Train Loss: 0.4591, Test Loss: 0.5447\n",
      "Epoch: 1010, Train Acc: 0.8103, Test Acc: 0.7500, Train Loss: 0.4628, Test Loss: 0.5443\n",
      "Epoch: 1020, Train Acc: 0.8103, Test Acc: 0.7450, Train Loss: 0.4566, Test Loss: 0.5443\n",
      "Epoch: 1030, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4542, Test Loss: 0.5438\n",
      "Epoch: 1040, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4531, Test Loss: 0.5433\n",
      "Epoch: 1050, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4500, Test Loss: 0.5429\n",
      "Epoch: 1060, Train Acc: 0.8147, Test Acc: 0.7450, Train Loss: 0.4526, Test Loss: 0.5427\n",
      "Epoch: 1070, Train Acc: 0.8039, Test Acc: 0.7500, Train Loss: 0.4541, Test Loss: 0.5407\n",
      "Epoch: 1080, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4516, Test Loss: 0.5403\n",
      "Epoch: 1090, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4475, Test Loss: 0.5404\n",
      "Epoch: 1100, Train Acc: 0.8125, Test Acc: 0.7500, Train Loss: 0.4482, Test Loss: 0.5411\n",
      "Epoch: 1110, Train Acc: 0.8039, Test Acc: 0.7300, Train Loss: 0.4523, Test Loss: 0.5500\n",
      "Epoch: 1120, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4471, Test Loss: 0.5386\n",
      "Epoch: 1130, Train Acc: 0.8082, Test Acc: 0.7550, Train Loss: 0.4442, Test Loss: 0.5376\n",
      "Epoch: 1140, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4447, Test Loss: 0.5373\n",
      "Epoch: 1150, Train Acc: 0.8147, Test Acc: 0.7550, Train Loss: 0.4434, Test Loss: 0.5363\n",
      "Epoch: 1160, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4438, Test Loss: 0.5366\n",
      "Epoch: 1170, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4427, Test Loss: 0.5367\n",
      "Epoch: 1180, Train Acc: 0.8125, Test Acc: 0.7450, Train Loss: 0.4381, Test Loss: 0.5382\n",
      "Epoch: 1190, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4364, Test Loss: 0.5368\n",
      "Epoch: 1200, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4400, Test Loss: 0.5359\n",
      "Epoch: 1210, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4402, Test Loss: 0.5343\n",
      "Epoch: 1220, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4312, Test Loss: 0.5342\n",
      "Epoch: 1230, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4367, Test Loss: 0.5351\n",
      "Epoch: 1240, Train Acc: 0.8103, Test Acc: 0.7550, Train Loss: 0.4327, Test Loss: 0.5381\n",
      "Epoch: 1250, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4394, Test Loss: 0.5339\n",
      "Epoch: 1260, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4318, Test Loss: 0.5324\n",
      "Epoch: 1270, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4307, Test Loss: 0.5320\n",
      "Epoch: 1280, Train Acc: 0.8147, Test Acc: 0.7500, Train Loss: 0.4320, Test Loss: 0.5310\n",
      "Epoch: 1290, Train Acc: 0.8211, Test Acc: 0.7550, Train Loss: 0.4277, Test Loss: 0.5324\n",
      "Epoch: 1300, Train Acc: 0.8125, Test Acc: 0.7550, Train Loss: 0.4311, Test Loss: 0.5306\n",
      "Epoch: 1310, Train Acc: 0.8190, Test Acc: 0.7550, Train Loss: 0.4274, Test Loss: 0.5319\n",
      "Epoch: 1320, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4233, Test Loss: 0.5323\n",
      "Epoch: 1330, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4240, Test Loss: 0.5307\n",
      "Epoch: 1340, Train Acc: 0.8168, Test Acc: 0.7500, Train Loss: 0.4252, Test Loss: 0.5322\n",
      "Epoch: 1350, Train Acc: 0.8168, Test Acc: 0.7550, Train Loss: 0.4275, Test Loss: 0.5289\n",
      "Epoch: 1360, Train Acc: 0.8254, Test Acc: 0.7550, Train Loss: 0.4260, Test Loss: 0.5293\n",
      "Epoch: 1370, Train Acc: 0.8190, Test Acc: 0.7500, Train Loss: 0.4239, Test Loss: 0.5312\n",
      "Epoch: 1380, Train Acc: 0.8211, Test Acc: 0.7550, Train Loss: 0.4231, Test Loss: 0.5299\n",
      "Epoch: 1390, Train Acc: 0.8211, Test Acc: 0.7550, Train Loss: 0.4229, Test Loss: 0.5294\n",
      "Epoch: 1400, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4182, Test Loss: 0.5282\n",
      "Epoch: 1410, Train Acc: 0.8254, Test Acc: 0.7600, Train Loss: 0.4203, Test Loss: 0.5283\n",
      "Epoch: 1420, Train Acc: 0.8254, Test Acc: 0.7650, Train Loss: 0.4177, Test Loss: 0.5282\n",
      "Epoch: 1430, Train Acc: 0.8233, Test Acc: 0.7650, Train Loss: 0.4183, Test Loss: 0.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "\n",
      "Aborted!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1440, Train Acc: 0.8233, Test Acc: 0.7550, Train Loss: 0.4195, Test Loss: 0.5285\n",
      "Epoch: 1450, Train Acc: 0.8233, Test Acc: 0.7600, Train Loss: 0.4144, Test Loss: 0.5274\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, sweep_run, project = project, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
